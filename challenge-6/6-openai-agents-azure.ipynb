{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4685d784",
   "metadata": {},
   "source": [
    "# Challenge 6: Agentic RAG with OpenAI Agents SDK and Azure OpenAI\n",
    "\n",
    "In this notebook, we'll explore how to use the OpenAI Agents SDK with Azure OpenAI Service to build an intelligent RAG system. This approach complements the previous Semantic Kernel example by showing an alternative implementation using OpenAI's dedicated agents framework.\n",
    "\n",
    "## What is the OpenAI Agents SDK?\n",
    "\n",
    "The OpenAI Agents SDK is a Python library designed to help developers build agentic AI applications. It provides a simple yet powerful framework with a small set of primitives:\n",
    "\n",
    "- **Agents**: LLMs equipped with instructions and tools\n",
    "- **Handoffs**: Allow agents to delegate to other agents for specific tasks\n",
    "- **Guardrails**: Enable input validation for agents\n",
    "\n",
    "The SDK also includes built-in tracing functionality that helps visualize and debug agent workflows."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7e3e41b",
   "metadata": {},
   "source": [
    "## 1. Setting up Our Environment\n",
    "\n",
    "First, let's install the necessary packages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "30098979",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: openai in /home/vscode/.local/lib/python3.11/site-packages (1.68.2)\n",
      "Requirement already satisfied: openai-agents in /home/vscode/.local/lib/python3.11/site-packages (0.0.7)\n",
      "Requirement already satisfied: python-dotenv in /home/vscode/.local/lib/python3.11/site-packages (1.1.0)\n",
      "Requirement already satisfied: azure-search-documents in /home/vscode/.local/lib/python3.11/site-packages (11.5.2)\n",
      "Requirement already satisfied: PyPDF2 in /home/vscode/.local/lib/python3.11/site-packages (3.0.1)\n",
      "Collecting uvx\n",
      "  Using cached uvx-2.5.1.tar.gz (56 kB)\n",
      "  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25lerror\n",
      "  \u001b[1;31merror\u001b[0m: \u001b[1msubprocess-exited-with-error\u001b[0m\n",
      "  \n",
      "  \u001b[31m×\u001b[0m \u001b[32mPreparing metadata \u001b[0m\u001b[1;32m(\u001b[0m\u001b[32mpyproject.toml\u001b[0m\u001b[1;32m)\u001b[0m did not run successfully.\n",
      "  \u001b[31m│\u001b[0m exit code: \u001b[1;36m1\u001b[0m\n",
      "  \u001b[31m╰─>\u001b[0m \u001b[31m[6 lines of output]\u001b[0m\n",
      "  \u001b[31m   \u001b[0m Checking for Rust toolchain....\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m Cargo, the Rust package manager, is not installed or is not on PATH.\n",
      "  \u001b[31m   \u001b[0m This package requires Rust and Cargo to compile extensions. Install it through\n",
      "  \u001b[31m   \u001b[0m the system's package manager or via https://rustup.rs/\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m \u001b[31m[end of output]\u001b[0m\n",
      "  \n",
      "  \u001b[1;35mnote\u001b[0m: This error originates from a subprocess, and is likely not a problem with pip.\n",
      "\u001b[?25h\u001b[1;31merror\u001b[0m: \u001b[1mmetadata-generation-failed\u001b[0m\n",
      "\n",
      "\u001b[31m×\u001b[0m Encountered error while generating package metadata.\n",
      "\u001b[31m╰─>\u001b[0m See above for output.\n",
      "\n",
      "\u001b[1;35mnote\u001b[0m: This is an issue with the package mentioned above, not pip.\n",
      "\u001b[1;36mhint\u001b[0m: See above for details.\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.0\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.0.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install openai openai-agents python-dotenv azure-search-documents PyPDF2 uvx"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db36ec3e",
   "metadata": {},
   "source": [
    "## 2. Initializing Azure Services\n",
    "\n",
    "Now let's import the necessary libraries and set up our connections to Azure OpenAI and Azure AI Search."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "60e23cba",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import uuid\n",
    "import asyncio\n",
    "import json\n",
    "import PyPDF2\n",
    "from typing import List, Dict, Any, Optional\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "from azure.core.credentials import AzureKeyCredential\n",
    "from azure.search.documents import SearchClient\n",
    "from azure.search.documents.indexes import SearchIndexClient\n",
    "from azure.search.documents.indexes.models import (\n",
    "    SearchIndex, \n",
    "    SimpleField, \n",
    "    SearchFieldDataType, \n",
    "    SearchableField,\n",
    "    SearchField,\n",
    "    VectorSearch,\n",
    "    HnswAlgorithmConfiguration,\n",
    "    VectorSearchProfile,\n",
    "    VectorSearchAlgorithmKind\n",
    ")\n",
    "\n",
    "from openai import AsyncAzureOpenAI\n",
    "from agents import Agent, Runner, function_tool, set_default_openai_client, handoff, trace, add_trace_processor\n",
    "from agents.tracing.processors import ConsoleSpanExporter, BatchTraceProcessor\n",
    "from agents.mcp import MCPServer, MCPServerStdio\n",
    "\n",
    "from IPython.display import display, HTML, Markdown\n",
    "\n",
    "# Load environment variables\n",
    "load_dotenv()\n",
    "\n",
    "# Azure AI Search setup\n",
    "search_service_name = os.getenv(\"AZURE_SEARCH_SERVICE_NAME\")\n",
    "search_admin_key = os.getenv(\"AZURE_SEARCH_ADMIN_KEY\")\n",
    "search_endpoint = f\"https://{search_service_name}.search.windows.net\"\n",
    "\n",
    "# Azure OpenAI setup\n",
    "azure_openai_key = os.getenv(\"AZURE_OPENAI_KEY\")\n",
    "azure_openai_endpoint = os.getenv(\"AZURE_OPENAI_ENDPOINT\")\n",
    "azure_deployment = os.getenv(\"AZURE_OPENAI_DEPLOYMENT\", \"gpt-4o-mini\")\n",
    "azure_embedding_deployment = os.getenv(\"AZURE_OPENAI_EMBEDDING_DEPLOYMENT\", \"text-embedding-ada-002\")\n",
    "azure_openai_api_version = os.getenv(\"AZURE_OPENAI_API_VERSION\", \"2024-12-01-preview\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "054e94b9",
   "metadata": {},
   "source": [
    "## 3. Configuring Azure OpenAI with the OpenAI Agents SDK\n",
    "\n",
    "The OpenAI Agents SDK can connect to Azure OpenAI Service, allowing you to leverage your Azure deployments while using the Agents SDK functionality."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "9b4e4407",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Azure OpenAI clients for the main model and embeddings\n",
    "openai_client = AsyncAzureOpenAI(\n",
    "    api_key=azure_openai_key,\n",
    "    api_version=azure_openai_api_version,\n",
    "    azure_endpoint=azure_openai_endpoint,\n",
    "    azure_deployment=azure_deployment\n",
    ")\n",
    "\n",
    "embedding_client = AsyncAzureOpenAI(\n",
    "    api_key=azure_openai_key,\n",
    "    api_version=azure_openai_api_version,\n",
    "    azure_endpoint=azure_openai_endpoint,\n",
    "    azure_deployment=azure_embedding_deployment\n",
    ")\n",
    "\n",
    "# Set the default OpenAI client for the Agents SDK\n",
    "set_default_openai_client(openai_client)\n",
    "\n",
    "# Set up console tracing for debugging\n",
    "console_exporter = ConsoleSpanExporter()\n",
    "console_processor = BatchTraceProcessor(exporter=console_exporter)\n",
    "add_trace_processor(console_processor)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7c04f13",
   "metadata": {},
   "source": [
    "## 4. Setting up Azure AI Search Index\n",
    "\n",
    "Let's set up our search index for storing and retrieving HR documentation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "93cfd2c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index 'hr-documents-agents' already exists\n"
     ]
    }
   ],
   "source": [
    "# Define constants for index\n",
    "INDEX_NAME = \"hr-documents-agents\"\n",
    "VECTOR_DIMENSIONS = 1536  # Dimensions for text-embedding-ada-002\n",
    "\n",
    "# Define the schema for our search index\n",
    "def create_search_index(index_name: str, index_client: SearchIndexClient):\n",
    "    \"\"\"Create a search index if it doesn't exist.\"\"\"\n",
    "    \n",
    "    if index_name in [index.name for index in index_client.list_indexes()]:\n",
    "        print(f\"Index '{index_name}' already exists\")\n",
    "        return\n",
    "    \n",
    "    fields = [\n",
    "        SimpleField(name=\"id\", type=SearchFieldDataType.String, key=True),\n",
    "        SearchableField(name=\"content\", type=SearchFieldDataType.String, analyzer_name=\"en.microsoft\"),\n",
    "        SimpleField(name=\"title\", type=SearchFieldDataType.String),\n",
    "        SimpleField(name=\"category\", type=SearchFieldDataType.String),\n",
    "        SimpleField(name=\"page_num\", type=SearchFieldDataType.Int32),\n",
    "        SearchField(\n",
    "            name=\"vector\", \n",
    "            type=SearchFieldDataType.Collection(SearchFieldDataType.Single),\n",
    "            vector_search_dimensions=VECTOR_DIMENSIONS,\n",
    "            vector_search_profile_name=\"vector-profile\"\n",
    "        )\n",
    "    ]\n",
    "    \n",
    "    vector_search = VectorSearch(\n",
    "        algorithms=[\n",
    "            HnswAlgorithmConfiguration(\n",
    "                name=\"vector-algorithm\", \n",
    "                kind=VectorSearchAlgorithmKind.HNSW\n",
    "            )\n",
    "        ],\n",
    "        profiles=[\n",
    "            VectorSearchProfile(\n",
    "                name=\"vector-profile\", \n",
    "                algorithm_configuration_name=\"vector-algorithm\"\n",
    "            )\n",
    "        ]\n",
    "    )\n",
    "    \n",
    "    index = SearchIndex(name=index_name, fields=fields, vector_search=vector_search)\n",
    "    index_client.create_index(index)\n",
    "    print(f\"Created index '{index_name}' with vector search capability\")\n",
    "\n",
    "# Initialize search clients\n",
    "search_index_client = SearchIndexClient(\n",
    "    endpoint=search_endpoint,\n",
    "    credential=AzureKeyCredential(search_admin_key)\n",
    ")\n",
    "\n",
    "search_client = SearchClient(\n",
    "    endpoint=search_endpoint,\n",
    "    index_name=INDEX_NAME,\n",
    "    credential=AzureKeyCredential(search_admin_key)\n",
    ")\n",
    "\n",
    "# Create search index\n",
    "create_search_index(INDEX_NAME, search_index_client)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5514cd4",
   "metadata": {},
   "source": [
    "## 5. Processing Documents and Generating Embeddings\n",
    "\n",
    "Now we'll process the employee handbook PDF and index it in Azure AI Search."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "299afd78",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Functions for document processing\n",
    "async def generate_embeddings(text):\n",
    "    \"\"\"Generate embeddings for a text using Azure OpenAI.\"\"\"\n",
    "    try:\n",
    "        response = await embedding_client.embeddings.create(\n",
    "            input=text,\n",
    "            model=azure_embedding_deployment\n",
    "        )\n",
    "        return response.data[0].embedding\n",
    "    except Exception as e:\n",
    "        print(f\"Error generating embeddings: {e}\")\n",
    "        return [0.0] * VECTOR_DIMENSIONS\n",
    "\n",
    "def extract_text_from_pdf(pdf_path):\n",
    "    \"\"\"Extract text from a PDF file, returning the text content by page.\"\"\"\n",
    "    \n",
    "    print(f\"Extracting text from {pdf_path}...\")\n",
    "    \n",
    "    pdf_pages = []\n",
    "    \n",
    "    try:\n",
    "        with open(pdf_path, 'rb') as file:\n",
    "            pdf_reader = PyPDF2.PdfReader(file)\n",
    "            \n",
    "            for page_num, page in enumerate(pdf_reader.pages):\n",
    "                text = page.extract_text()\n",
    "                if text.strip():  # Only add non-empty pages\n",
    "                    pdf_pages.append({\n",
    "                        \"page_num\": page_num + 1,\n",
    "                        \"content\": text.strip()\n",
    "                    })\n",
    "            \n",
    "            print(f\"Successfully extracted text from {len(pdf_pages)} pages\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error extracting text from PDF: {e}\")\n",
    "    \n",
    "    return pdf_pages\n",
    "\n",
    "async def chunk_text_with_embeddings(pages, max_chunk_size=4000):\n",
    "    \"\"\"Split page content into smaller chunks with embeddings.\"\"\"\n",
    "    \n",
    "    chunks = []\n",
    "    \n",
    "    for page in pages:\n",
    "        page_text = page[\"content\"]\n",
    "        page_num = page[\"page_num\"]\n",
    "        \n",
    "        # If the page text is shorter than max_chunk_size, keep it as is\n",
    "        if len(page_text) <= max_chunk_size:\n",
    "            embedding = await generate_embeddings(page_text)\n",
    "            \n",
    "            chunks.append({\n",
    "                \"page_num\": page_num,\n",
    "                \"content\": page_text,\n",
    "                \"title\": f\"Employee Handbook - Page {page_num}\",\n",
    "                \"category\": \"Handbook\",\n",
    "                \"vector\": embedding\n",
    "            })\n",
    "        else:\n",
    "            # Split by paragraphs first\n",
    "            paragraphs = page_text.split('\\n\\n')\n",
    "            current_chunk = \"\"\n",
    "            \n",
    "            for para in paragraphs:\n",
    "                if len(current_chunk) + len(para) <= max_chunk_size:\n",
    "                    current_chunk += para + \"\\n\\n\"\n",
    "                else:\n",
    "                    # Add the current chunk if it's not empty\n",
    "                    if current_chunk:\n",
    "                        embedding = await generate_embeddings(current_chunk.strip())\n",
    "                        \n",
    "                        chunks.append({\n",
    "                            \"page_num\": page_num,\n",
    "                            \"content\": current_chunk.strip(),\n",
    "                            \"title\": f\"Employee Handbook - Page {page_num}\",\n",
    "                            \"category\": \"Handbook\",\n",
    "                            \"vector\": embedding\n",
    "                        })\n",
    "                    \n",
    "                    current_chunk = para + \"\\n\\n\"\n",
    "            \n",
    "            # Add the last chunk if it's not empty\n",
    "            if current_chunk:\n",
    "                embedding = await generate_embeddings(current_chunk.strip())\n",
    "                \n",
    "                chunks.append({\n",
    "                    \"page_num\": page_num,\n",
    "                    \"content\": current_chunk.strip(),\n",
    "                    \"title\": f\"Employee Handbook - Page {page_num}\",\n",
    "                    \"category\": \"Handbook\",\n",
    "                    \"vector\": embedding\n",
    "                })\n",
    "    \n",
    "    print(f\"Created {len(chunks)} chunks with embeddings from {len(pages)} pages\")\n",
    "    return chunks\n",
    "\n",
    "def index_documents(documents, search_client):\n",
    "    \"\"\"Index a list of documents into Azure AI Search.\"\"\"\n",
    "    \n",
    "    indexed_docs = []\n",
    "    \n",
    "    for doc in documents:\n",
    "        # Create a unique ID for each document\n",
    "        doc_id = str(uuid.uuid4())\n",
    "        \n",
    "        # Format the document for indexing\n",
    "        search_doc = {\n",
    "            \"id\": doc_id,\n",
    "            \"title\": doc[\"title\"],\n",
    "            \"content\": doc[\"content\"],\n",
    "            \"category\": doc[\"category\"],\n",
    "            \"page_num\": doc[\"page_num\"],\n",
    "            \"vector\": doc[\"vector\"]\n",
    "        }\n",
    "        \n",
    "        indexed_docs.append(search_doc)\n",
    "    \n",
    "    # Index the documents in batches\n",
    "    search_client.upload_documents(documents=indexed_docs)\n",
    "    print(f\"Indexed {len(indexed_docs)} documents with vector embeddings\")\n",
    "    \n",
    "    return indexed_docs\n",
    "\n",
    "# Process and index the PDF\n",
    "async def process_and_index_pdf():\n",
    "    pdf_path = \"docs/contoso_electronics.pdf\"\n",
    "    pdf_pages = extract_text_from_pdf(pdf_path)\n",
    "    pdf_chunks = await chunk_text_with_embeddings(pdf_pages)\n",
    "    \n",
    "    # Index the processed chunks\n",
    "    indexed_documents = index_documents(pdf_chunks, search_client)\n",
    "    return indexed_documents\n",
    "\n",
    "# Initialize the vector search\n",
    "async def init_vector_search():\n",
    "    # Process and index the PDF\n",
    "    await process_and_index_pdf()\n",
    "    print(\"Vector search initialized!\")\n",
    "    return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "df243002",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This cell initializes the vector search when executed\n",
    "async def initialize():\n",
    "    await init_vector_search()\n",
    "    \n",
    "# When running in Jupyter, uncomment and run this line:\n",
    "# await initialize()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1467901",
   "metadata": {},
   "source": [
    "## 6. Creating Function Tools for Document Search\n",
    "\n",
    "With the OpenAI Agents SDK, we can wrap search functionality as a tool that our agents can use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "70cfd965",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a function tool for searching documents\n",
    "@function_tool\n",
    "async def search_hr_documents(\n",
    "    query: str, \n",
    "    top: int = 3\n",
    ") -> str:\n",
    "    \"\"\"\n",
    "    Search for information in the HR documentation using the provided query.\n",
    "    \n",
    "    Args:\n",
    "        query: The search query to find relevant HR documentation\n",
    "        top: The number of top results to return (default: 3)\n",
    "    \n",
    "    Returns:\n",
    "        A formatted string with the search results\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Generate embedding for the query\n",
    "        query_embedding = await generate_embeddings(query)\n",
    "        \n",
    "        # Perform vector search\n",
    "        vector_results = search_client.search(\n",
    "            search_text=None,\n",
    "            vector=query_embedding,\n",
    "            vector_fields=\"vector\",\n",
    "            top=top,\n",
    "            select=[\"id\", \"title\", \"content\", \"page_num\"]\n",
    "        )\n",
    "        \n",
    "        # Format the results\n",
    "        formatted_results = []\n",
    "        \n",
    "        for i, result in enumerate(vector_results):\n",
    "            formatted_results.append(f\"Result {i+1} (Page {result['page_num']}):\\n{result['content']}\\n\")\n",
    "        \n",
    "        if formatted_results:\n",
    "            return \"\\n\".join(formatted_results)\n",
    "        else:\n",
    "            return \"No relevant HR documents found for your query.\"\n",
    "    \n",
    "    except Exception as e:\n",
    "        return f\"An error occurred while searching: {str(e)}\"\n",
    "\n",
    "@function_tool\n",
    "async def generate_query_from_question(question: str) -> str:\n",
    "    \"\"\"\n",
    "    Generate an optimized search query based on the user's question.\n",
    "    \n",
    "    Args:\n",
    "        question: The user's question about HR policies or information\n",
    "    \n",
    "    Returns:\n",
    "        An optimized search query for better retrieval\n",
    "    \"\"\"\n",
    "    # This will be handled by the LLM's built-in reasoning since it's a simple text transform\n",
    "    return question"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "616b475b",
   "metadata": {},
   "source": [
    "## 7. Creating Specialized Agents with Handoffs\n",
    "\n",
    "Let's create a system of agents for our HR application, including a general assistant, a search specialist, and a policy expert."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "8795802e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a search specialist agent\n",
    "search_specialist = Agent(\n",
    "    name=\"HR Search Specialist\",\n",
    "    instructions=\"\"\"You are a search specialist for HR documentation. \n",
    "    Your job is to:\n",
    "    1. Take a query about HR policies or employee information\n",
    "    2. If needed, optimize the query using the generate_query_from_question tool\n",
    "    3. Search the knowledge base using the search_hr_documents tool\n",
    "    4. Return the most relevant information found\n",
    "    \n",
    "    Be thorough and precise in your searches. Focus on finding exact answers.\n",
    "    Always cite the page number where information was found.\"\"\",\n",
    "    tools=[search_hr_documents, generate_query_from_question]\n",
    ")\n",
    "\n",
    "# Create a policy expert agent\n",
    "policy_expert = Agent(\n",
    "    name=\"HR Policy Expert\",\n",
    "    instructions=\"\"\"You are an HR policy expert. \n",
    "    Your job is to:\n",
    "    1. Analyze HR policy questions\n",
    "    2. Interpret and explain HR policies in a clear, helpful way\n",
    "    3. Provide well-reasoned guidance on policy implementation\n",
    "    4. Make sure your explanations align with company policies\n",
    "    \n",
    "    Focus on explaining \"why\" policies exist and how they benefit both the employee and the company.\n",
    "    If you need to search for specific policy details, hand off to the HR Search Specialist.\"\"\",\n",
    "    handoffs=[handoff(search_specialist)]\n",
    ")\n",
    "\n",
    "# Create a general HR assistant agent that can delegate to specialists\n",
    "hr_assistant = Agent(\n",
    "    name=\"HR Assistant\",\n",
    "    instructions=\"\"\"You are a helpful HR assistant for Contoso Electronics.\n",
    "    \n",
    "    Help employees with HR-related questions, focusing on:\n",
    "    - Company policies and procedures\n",
    "    - Benefits and time off\n",
    "    - Workplace guidelines\n",
    "    - Onboarding information\n",
    "    \n",
    "    For policy interpretation or complex policy questions, hand off to the HR Policy Expert.\n",
    "    For detailed information search, hand off to the HR Search Specialist.\n",
    "    \n",
    "    Be friendly, professional, and concise. Focus on providing accurate information based on company documentation.\"\"\",\n",
    "    handoffs=[\n",
    "        handoff(search_specialist),\n",
    "        handoff(policy_expert)\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b54022ee",
   "metadata": {},
   "source": [
    "## 8. Testing Our Agentic RAG System with the OpenAI Agents SDK\n",
    "\n",
    "Now let's test our agents with some sample questions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "6b1abe7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to run an agent and display the result\n",
    "async def ask_hr_assistant(question):\n",
    "    print(f\"Question: {question}\\n\")\n",
    "    \n",
    "    # Use tracing to capture the agent workflow\n",
    "    with trace(workflow_name=\"HR Assistant RAG\"):\n",
    "        result = await Runner.run(\n",
    "            hr_assistant,\n",
    "            input=question\n",
    "        )\n",
    "    \n",
    "    print(f\"Answer: {result.final_output}\\n\")\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "20547544",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: What is the policy on remote work?\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Exporter] Export trace_id=trace_a5500335cc024fa29ecf43ddaf60ba14, name=HR Assistant RAG, \n",
      "[Exporter] Export span: {'object': 'trace.span', 'id': 'span_259df930579a48c4a372bbd1', 'trace_id': 'trace_a5500335cc024fa29ecf43ddaf60ba14', 'parent_id': 'span_0d75d37745944db2a40d32f7', 'started_at': '2025-03-27T10:00:40.830958+00:00', 'ended_at': '2025-03-27T10:00:42.624926+00:00', 'span_data': {'type': 'response', 'response_id': 'resp_67e521c9d25c819082f8d3f02429afe8'}, 'error': None}\n",
      "[Exporter] Export span: {'object': 'trace.span', 'id': 'span_cb5590befbe44959a9e313b0', 'trace_id': 'trace_a5500335cc024fa29ecf43ddaf60ba14', 'parent_id': 'span_0d75d37745944db2a40d32f7', 'started_at': '2025-03-27T10:00:42.625470+00:00', 'ended_at': '2025-03-27T10:00:42.625572+00:00', 'span_data': {'type': 'handoff', 'from_agent': 'HR Assistant', 'to_agent': 'HR Policy Expert'}, 'error': None}\n",
      "[Exporter] Export span: {'object': 'trace.span', 'id': 'span_0d75d37745944db2a40d32f7', 'trace_id': 'trace_a5500335cc024fa29ecf43ddaf60ba14', 'parent_id': None, 'started_at': '2025-03-27T10:00:40.830679+00:00', 'ended_at': '2025-03-27T10:00:42.625665+00:00', 'span_data': {'type': 'agent', 'name': 'HR Assistant', 'handoffs': ['HR Search Specialist', 'HR Policy Expert'], 'tools': [], 'output_type': 'str'}, 'error': None}\n",
      "[Exporter] Export span: {'object': 'trace.span', 'id': 'span_7200c07268c8492885b02345', 'trace_id': 'trace_a5500335cc024fa29ecf43ddaf60ba14', 'parent_id': 'span_ad8be60c99fc474ba555bf35', 'started_at': '2025-03-27T10:00:42.625902+00:00', 'ended_at': '2025-03-27T10:00:48.324400+00:00', 'span_data': {'type': 'response', 'response_id': 'resp_67e521cb71848190a23528e3b4586e78'}, 'error': None}\n",
      "[Exporter] Export span: {'object': 'trace.span', 'id': 'span_ad8be60c99fc474ba555bf35', 'trace_id': 'trace_a5500335cc024fa29ecf43ddaf60ba14', 'parent_id': None, 'started_at': '2025-03-27T10:00:42.625725+00:00', 'ended_at': '2025-03-27T10:00:48.324856+00:00', 'span_data': {'type': 'agent', 'name': 'HR Policy Expert', 'handoffs': ['HR Search Specialist'], 'tools': [], 'output_type': 'str'}, 'error': None}\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'RunResult' object has no attribute 'response'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[42]\u001b[39m\u001b[32m, line 13\u001b[39m\n\u001b[32m     10\u001b[39m     \u001b[38;5;28;01mawait\u001b[39;00m ask_hr_assistant(\u001b[33m\"\u001b[39m\u001b[33mWhat are the security protocols for accessing company systems remotely?\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     12\u001b[39m \u001b[38;5;66;03m# When running in Jupyter, uncomment and run this line:\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m13\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m test_hr_assistant()\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[42]\u001b[39m\u001b[32m, line 4\u001b[39m, in \u001b[36mtest_hr_assistant\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mtest_hr_assistant\u001b[39m():\n\u001b[32m      3\u001b[39m     \u001b[38;5;66;03m# Test with a simple question\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m4\u001b[39m     \u001b[38;5;28;01mawait\u001b[39;00m ask_hr_assistant(\u001b[33m\"\u001b[39m\u001b[33mWhat is the policy on remote work?\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m      6\u001b[39m     \u001b[38;5;66;03m# Test with a question that might require policy interpretation\u001b[39;00m\n\u001b[32m      7\u001b[39m     \u001b[38;5;28;01mawait\u001b[39;00m ask_hr_assistant(\u001b[33m\"\u001b[39m\u001b[33mI\u001b[39m\u001b[33m'\u001b[39m\u001b[33mm planning to take parental leave soon. What is the process and how much time am I entitled to?\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[41]\u001b[39m\u001b[32m, line 12\u001b[39m, in \u001b[36mask_hr_assistant\u001b[39m\u001b[34m(question)\u001b[39m\n\u001b[32m      6\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m trace(workflow_name=\u001b[33m\"\u001b[39m\u001b[33mHR Assistant RAG\u001b[39m\u001b[33m\"\u001b[39m):\n\u001b[32m      7\u001b[39m     result = \u001b[38;5;28;01mawait\u001b[39;00m Runner.run(\n\u001b[32m      8\u001b[39m         hr_assistant,\n\u001b[32m      9\u001b[39m         \u001b[38;5;28minput\u001b[39m=question\n\u001b[32m     10\u001b[39m     )\n\u001b[32m---> \u001b[39m\u001b[32m12\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mAnswer: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[43mresult\u001b[49m\u001b[43m.\u001b[49m\u001b[43mresponse\u001b[49m.content\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m     13\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "\u001b[31mAttributeError\u001b[39m: 'RunResult' object has no attribute 'response'"
     ]
    }
   ],
   "source": [
    "# This cell can be used to test the HR assistant\n",
    "async def test_hr_assistant():\n",
    "    # Test with a simple question\n",
    "    await ask_hr_assistant(\"What is the policy on remote work?\")\n",
    "    \n",
    "    # Test with a question that might require policy interpretation\n",
    "    await ask_hr_assistant(\"I'm planning to take parental leave soon. What is the process and how much time am I entitled to?\")\n",
    "    \n",
    "    # Test with a question that might require specific document search\n",
    "    await ask_hr_assistant(\"What are the security protocols for accessing company systems remotely?\")\n",
    "\n",
    "# When running in Jupyter, uncomment and run this line:\n",
    "await test_hr_assistant()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a51b78a0",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "In this notebook, we've demonstrated how to use the OpenAI Agents SDK with Azure OpenAI to build an intelligent RAG system, integrating with the MCP protocol for web search capabilities. Key features we explored include:\n",
    "\n",
    "1. **Azure OpenAI Integration** - Connected the OpenAI Agents SDK to Azure OpenAI Service\n",
    "2. **Function Tools** - Created tools for search and query generation\n",
    "3. **Agent Specialization** - Built specialized agents for different aspects of HR assistance\n",
    "4. **Handoffs** - Enabled delegation between agents for better task handling\n",
    "5. **MCP Protocol Integration** - Connected to an existing MCP server for Bing Search\n",
    "6. **Tracing** - Used the built-in tracing for monitoring agent workflows\n",
    "\n",
    "This approach offers a powerful alternative to the Semantic Kernel implementation shown earlier, with a focus on agent specialization and handoffs for complex tasks."
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "formats": "ipynb,py:percent"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
