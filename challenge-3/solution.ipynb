{
    "cells": [
        {
            "cell_type": "markdown",
            "id": "97d516ea",
            "metadata": {},
            "source": [
                "# Challenge 3: Fundamentals of Prompt Engineering & Evaluation\n",
                "\n",
                "In this challenge, we'll explore core principles of effective prompt engineering, focusing on practical techniques for crafting prompts and evaluating them using Microsoft's tools. We'll also learn how to evaluate and refine prompts using quantitative metrics."
            ]
        },
        {
            "cell_type": "markdown",
            "id": "e825b913",
            "metadata": {},
            "source": [
                "## 1. Core Principles of Effective Prompt Crafting\n",
                "\n",
                "Effective prompts follow these key principles:\n",
                "\n",
                "1. **Role & Context Setting**: Define the AI's role and provide context for the task\n",
                "2. **Clear Instructions**: Provide specific, unambiguous directions\n",
                "3. **Input/Output Format Specification**: Clearly define how to format inputs and expected outputs\n",
                "4. **Few-Shot Examples**: Provide examples demonstrating desired input/output patterns\n",
                "5. **Chain-of-Thought Prompting**: Guide the model through a reasoning process\n",
                "6. **System vs User Prompts**: Utilize system prompts for personality and user prompts for specific requests"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "53699e7f",
            "metadata": {},
            "source": [
                "## 2. Setting up Our Environment\n",
                "\n",
                "First, let's install the necessary packages for our prompt engineering and evaluation work:"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 20,
            "id": "6ac3307b",
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Defaulting to user installation because normal site-packages is not writeable\n",
                        "Requirement already satisfied: openai in /home/vscode/.local/lib/python3.11/site-packages (1.66.3)\n",
                        "Requirement already satisfied: python-dotenv in /home/vscode/.local/lib/python3.11/site-packages (1.0.1)\n",
                        "Requirement already satisfied: numpy in /home/vscode/.local/lib/python3.11/site-packages (2.2.4)\n",
                        "Requirement already satisfied: pandas in /home/vscode/.local/lib/python3.11/site-packages (2.2.3)\n",
                        "Requirement already satisfied: matplotlib in /home/vscode/.local/lib/python3.11/site-packages (3.10.1)\n",
                        "Collecting azure-ai-evaluation\n",
                        "  Downloading azure_ai_evaluation-1.3.0-py3-none-any.whl.metadata (32 kB)\n",
                        "Requirement already satisfied: anyio<5,>=3.5.0 in /home/vscode/.local/lib/python3.11/site-packages (from openai) (4.9.0)\n",
                        "Requirement already satisfied: distro<2,>=1.7.0 in /home/vscode/.local/lib/python3.11/site-packages (from openai) (1.9.0)\n",
                        "Requirement already satisfied: httpx<1,>=0.23.0 in /home/vscode/.local/lib/python3.11/site-packages (from openai) (0.28.1)\n",
                        "Requirement already satisfied: jiter<1,>=0.4.0 in /home/vscode/.local/lib/python3.11/site-packages (from openai) (0.9.0)\n",
                        "Requirement already satisfied: pydantic<3,>=1.9.0 in /home/vscode/.local/lib/python3.11/site-packages (from openai) (2.10.6)\n",
                        "Requirement already satisfied: sniffio in /home/vscode/.local/lib/python3.11/site-packages (from openai) (1.3.1)\n",
                        "Requirement already satisfied: tqdm>4 in /home/vscode/.local/lib/python3.11/site-packages (from openai) (4.67.1)\n",
                        "Requirement already satisfied: typing-extensions<5,>=4.11 in /home/vscode/.local/lib/python3.11/site-packages (from openai) (4.12.2)\n",
                        "Requirement already satisfied: python-dateutil>=2.8.2 in /home/vscode/.local/lib/python3.11/site-packages (from pandas) (2.9.0.post0)\n",
                        "Requirement already satisfied: pytz>=2020.1 in /home/vscode/.local/lib/python3.11/site-packages (from pandas) (2025.1)\n",
                        "Requirement already satisfied: tzdata>=2022.7 in /home/vscode/.local/lib/python3.11/site-packages (from pandas) (2025.1)\n",
                        "Requirement already satisfied: contourpy>=1.0.1 in /home/vscode/.local/lib/python3.11/site-packages (from matplotlib) (1.3.1)\n",
                        "Requirement already satisfied: cycler>=0.10 in /home/vscode/.local/lib/python3.11/site-packages (from matplotlib) (0.12.1)\n",
                        "Requirement already satisfied: fonttools>=4.22.0 in /home/vscode/.local/lib/python3.11/site-packages (from matplotlib) (4.56.0)\n",
                        "Requirement already satisfied: kiwisolver>=1.3.1 in /home/vscode/.local/lib/python3.11/site-packages (from matplotlib) (1.4.8)\n",
                        "Requirement already satisfied: packaging>=20.0 in /home/vscode/.local/lib/python3.11/site-packages (from matplotlib) (24.2)\n",
                        "Requirement already satisfied: pillow>=8 in /home/vscode/.local/lib/python3.11/site-packages (from matplotlib) (11.1.0)\n",
                        "Requirement already satisfied: pyparsing>=2.3.1 in /home/vscode/.local/lib/python3.11/site-packages (from matplotlib) (3.2.1)\n",
                        "Collecting promptflow-devkit>=1.17.1 (from azure-ai-evaluation)\n",
                        "  Downloading promptflow_devkit-1.17.2-py3-none-any.whl.metadata (5.6 kB)\n",
                        "Collecting promptflow-core>=1.17.1 (from azure-ai-evaluation)\n",
                        "  Downloading promptflow_core-1.17.2-py3-none-any.whl.metadata (2.7 kB)\n",
                        "Collecting pyjwt>=2.8.0 (from azure-ai-evaluation)\n",
                        "  Downloading PyJWT-2.10.1-py3-none-any.whl.metadata (4.0 kB)\n",
                        "Collecting azure-identity>=1.16.0 (from azure-ai-evaluation)\n",
                        "  Downloading azure_identity-1.21.0-py3-none-any.whl.metadata (81 kB)\n",
                        "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m81.3/81.3 kB\u001b[0m \u001b[31m7.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
                        "\u001b[?25hCollecting azure-core>=1.30.2 (from azure-ai-evaluation)\n",
                        "  Downloading azure_core-1.32.0-py3-none-any.whl.metadata (39 kB)\n",
                        "Collecting nltk>=3.9.1 (from azure-ai-evaluation)\n",
                        "  Downloading nltk-3.9.1-py3-none-any.whl.metadata (2.9 kB)\n",
                        "Collecting azure-storage-blob>=12.10.0 (from azure-ai-evaluation)\n",
                        "  Downloading azure_storage_blob-12.25.0-py3-none-any.whl.metadata (26 kB)\n",
                        "Requirement already satisfied: idna>=2.8 in /home/vscode/.local/lib/python3.11/site-packages (from anyio<5,>=3.5.0->openai) (3.10)\n",
                        "Collecting requests>=2.21.0 (from azure-core>=1.30.2->azure-ai-evaluation)\n",
                        "  Downloading requests-2.32.3-py3-none-any.whl.metadata (4.6 kB)\n",
                        "Requirement already satisfied: six>=1.11.0 in /home/vscode/.local/lib/python3.11/site-packages (from azure-core>=1.30.2->azure-ai-evaluation) (1.17.0)\n",
                        "Collecting cryptography>=2.5 (from azure-identity>=1.16.0->azure-ai-evaluation)\n",
                        "  Downloading cryptography-44.0.2-cp39-abi3-manylinux_2_28_aarch64.whl.metadata (5.7 kB)\n",
                        "Collecting msal>=1.30.0 (from azure-identity>=1.16.0->azure-ai-evaluation)\n",
                        "  Downloading msal-1.32.0-py3-none-any.whl.metadata (11 kB)\n",
                        "Collecting msal-extensions>=1.2.0 (from azure-identity>=1.16.0->azure-ai-evaluation)\n",
                        "  Downloading msal_extensions-1.3.1-py3-none-any.whl.metadata (7.8 kB)\n",
                        "Collecting isodate>=0.6.1 (from azure-storage-blob>=12.10.0->azure-ai-evaluation)\n",
                        "  Downloading isodate-0.7.2-py3-none-any.whl.metadata (11 kB)\n",
                        "Requirement already satisfied: certifi in /home/vscode/.local/lib/python3.11/site-packages (from httpx<1,>=0.23.0->openai) (2025.1.31)\n",
                        "Requirement already satisfied: httpcore==1.* in /home/vscode/.local/lib/python3.11/site-packages (from httpx<1,>=0.23.0->openai) (1.0.7)\n",
                        "Requirement already satisfied: h11<0.15,>=0.13 in /home/vscode/.local/lib/python3.11/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.14.0)\n",
                        "Collecting click (from nltk>=3.9.1->azure-ai-evaluation)\n",
                        "  Downloading click-8.1.8-py3-none-any.whl.metadata (2.3 kB)\n",
                        "Collecting joblib (from nltk>=3.9.1->azure-ai-evaluation)\n",
                        "  Downloading joblib-1.4.2-py3-none-any.whl.metadata (5.4 kB)\n",
                        "Collecting regex>=2021.8.3 (from nltk>=3.9.1->azure-ai-evaluation)\n",
                        "  Downloading regex-2024.11.6-cp311-cp311-manylinux_2_17_aarch64.manylinux2014_aarch64.whl.metadata (40 kB)\n",
                        "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m40.5/40.5 kB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
                        "\u001b[?25hCollecting docstring_parser (from promptflow-core>=1.17.1->azure-ai-evaluation)\n",
                        "  Downloading docstring_parser-0.16-py3-none-any.whl.metadata (3.0 kB)\n",
                        "Collecting fastapi<1.0.0,>=0.109.0 (from promptflow-core>=1.17.1->azure-ai-evaluation)\n",
                        "  Downloading fastapi-0.115.11-py3-none-any.whl.metadata (27 kB)\n",
                        "Collecting filetype>=1.2.0 (from promptflow-core>=1.17.1->azure-ai-evaluation)\n",
                        "  Downloading filetype-1.2.0-py2.py3-none-any.whl.metadata (6.5 kB)\n",
                        "Collecting flask<4.0.0,>=2.2.3 (from promptflow-core>=1.17.1->azure-ai-evaluation)\n",
                        "  Downloading flask-3.1.0-py3-none-any.whl.metadata (2.7 kB)\n",
                        "Collecting jsonschema<5.0.0,>=4.0.0 (from promptflow-core>=1.17.1->azure-ai-evaluation)\n",
                        "  Downloading jsonschema-4.23.0-py3-none-any.whl.metadata (7.9 kB)\n",
                        "Collecting promptflow-tracing==1.17.2 (from promptflow-core>=1.17.1->azure-ai-evaluation)\n",
                        "  Downloading promptflow_tracing-1.17.2-py3-none-any.whl.metadata (2.2 kB)\n",
                        "Requirement already satisfied: psutil in /home/vscode/.local/lib/python3.11/site-packages (from promptflow-core>=1.17.1->azure-ai-evaluation) (7.0.0)\n",
                        "Collecting ruamel.yaml<1.0.0,>=0.17.10 (from promptflow-core>=1.17.1->azure-ai-evaluation)\n",
                        "  Downloading ruamel.yaml-0.18.10-py3-none-any.whl.metadata (23 kB)\n",
                        "Collecting opentelemetry-sdk<2.0.0,>=1.22.0 (from promptflow-tracing==1.17.2->promptflow-core>=1.17.1->azure-ai-evaluation)\n",
                        "  Downloading opentelemetry_sdk-1.31.0-py3-none-any.whl.metadata (1.6 kB)\n",
                        "Collecting tiktoken>=0.4.0 (from promptflow-tracing==1.17.2->promptflow-core>=1.17.1->azure-ai-evaluation)\n",
                        "  Downloading tiktoken-0.9.0-cp311-cp311-manylinux_2_17_aarch64.manylinux2014_aarch64.whl.metadata (6.7 kB)\n",
                        "Collecting argcomplete>=3.2.3 (from promptflow-devkit>=1.17.1->azure-ai-evaluation)\n",
                        "  Downloading argcomplete-3.6.0-py3-none-any.whl.metadata (16 kB)\n",
                        "Collecting azure-monitor-opentelemetry-exporter<2.0.0,>=1.0.0b21 (from promptflow-devkit>=1.17.1->azure-ai-evaluation)\n",
                        "  Downloading azure_monitor_opentelemetry_exporter-1.0.0b35-py2.py3-none-any.whl.metadata (32 kB)\n",
                        "Collecting colorama<0.5.0,>=0.4.6 (from promptflow-devkit>=1.17.1->azure-ai-evaluation)\n",
                        "  Downloading colorama-0.4.6-py2.py3-none-any.whl.metadata (17 kB)\n",
                        "Collecting filelock<4.0.0,>=3.4.0 (from promptflow-devkit>=1.17.1->azure-ai-evaluation)\n",
                        "  Downloading filelock-3.18.0-py3-none-any.whl.metadata (2.9 kB)\n",
                        "Collecting flask-cors<6.0.0,>=5.0.0 (from promptflow-devkit>=1.17.1->azure-ai-evaluation)\n",
                        "  Downloading flask_cors-5.0.1-py3-none-any.whl.metadata (961 bytes)\n",
                        "Collecting flask-restx<2.0.0,>=1.2.0 (from promptflow-devkit>=1.17.1->azure-ai-evaluation)\n",
                        "  Downloading flask_restx-1.3.0-py2.py3-none-any.whl.metadata (9.3 kB)\n",
                        "Requirement already satisfied: gitpython<4.0.0,>=3.1.24 in /usr/local/lib/python3.11/site-packages (from promptflow-devkit>=1.17.1->azure-ai-evaluation) (3.1.41)\n",
                        "Collecting keyring<25.0.0,>=24.2.0 (from promptflow-devkit>=1.17.1->azure-ai-evaluation)\n",
                        "  Downloading keyring-24.3.1-py3-none-any.whl.metadata (20 kB)\n",
                        "Collecting marshmallow<4.0.0,>=3.5 (from promptflow-devkit>=1.17.1->azure-ai-evaluation)\n",
                        "  Downloading marshmallow-3.26.1-py3-none-any.whl.metadata (7.3 kB)\n",
                        "Collecting opentelemetry-exporter-otlp-proto-http<2.0.0,>=1.22.0 (from promptflow-devkit>=1.17.1->azure-ai-evaluation)\n",
                        "  Downloading opentelemetry_exporter_otlp_proto_http-1.31.0-py3-none-any.whl.metadata (2.4 kB)\n",
                        "Collecting pillow>=8 (from matplotlib)\n",
                        "  Downloading pillow-11.0.0-cp311-cp311-manylinux_2_28_aarch64.whl.metadata (9.1 kB)\n",
                        "Collecting pydash<8.0.0,>=6.0.0 (from promptflow-devkit>=1.17.1->azure-ai-evaluation)\n",
                        "  Downloading pydash-7.0.7-py3-none-any.whl.metadata (45 kB)\n",
                        "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.8/45.8 kB\u001b[0m \u001b[31m8.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
                        "\u001b[?25hCollecting sqlalchemy<3.0.0,>=1.4.48 (from promptflow-devkit>=1.17.1->azure-ai-evaluation)\n",
                        "  Downloading sqlalchemy-2.0.39-cp311-cp311-manylinux_2_17_aarch64.manylinux2014_aarch64.whl.metadata (9.6 kB)\n",
                        "Collecting strictyaml<2.0.0,>=1.5.0 (from promptflow-devkit>=1.17.1->azure-ai-evaluation)\n",
                        "  Downloading strictyaml-1.7.3-py3-none-any.whl.metadata (11 kB)\n",
                        "Collecting tabulate<1.0.0,>=0.9.0 (from promptflow-devkit>=1.17.1->azure-ai-evaluation)\n",
                        "  Downloading tabulate-0.9.0-py3-none-any.whl.metadata (34 kB)\n",
                        "Collecting waitress<4.0.0,>=3.0.0 (from promptflow-devkit>=1.17.1->azure-ai-evaluation)\n",
                        "  Downloading waitress-3.0.2-py3-none-any.whl.metadata (5.8 kB)\n",
                        "Requirement already satisfied: annotated-types>=0.6.0 in /home/vscode/.local/lib/python3.11/site-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\n",
                        "Requirement already satisfied: pydantic-core==2.27.2 in /home/vscode/.local/lib/python3.11/site-packages (from pydantic<3,>=1.9.0->openai) (2.27.2)\n",
                        "Collecting fixedint==0.1.6 (from azure-monitor-opentelemetry-exporter<2.0.0,>=1.0.0b21->promptflow-devkit>=1.17.1->azure-ai-evaluation)\n",
                        "  Downloading fixedint-0.1.6-py3-none-any.whl.metadata (4.8 kB)\n",
                        "Collecting msrest>=0.6.10 (from azure-monitor-opentelemetry-exporter<2.0.0,>=1.0.0b21->promptflow-devkit>=1.17.1->azure-ai-evaluation)\n",
                        "  Downloading msrest-0.7.1-py3-none-any.whl.metadata (21 kB)\n",
                        "Collecting opentelemetry-api~=1.26 (from azure-monitor-opentelemetry-exporter<2.0.0,>=1.0.0b21->promptflow-devkit>=1.17.1->azure-ai-evaluation)\n",
                        "  Downloading opentelemetry_api-1.31.0-py3-none-any.whl.metadata (1.6 kB)\n",
                        "Collecting psutil (from promptflow-core>=1.17.1->azure-ai-evaluation)\n",
                        "  Downloading psutil-6.1.1-cp36-abi3-manylinux_2_17_aarch64.manylinux2014_aarch64.whl.metadata (22 kB)\n",
                        "Collecting cffi>=1.12 (from cryptography>=2.5->azure-identity>=1.16.0->azure-ai-evaluation)\n",
                        "  Downloading cffi-1.17.1-cp311-cp311-manylinux_2_17_aarch64.manylinux2014_aarch64.whl.metadata (1.5 kB)\n",
                        "Collecting starlette<0.47.0,>=0.40.0 (from fastapi<1.0.0,>=0.109.0->promptflow-core>=1.17.1->azure-ai-evaluation)\n",
                        "  Downloading starlette-0.46.1-py3-none-any.whl.metadata (6.2 kB)\n",
                        "Collecting Werkzeug>=3.1 (from flask<4.0.0,>=2.2.3->promptflow-core>=1.17.1->azure-ai-evaluation)\n",
                        "  Downloading werkzeug-3.1.3-py3-none-any.whl.metadata (3.7 kB)\n",
                        "Collecting Jinja2>=3.1.2 (from flask<4.0.0,>=2.2.3->promptflow-core>=1.17.1->azure-ai-evaluation)\n",
                        "  Downloading jinja2-3.1.6-py3-none-any.whl.metadata (2.9 kB)\n",
                        "Collecting itsdangerous>=2.2 (from flask<4.0.0,>=2.2.3->promptflow-core>=1.17.1->azure-ai-evaluation)\n",
                        "  Downloading itsdangerous-2.2.0-py3-none-any.whl.metadata (1.9 kB)\n",
                        "Collecting blinker>=1.9 (from flask<4.0.0,>=2.2.3->promptflow-core>=1.17.1->azure-ai-evaluation)\n",
                        "  Downloading blinker-1.9.0-py3-none-any.whl.metadata (1.6 kB)\n",
                        "Collecting aniso8601>=0.82 (from flask-restx<2.0.0,>=1.2.0->promptflow-devkit>=1.17.1->azure-ai-evaluation)\n",
                        "  Downloading aniso8601-10.0.0-py2.py3-none-any.whl.metadata (23 kB)\n",
                        "Collecting importlib-resources (from flask-restx<2.0.0,>=1.2.0->promptflow-devkit>=1.17.1->azure-ai-evaluation)\n",
                        "  Downloading importlib_resources-6.5.2-py3-none-any.whl.metadata (3.9 kB)\n",
                        "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.11/site-packages (from gitpython<4.0.0,>=3.1.24->promptflow-devkit>=1.17.1->azure-ai-evaluation) (4.0.11)\n",
                        "Collecting attrs>=22.2.0 (from jsonschema<5.0.0,>=4.0.0->promptflow-core>=1.17.1->azure-ai-evaluation)\n",
                        "  Downloading attrs-25.3.0-py3-none-any.whl.metadata (10 kB)\n",
                        "Collecting jsonschema-specifications>=2023.03.6 (from jsonschema<5.0.0,>=4.0.0->promptflow-core>=1.17.1->azure-ai-evaluation)\n",
                        "  Downloading jsonschema_specifications-2024.10.1-py3-none-any.whl.metadata (3.0 kB)\n",
                        "Collecting referencing>=0.28.4 (from jsonschema<5.0.0,>=4.0.0->promptflow-core>=1.17.1->azure-ai-evaluation)\n",
                        "  Downloading referencing-0.36.2-py3-none-any.whl.metadata (2.8 kB)\n",
                        "Collecting rpds-py>=0.7.1 (from jsonschema<5.0.0,>=4.0.0->promptflow-core>=1.17.1->azure-ai-evaluation)\n",
                        "  Downloading rpds_py-0.23.1-cp311-cp311-manylinux_2_17_aarch64.manylinux2014_aarch64.whl.metadata (4.1 kB)\n",
                        "Collecting jaraco.classes (from keyring<25.0.0,>=24.2.0->promptflow-devkit>=1.17.1->azure-ai-evaluation)\n",
                        "  Downloading jaraco.classes-3.4.0-py3-none-any.whl.metadata (2.6 kB)\n",
                        "Collecting importlib-metadata>=4.11.4 (from keyring<25.0.0,>=24.2.0->promptflow-devkit>=1.17.1->azure-ai-evaluation)\n",
                        "  Downloading importlib_metadata-8.6.1-py3-none-any.whl.metadata (4.7 kB)\n",
                        "Collecting SecretStorage>=3.2 (from keyring<25.0.0,>=24.2.0->promptflow-devkit>=1.17.1->azure-ai-evaluation)\n",
                        "  Downloading SecretStorage-3.3.3-py3-none-any.whl.metadata (4.0 kB)\n",
                        "Collecting jeepney>=0.4.2 (from keyring<25.0.0,>=24.2.0->promptflow-devkit>=1.17.1->azure-ai-evaluation)\n",
                        "  Downloading jeepney-0.9.0-py3-none-any.whl.metadata (1.2 kB)\n",
                        "Collecting deprecated>=1.2.6 (from opentelemetry-exporter-otlp-proto-http<2.0.0,>=1.22.0->promptflow-devkit>=1.17.1->azure-ai-evaluation)\n",
                        "  Downloading Deprecated-1.2.18-py2.py3-none-any.whl.metadata (5.7 kB)\n",
                        "Collecting googleapis-common-protos~=1.52 (from opentelemetry-exporter-otlp-proto-http<2.0.0,>=1.22.0->promptflow-devkit>=1.17.1->azure-ai-evaluation)\n",
                        "  Downloading googleapis_common_protos-1.69.2-py3-none-any.whl.metadata (9.3 kB)\n",
                        "Collecting opentelemetry-exporter-otlp-proto-common==1.31.0 (from opentelemetry-exporter-otlp-proto-http<2.0.0,>=1.22.0->promptflow-devkit>=1.17.1->azure-ai-evaluation)\n",
                        "  Downloading opentelemetry_exporter_otlp_proto_common-1.31.0-py3-none-any.whl.metadata (1.9 kB)\n",
                        "Collecting opentelemetry-proto==1.31.0 (from opentelemetry-exporter-otlp-proto-http<2.0.0,>=1.22.0->promptflow-devkit>=1.17.1->azure-ai-evaluation)\n",
                        "  Downloading opentelemetry_proto-1.31.0-py3-none-any.whl.metadata (2.4 kB)\n",
                        "Collecting protobuf<6.0,>=5.0 (from opentelemetry-proto==1.31.0->opentelemetry-exporter-otlp-proto-http<2.0.0,>=1.22.0->promptflow-devkit>=1.17.1->azure-ai-evaluation)\n",
                        "  Downloading protobuf-5.29.3-cp38-abi3-manylinux2014_aarch64.whl.metadata (592 bytes)\n",
                        "Collecting charset-normalizer<4,>=2 (from requests>=2.21.0->azure-core>=1.30.2->azure-ai-evaluation)\n",
                        "  Downloading charset_normalizer-3.4.1-cp311-cp311-manylinux_2_17_aarch64.manylinux2014_aarch64.whl.metadata (35 kB)\n",
                        "Collecting urllib3<3,>=1.21.1 (from requests>=2.21.0->azure-core>=1.30.2->azure-ai-evaluation)\n",
                        "  Downloading urllib3-2.3.0-py3-none-any.whl.metadata (6.5 kB)\n",
                        "Collecting ruamel.yaml.clib>=0.2.7 (from ruamel.yaml<1.0.0,>=0.17.10->promptflow-core>=1.17.1->azure-ai-evaluation)\n",
                        "  Downloading ruamel.yaml.clib-0.2.12-cp311-cp311-manylinux2014_aarch64.whl.metadata (2.7 kB)\n",
                        "Collecting greenlet!=0.4.17 (from sqlalchemy<3.0.0,>=1.4.48->promptflow-devkit>=1.17.1->azure-ai-evaluation)\n",
                        "  Downloading greenlet-3.1.1-cp311-cp311-manylinux_2_17_aarch64.manylinux2014_aarch64.whl.metadata (3.8 kB)\n",
                        "Collecting pycparser (from cffi>=1.12->cryptography>=2.5->azure-identity>=1.16.0->azure-ai-evaluation)\n",
                        "  Downloading pycparser-2.22-py3-none-any.whl.metadata (943 bytes)\n",
                        "Collecting wrapt<2,>=1.10 (from deprecated>=1.2.6->opentelemetry-exporter-otlp-proto-http<2.0.0,>=1.22.0->promptflow-devkit>=1.17.1->azure-ai-evaluation)\n",
                        "  Downloading wrapt-1.17.2-cp311-cp311-manylinux_2_17_aarch64.manylinux2014_aarch64.whl.metadata (6.4 kB)\n",
                        "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.11/site-packages (from gitdb<5,>=4.0.1->gitpython<4.0.0,>=3.1.24->promptflow-devkit>=1.17.1->azure-ai-evaluation) (5.0.1)\n",
                        "Collecting zipp>=3.20 (from importlib-metadata>=4.11.4->keyring<25.0.0,>=24.2.0->promptflow-devkit>=1.17.1->azure-ai-evaluation)\n",
                        "  Downloading zipp-3.21.0-py3-none-any.whl.metadata (3.7 kB)\n",
                        "Collecting MarkupSafe>=2.0 (from Jinja2>=3.1.2->flask<4.0.0,>=2.2.3->promptflow-core>=1.17.1->azure-ai-evaluation)\n",
                        "  Downloading MarkupSafe-3.0.2-cp311-cp311-manylinux_2_17_aarch64.manylinux2014_aarch64.whl.metadata (4.0 kB)\n",
                        "Collecting requests-oauthlib>=0.5.0 (from msrest>=0.6.10->azure-monitor-opentelemetry-exporter<2.0.0,>=1.0.0b21->promptflow-devkit>=1.17.1->azure-ai-evaluation)\n",
                        "  Downloading requests_oauthlib-2.0.0-py2.py3-none-any.whl.metadata (11 kB)\n",
                        "Collecting opentelemetry-semantic-conventions==0.52b0 (from opentelemetry-sdk<2.0.0,>=1.22.0->promptflow-tracing==1.17.2->promptflow-core>=1.17.1->azure-ai-evaluation)\n",
                        "  Downloading opentelemetry_semantic_conventions-0.52b0-py3-none-any.whl.metadata (2.5 kB)\n",
                        "Collecting more-itertools (from jaraco.classes->keyring<25.0.0,>=24.2.0->promptflow-devkit>=1.17.1->azure-ai-evaluation)\n",
                        "  Downloading more_itertools-10.6.0-py3-none-any.whl.metadata (37 kB)\n",
                        "Collecting oauthlib>=3.0.0 (from requests-oauthlib>=0.5.0->msrest>=0.6.10->azure-monitor-opentelemetry-exporter<2.0.0,>=1.0.0b21->promptflow-devkit>=1.17.1->azure-ai-evaluation)\n",
                        "  Downloading oauthlib-3.2.2-py3-none-any.whl.metadata (7.5 kB)\n",
                        "Downloading azure_ai_evaluation-1.3.0-py3-none-any.whl (583 kB)\n",
                        "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m583.8/583.8 kB\u001b[0m \u001b[31m30.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
                        "\u001b[?25hDownloading azure_core-1.32.0-py3-none-any.whl (198 kB)\n",
                        "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m198.9/198.9 kB\u001b[0m \u001b[31m34.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
                        "\u001b[?25hDownloading azure_identity-1.21.0-py3-none-any.whl (189 kB)\n",
                        "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m189.2/189.2 kB\u001b[0m \u001b[31m35.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
                        "\u001b[?25hDownloading azure_storage_blob-12.25.0-py3-none-any.whl (406 kB)\n",
                        "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m406.9/406.9 kB\u001b[0m \u001b[31m58.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
                        "\u001b[?25hDownloading nltk-3.9.1-py3-none-any.whl (1.5 MB)\n",
                        "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.5/1.5 MB\u001b[0m \u001b[31m76.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
                        "\u001b[?25hDownloading promptflow_core-1.17.2-py3-none-any.whl (987 kB)\n",
                        "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m987.9/987.9 kB\u001b[0m \u001b[31m64.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
                        "\u001b[?25hDownloading promptflow_tracing-1.17.2-py3-none-any.whl (26 kB)\n",
                        "Downloading promptflow_devkit-1.17.2-py3-none-any.whl (7.0 MB)\n",
                        "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.0/7.0 MB\u001b[0m \u001b[31m91.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
                        "\u001b[?25hDownloading pillow-11.0.0-cp311-cp311-manylinux_2_28_aarch64.whl (4.2 MB)\n",
                        "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.2/4.2 MB\u001b[0m \u001b[31m84.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
                        "\u001b[?25hDownloading PyJWT-2.10.1-py3-none-any.whl (22 kB)\n",
                        "Downloading argcomplete-3.6.0-py3-none-any.whl (43 kB)\n",
                        "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.8/43.8 kB\u001b[0m \u001b[31m16.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
                        "\u001b[?25hDownloading azure_monitor_opentelemetry_exporter-1.0.0b35-py2.py3-none-any.whl (153 kB)\n",
                        "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m153.3/153.3 kB\u001b[0m \u001b[31m68.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
                        "\u001b[?25hDownloading fixedint-0.1.6-py3-none-any.whl (12 kB)\n",
                        "Downloading colorama-0.4.6-py2.py3-none-any.whl (25 kB)\n",
                        "Downloading cryptography-44.0.2-cp39-abi3-manylinux_2_28_aarch64.whl (4.0 MB)\n",
                        "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.0/4.0 MB\u001b[0m \u001b[31m98.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
                        "\u001b[?25hDownloading fastapi-0.115.11-py3-none-any.whl (94 kB)\n",
                        "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m94.9/94.9 kB\u001b[0m \u001b[31m49.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
                        "\u001b[?25hDownloading filelock-3.18.0-py3-none-any.whl (16 kB)\n",
                        "Downloading filetype-1.2.0-py2.py3-none-any.whl (19 kB)\n",
                        "Downloading flask-3.1.0-py3-none-any.whl (102 kB)\n",
                        "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m103.0/103.0 kB\u001b[0m \u001b[31m39.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
                        "\u001b[?25hDownloading click-8.1.8-py3-none-any.whl (98 kB)\n",
                        "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m98.2/98.2 kB\u001b[0m \u001b[31m37.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
                        "\u001b[?25hDownloading flask_cors-5.0.1-py3-none-any.whl (11 kB)\n",
                        "Downloading flask_restx-1.3.0-py2.py3-none-any.whl (2.8 MB)\n",
                        "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.8/2.8 MB\u001b[0m \u001b[31m96.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
                        "\u001b[?25hDownloading isodate-0.7.2-py3-none-any.whl (22 kB)\n",
                        "Downloading jsonschema-4.23.0-py3-none-any.whl (88 kB)\n",
                        "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m88.5/88.5 kB\u001b[0m \u001b[31m42.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
                        "\u001b[?25hDownloading keyring-24.3.1-py3-none-any.whl (38 kB)\n",
                        "Downloading marshmallow-3.26.1-py3-none-any.whl (50 kB)\n",
                        "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.9/50.9 kB\u001b[0m \u001b[31m22.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
                        "\u001b[?25hDownloading msal-1.32.0-py3-none-any.whl (114 kB)\n",
                        "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m114.7/114.7 kB\u001b[0m \u001b[31m42.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
                        "\u001b[?25hDownloading msal_extensions-1.3.1-py3-none-any.whl (20 kB)\n",
                        "Downloading opentelemetry_exporter_otlp_proto_http-1.31.0-py3-none-any.whl (17 kB)\n",
                        "Downloading opentelemetry_exporter_otlp_proto_common-1.31.0-py3-none-any.whl (18 kB)\n",
                        "Downloading opentelemetry_proto-1.31.0-py3-none-any.whl (55 kB)\n",
                        "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m55.9/55.9 kB\u001b[0m \u001b[31m23.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
                        "\u001b[?25hDownloading psutil-6.1.1-cp36-abi3-manylinux_2_17_aarch64.manylinux2014_aarch64.whl (289 kB)\n",
                        "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m289.0/289.0 kB\u001b[0m \u001b[31m59.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
                        "\u001b[?25hDownloading pydash-7.0.7-py3-none-any.whl (110 kB)\n",
                        "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m110.3/110.3 kB\u001b[0m \u001b[31m30.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
                        "\u001b[?25hDownloading regex-2024.11.6-cp311-cp311-manylinux_2_17_aarch64.manylinux2014_aarch64.whl (792 kB)\n",
                        "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m792.1/792.1 kB\u001b[0m \u001b[31m89.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
                        "\u001b[?25hDownloading requests-2.32.3-py3-none-any.whl (64 kB)\n",
                        "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m64.9/64.9 kB\u001b[0m \u001b[31m15.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
                        "\u001b[?25hDownloading ruamel.yaml-0.18.10-py3-none-any.whl (117 kB)\n",
                        "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m117.7/117.7 kB\u001b[0m \u001b[31m33.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
                        "\u001b[?25hDownloading sqlalchemy-2.0.39-cp311-cp311-manylinux_2_17_aarch64.manylinux2014_aarch64.whl (3.2 MB)\n",
                        "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.2/3.2 MB\u001b[0m \u001b[31m93.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
                        "\u001b[?25hDownloading strictyaml-1.7.3-py3-none-any.whl (123 kB)\n",
                        "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m123.9/123.9 kB\u001b[0m \u001b[31m34.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
                        "\u001b[?25hDownloading tabulate-0.9.0-py3-none-any.whl (35 kB)\n",
                        "Downloading waitress-3.0.2-py3-none-any.whl (56 kB)\n",
                        "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.2/56.2 kB\u001b[0m \u001b[31m14.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
                        "\u001b[?25hDownloading docstring_parser-0.16-py3-none-any.whl (36 kB)\n",
                        "Downloading joblib-1.4.2-py3-none-any.whl (301 kB)\n",
                        "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m301.8/301.8 kB\u001b[0m \u001b[31m80.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
                        "\u001b[?25hDownloading aniso8601-10.0.0-py2.py3-none-any.whl (52 kB)\n",
                        "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m52.8/52.8 kB\u001b[0m \u001b[31m20.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
                        "\u001b[?25hDownloading attrs-25.3.0-py3-none-any.whl (63 kB)\n",
                        "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.8/63.8 kB\u001b[0m \u001b[31m20.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
                        "\u001b[?25hDownloading blinker-1.9.0-py3-none-any.whl (8.5 kB)\n",
                        "Downloading cffi-1.17.1-cp311-cp311-manylinux_2_17_aarch64.manylinux2014_aarch64.whl (469 kB)\n",
                        "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m469.2/469.2 kB\u001b[0m \u001b[31m62.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
                        "\u001b[?25hDownloading charset_normalizer-3.4.1-cp311-cp311-manylinux_2_17_aarch64.manylinux2014_aarch64.whl (139 kB)\n",
                        "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m139.5/139.5 kB\u001b[0m \u001b[31m32.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
                        "\u001b[?25hDownloading Deprecated-1.2.18-py2.py3-none-any.whl (10.0 kB)\n",
                        "Downloading googleapis_common_protos-1.69.2-py3-none-any.whl (293 kB)\n",
                        "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m293.2/293.2 kB\u001b[0m \u001b[31m47.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
                        "\u001b[?25hDownloading greenlet-3.1.1-cp311-cp311-manylinux_2_17_aarch64.manylinux2014_aarch64.whl (640 kB)\n",
                        "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m640.4/640.4 kB\u001b[0m \u001b[31m61.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
                        "\u001b[?25hDownloading importlib_metadata-8.6.1-py3-none-any.whl (26 kB)\n",
                        "Downloading itsdangerous-2.2.0-py3-none-any.whl (16 kB)\n",
                        "Downloading jeepney-0.9.0-py3-none-any.whl (49 kB)\n",
                        "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.0/49.0 kB\u001b[0m \u001b[31m8.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
                        "\u001b[?25hDownloading jinja2-3.1.6-py3-none-any.whl (134 kB)\n",
                        "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.9/134.9 kB\u001b[0m \u001b[31m19.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
                        "\u001b[?25hDownloading jsonschema_specifications-2024.10.1-py3-none-any.whl (18 kB)\n",
                        "Downloading msrest-0.7.1-py3-none-any.whl (85 kB)\n",
                        "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m85.4/85.4 kB\u001b[0m \u001b[31m11.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
                        "\u001b[?25hDownloading opentelemetry_api-1.31.0-py3-none-any.whl (65 kB)\n",
                        "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m65.1/65.1 kB\u001b[0m \u001b[31m8.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
                        "\u001b[?25hDownloading opentelemetry_sdk-1.31.0-py3-none-any.whl (118 kB)\n",
                        "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m118.9/118.9 kB\u001b[0m \u001b[31m17.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
                        "\u001b[?25hDownloading opentelemetry_semantic_conventions-0.52b0-py3-none-any.whl (183 kB)\n",
                        "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m183.4/183.4 kB\u001b[0m \u001b[31m26.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
                        "\u001b[?25hDownloading referencing-0.36.2-py3-none-any.whl (26 kB)\n",
                        "Downloading rpds_py-0.23.1-cp311-cp311-manylinux_2_17_aarch64.manylinux2014_aarch64.whl (385 kB)\n",
                        "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m385.6/385.6 kB\u001b[0m \u001b[31m51.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
                        "\u001b[?25hDownloading ruamel.yaml.clib-0.2.12-cp311-cp311-manylinux2014_aarch64.whl (641 kB)\n",
                        "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m641.5/641.5 kB\u001b[0m \u001b[31m53.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
                        "\u001b[?25hDownloading SecretStorage-3.3.3-py3-none-any.whl (15 kB)\n",
                        "Downloading starlette-0.46.1-py3-none-any.whl (71 kB)\n",
                        "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m72.0/72.0 kB\u001b[0m \u001b[31m6.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
                        "\u001b[?25hDownloading tiktoken-0.9.0-cp311-cp311-manylinux_2_17_aarch64.manylinux2014_aarch64.whl (1.1 MB)\n",
                        "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m83.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
                        "\u001b[?25hDownloading urllib3-2.3.0-py3-none-any.whl (128 kB)\n",
                        "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m128.4/128.4 kB\u001b[0m \u001b[31m19.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
                        "\u001b[?25hDownloading werkzeug-3.1.3-py3-none-any.whl (224 kB)\n",
                        "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m224.5/224.5 kB\u001b[0m \u001b[31m34.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
                        "\u001b[?25hDownloading importlib_resources-6.5.2-py3-none-any.whl (37 kB)\n",
                        "Downloading jaraco.classes-3.4.0-py3-none-any.whl (6.8 kB)\n",
                        "Downloading MarkupSafe-3.0.2-cp311-cp311-manylinux_2_17_aarch64.manylinux2014_aarch64.whl (23 kB)\n",
                        "Downloading protobuf-5.29.3-cp38-abi3-manylinux2014_aarch64.whl (319 kB)\n",
                        "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m319.6/319.6 kB\u001b[0m \u001b[31m52.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
                        "\u001b[?25hDownloading requests_oauthlib-2.0.0-py2.py3-none-any.whl (24 kB)\n",
                        "Downloading wrapt-1.17.2-cp311-cp311-manylinux_2_17_aarch64.manylinux2014_aarch64.whl (83 kB)\n",
                        "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m83.8/83.8 kB\u001b[0m \u001b[31m12.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
                        "\u001b[?25hDownloading zipp-3.21.0-py3-none-any.whl (9.6 kB)\n",
                        "Downloading more_itertools-10.6.0-py3-none-any.whl (63 kB)\n",
                        "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.0/63.0 kB\u001b[0m \u001b[31m12.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
                        "\u001b[?25hDownloading pycparser-2.22-py3-none-any.whl (117 kB)\n",
                        "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m117.6/117.6 kB\u001b[0m \u001b[31m18.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
                        "\u001b[?25hDownloading oauthlib-3.2.2-py3-none-any.whl (151 kB)\n",
                        "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m151.7/151.7 kB\u001b[0m \u001b[31m21.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
                        "\u001b[?25hInstalling collected packages: fixedint, filetype, aniso8601, zipp, wrapt, waitress, urllib3, tabulate, ruamel.yaml.clib, rpds-py, regex, pyjwt, pydash, pycparser, psutil, protobuf, pillow, oauthlib, more-itertools, marshmallow, MarkupSafe, joblib, jeepney, itsdangerous, isodate, importlib-resources, greenlet, filelock, docstring_parser, colorama, click, charset-normalizer, blinker, attrs, argcomplete, Werkzeug, strictyaml, starlette, sqlalchemy, ruamel.yaml, requests, referencing, opentelemetry-proto, nltk, Jinja2, jaraco.classes, importlib-metadata, googleapis-common-protos, deprecated, cffi, tiktoken, requests-oauthlib, opentelemetry-exporter-otlp-proto-common, opentelemetry-api, jsonschema-specifications, flask, fastapi, cryptography, azure-core, SecretStorage, opentelemetry-semantic-conventions, msrest, jsonschema, flask-cors, azure-storage-blob, opentelemetry-sdk, msal, keyring, flask-restx, promptflow-tracing, opentelemetry-exporter-otlp-proto-http, msal-extensions, azure-monitor-opentelemetry-exporter, promptflow-core, azure-identity, promptflow-devkit, azure-ai-evaluation\n",
                        "  Attempting uninstall: psutil\n",
                        "    Found existing installation: psutil 7.0.0\n",
                        "    Uninstalling psutil-7.0.0:\n",
                        "      Successfully uninstalled psutil-7.0.0\n",
                        "  Attempting uninstall: pillow\n",
                        "    Found existing installation: pillow 11.1.0\n",
                        "    Uninstalling pillow-11.1.0:\n",
                        "      Successfully uninstalled pillow-11.1.0\n",
                        "Successfully installed Jinja2-3.1.6 MarkupSafe-3.0.2 SecretStorage-3.3.3 Werkzeug-3.1.3 aniso8601-10.0.0 argcomplete-3.6.0 attrs-25.3.0 azure-ai-evaluation-1.3.0 azure-core-1.32.0 azure-identity-1.21.0 azure-monitor-opentelemetry-exporter-1.0.0b35 azure-storage-blob-12.25.0 blinker-1.9.0 cffi-1.17.1 charset-normalizer-3.4.1 click-8.1.8 colorama-0.4.6 cryptography-44.0.2 deprecated-1.2.18 docstring_parser-0.16 fastapi-0.115.11 filelock-3.18.0 filetype-1.2.0 fixedint-0.1.6 flask-3.1.0 flask-cors-5.0.1 flask-restx-1.3.0 googleapis-common-protos-1.69.2 greenlet-3.1.1 importlib-metadata-8.6.1 importlib-resources-6.5.2 isodate-0.7.2 itsdangerous-2.2.0 jaraco.classes-3.4.0 jeepney-0.9.0 joblib-1.4.2 jsonschema-4.23.0 jsonschema-specifications-2024.10.1 keyring-24.3.1 marshmallow-3.26.1 more-itertools-10.6.0 msal-1.32.0 msal-extensions-1.3.1 msrest-0.7.1 nltk-3.9.1 oauthlib-3.2.2 opentelemetry-api-1.31.0 opentelemetry-exporter-otlp-proto-common-1.31.0 opentelemetry-exporter-otlp-proto-http-1.31.0 opentelemetry-proto-1.31.0 opentelemetry-sdk-1.31.0 opentelemetry-semantic-conventions-0.52b0 pillow-11.0.0 promptflow-core-1.17.2 promptflow-devkit-1.17.2 promptflow-tracing-1.17.2 protobuf-5.29.3 psutil-6.1.1 pycparser-2.22 pydash-7.0.7 pyjwt-2.10.1 referencing-0.36.2 regex-2024.11.6 requests-2.32.3 requests-oauthlib-2.0.0 rpds-py-0.23.1 ruamel.yaml-0.18.10 ruamel.yaml.clib-0.2.12 sqlalchemy-2.0.39 starlette-0.46.1 strictyaml-1.7.3 tabulate-0.9.0 tiktoken-0.9.0 urllib3-2.3.0 waitress-3.0.2 wrapt-1.17.2 zipp-3.21.0\n",
                        "\n",
                        "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.0\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.0.1\u001b[0m\n",
                        "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
                    ]
                }
            ],
            "source": [
                "!pip install openai python-dotenv numpy pandas matplotlib azure-ai-evaluation"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 21,
            "id": "3b56e405",
            "metadata": {},
            "outputs": [],
            "source": [
                "import os\n",
                "import json\n",
                "import pandas as pd\n",
                "import numpy as np\n",
                "import matplotlib.pyplot as plt\n",
                "from dotenv import load_dotenv\n",
                "from openai import AsyncAzureOpenAI\n",
                "\n",
                "# Load environment variables\n",
                "load_dotenv()\n",
                "\n",
                "# Set up AsyncOpenAI client with Azure credentials\n",
                "client = AsyncAzureOpenAI(\n",
                "    azure_endpoint=os.getenv('AZURE_OPENAI_ENDPOINT'),\n",
                "    azure_deployment=os.getenv('AZURE_OPENAI_DEPLOYMENT'),\n",
                "    api_key=os.getenv('AZURE_OPENAI_KEY'),\n",
                "    api_version = \"2024-12-01-preview\"\n",
                ")"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "bf0bc912",
            "metadata": {},
            "source": [
                "## 3. Interactive Prompt Development\n",
                "\n",
                "Let's set up a function to test our prompts interactively:"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 22,
            "id": "7ce2585b",
            "metadata": {},
            "outputs": [],
            "source": [
                "async def get_completion(prompt, system_prompt=\"You are a helpful assistant.\", temperature=0.7):\n",
                "    \"\"\"Get a completion from the OpenAI API\"\"\"\n",
                "    response = await client.chat.completions.create(\n",
                "        model=\"gpt-4o-mini\",  # You can change this to your preferred model\n",
                "        messages=[\n",
                "            {\"role\": \"system\", \"content\": system_prompt},\n",
                "            {\"role\": \"user\", \"content\": prompt}\n",
                "        ],\n",
                "        temperature=temperature,\n",
                "    )\n",
                "    return response.choices[0].message.content"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "79f3d3f9",
            "metadata": {},
            "source": [
                "## 4. Prompt Scenarios: Research Assistant\n",
                "\n",
                "Let's create a prompt for a research assistant that summarizes academic papers:"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 23,
            "id": "ba1b0ec6",
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "==== BASIC PROMPT SUMMARY ====\n",
                        "\n",
                        "The research paper titled \"Deep Reinforcement Learning for Autonomous Driving: A Survey\" by B. R. Kiran et al. provides an in-depth overview of the application of deep reinforcement learning (DRL) in the field of autonomous driving. The authors highlight the significant advancements in perception tasks, such as object detection and semantic segmentation, but emphasize that safe and reliable autonomous driving systems still face challenges, particularly in complex decision-making scenarios.\n",
                        "\n",
                        "The paper begins by explaining the fundamentals of DRL, including concepts like Markov decision processes, deep Q-networks, policy gradient methods, and actor-critic approaches. It categorizes existing literature based on specific driving tasks, such as lane keeping, intersection navigation, and highway merging. Additionally, the authors review various training methodologies, including simulation-based training, real-world training, and transfer learning.\n",
                        "\n",
                        "The survey also addresses critical challenges in applying DRL to autonomous driving, including the need for safety guarantees, explainability of the decision-making process, and improving data efficiency. The paper concludes by outlining future research directions to enhance the effectiveness and reliability of DRL in the context of autonomous vehicles, reinforcing the potential of this approach to transform transportation systems.\n",
                        "\n",
                        "\n",
                        "==== ENGINEERED PROMPT SUMMARY ====\n",
                        "\n",
                        "# Structured Summary of the Research Paper\n",
                        "\n",
                        "## Core Research Question/Objective\n",
                        "The paper aims to survey the application of deep reinforcement learning (DRL) in the field of autonomous driving, focusing on the techniques, challenges, and potential advancements in decision-making for autonomous vehicles.\n",
                        "\n",
                        "## Key Methodologies Used\n",
                        "- Comprehensive review of foundational DRL concepts, including Markov decision processes, deep Q-networks, policy gradient methods, and actor-critic approaches.\n",
                        "- Categorization of existing literature based on specific autonomous driving tasks such as lane keeping, intersection navigation, and highway merging.\n",
                        "- Examination of various training approaches like simulation-based training, real-world training, and transfer learning.\n",
                        "\n",
                        "## Main Contributions/Findings\n",
                        "- Identification of the strengths of DRL in addressing complex decision-making tasks in autonomous driving, highlighting its capacity for learning from experience.\n",
                        "- Classification of existing DRL methods according to their application in autonomous driving tasks, revealing the diversity and specialization of approaches taken in the literature.\n",
                        "- Discussion of key challenges in deploying DRL for autonomous driving, including safety guarantees, explainability, and data efficiency, which need to be addressed for practical applications.\n",
                        "- Insight into the importance of combining perception and decision-making capabilities for the development of reliable autonomous driving systems.\n",
                        "\n",
                        "## Limitations or Challenges Mentioned\n",
                        "- The challenge of ensuring safety guarantees in DRL-based systems, which is critical for real-world deployment.\n",
                        "- Issues related to the explainability of DRL models, making it difficult for developers to understand and trust the decision-making processes of autonomous vehicles.\n",
                        "\n",
                        "## Potential Applications and Future Work\n",
                        "The findings indicate that DRL can significantly enhance the decision-making capabilities of autonomous vehicles in various driving scenarios. Future work should focus on improving safety and explainability in DRL systems, as well as exploring more efficient data utilization strategies to facilitate real-world applications.\n"
                    ]
                }
            ],
            "source": [
                "research_paper = \"\"\"\n",
                "Title: Deep Reinforcement Learning for Autonomous Driving: A Survey\n",
                "Authors: B. R. Kiran, I. Sobh, V. Talpaert, P. Mannion, A. A. Al Sallab, S. Yogamani, P. Pérez\n",
                "\n",
                "Abstract: The field of autonomous driving has seen substantial progress in recent years, largely due to advances in deep learning for perception tasks such as object detection and semantic segmentation. However, designing a reliable autonomous driving system that can operate safely in all conditions remains a challenge. Deep reinforcement learning (DRL) offers a promising framework for addressing complex decision-making tasks in autonomous driving, as it allows systems to learn from experience and improve over time. In this paper, we provide a comprehensive survey of DRL methods applied to autonomous driving. We begin by covering the fundamentals of DRL, including Markov decision processes, deep Q-networks, policy gradient methods, and actor-critic approaches. We then categorize existing literature based on the specific autonomous driving tasks being addressed, such as lane keeping, intersection navigation, and highway merging. We also examine different training approaches, including simulation-based training, real-world training, and transfer learning. Finally, we discuss key challenges and future research directions in applying DRL to autonomous driving, such as safety guarantees, explainability, and data efficiency.\n",
                "\n",
                "Introduction:\n",
                "Autonomous driving has emerged as one of the most challenging and impactful applications of artificial intelligence and robotics. The development of fully autonomous vehicles promises to revolutionize transportation by improving safety, reducing congestion, and enhancing mobility for all. While significant progress has been made in perception systems for autonomous driving, decision-making remains a critical challenge, especially in complex, dynamic environments with multiple actors.\n",
                "\n",
                "Deep reinforcement learning (DRL) has shown remarkable success in domains requiring sequential decision-making, such as game playing and robotic control. DRL combines the representation learning capabilities of deep neural networks with the trial-and-error learning paradigm of reinforcement learning, allowing systems to learn complex behaviors through interaction with their environment. This makes DRL particularly well-suited for autonomous driving, where vehicles must make a sequence of decisions based on high-dimensional sensory inputs and learn from the consequences of those decisions.\n",
                "\"\"\"\n",
                "\n",
                "# Basic prompt without engineering techniques\n",
                "basic_prompt = f\"Summarize this research paper: {research_paper}\"\n",
                "\n",
                "# Engineered prompt using best practices\n",
                "engineered_prompt = f\"\"\"\n",
                "You are a research assistant helping a computer science professor understand recent publications in AI. \n",
                "\n",
                "Please analyze the following research paper and create a structured summary with these components:\n",
                "1. Core research question/objective (1-2 sentences)\n",
                "2. Key methodologies used (2-3 bullet points)\n",
                "3. Main contributions/findings (3-4 bullet points)\n",
                "4. Limitations or challenges mentioned (1-2 bullet points)\n",
                "5. Potential applications and future work (1-2 sentences)\n",
                "\n",
                "Format your response with clear headings and concise language suitable for an academic audience familiar with AI concepts but not specialized in this particular subdomain.\n",
                "\n",
                "PAPER TO SUMMARIZE:\n",
                "{research_paper}\n",
                "\"\"\"\n",
                "\n",
                "# Get completions\n",
                "basic_summary = await get_completion(basic_prompt)\n",
                "engineered_summary = await get_completion(engineered_prompt)\n",
                "\n",
                "print(\"==== BASIC PROMPT SUMMARY ====\\n\")\n",
                "print(basic_summary)\n",
                "print(\"\\n\\n==== ENGINEERED PROMPT SUMMARY ====\\n\")\n",
                "print(engineered_summary)"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "dd51ea23",
            "metadata": {},
            "source": [
                "## 5. Few-Shot Learning Example: Code Reviewer\n",
                "\n",
                "Next, let's create a code reviewer prompt using few-shot examples:"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 29,
            "id": "7a7c32b0",
            "metadata": {},
            "outputs": [],
            "source": [
                "code_to_review = \"\"\"\n",
                "def calculate_average(numbers):\n",
                "    total = 0\n",
                "    for num in numbers:\n",
                "        total += num\n",
                "    return total / len(numbers)\n",
                "\n",
                "def find_max(numbers):\n",
                "    max_val = numbers[0]\n",
                "    for num in numbers:\n",
                "        if num > max_val:\n",
                "            max_val = num\n",
                "    return max_val\n",
                "\n",
                "def process_data(data):\n",
                "    results = []\n",
                "    for item in data:\n",
                "        if len(item) > 0:\n",
                "            results.append(calculate_average(item))\n",
                "        else:\n",
                "            results.append(0)\n",
                "    return results\n",
                "\"\"\""
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 30,
            "id": "1e531588",
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "REVIEW:\n",
                        "\n",
                        "### `calculate_average(numbers)`\n",
                        "\n",
                        "✅ Good: The function has a clear purpose and is straightforward.\n",
                        "\n",
                        "❌ Issue: No error handling for empty lists - this will raise a `ZeroDivisionError`.\n",
                        "\n",
                        "⚠️ Improvement: Missing type hints and docstring.\n",
                        "\n",
                        "Suggested rewrite:\n",
                        "```python\n",
                        "def calculate_average(numbers: list) -> float:\n",
                        "    \"\"\"Calculate the average of a list of numbers.\n",
                        "\n",
                        "    Args:\n",
                        "        numbers: A list of numeric values.\n",
                        "\n",
                        "    Returns:\n",
                        "        The average of the numbers in the list.\n",
                        "\n",
                        "    Raises:\n",
                        "        ValueError: If the input list is empty.\n",
                        "    \"\"\"\n",
                        "    if not numbers:\n",
                        "        raise ValueError(\"The input list must not be empty\")\n",
                        "\n",
                        "    total = sum(numbers)\n",
                        "    return total / len(numbers)\n",
                        "```\n",
                        "\n",
                        "### `find_max(numbers)`\n",
                        "\n",
                        "✅ Good: The function has a clear purpose and correctly identifies the maximum value.\n",
                        "\n",
                        "❌ Issue: No error handling for empty lists - this will raise an `IndexError`.\n",
                        "\n",
                        "⚠️ Improvement: Missing type hints and docstring.\n",
                        "\n",
                        "Suggested rewrite:\n",
                        "```python\n",
                        "def find_max(numbers: list) -> float:\n",
                        "    \"\"\"Find the maximum value in a list of numbers.\n",
                        "\n",
                        "    Args:\n",
                        "        numbers: A list of numeric values.\n",
                        "\n",
                        "    Returns:\n",
                        "        The maximum value in the list.\n",
                        "\n",
                        "    Raises:\n",
                        "        ValueError: If the input list is empty.\n",
                        "    \"\"\"\n",
                        "    if not numbers:\n",
                        "        raise ValueError(\"The input list must not be empty\")\n",
                        "\n",
                        "    max_val = numbers[0]\n",
                        "    for num in numbers:\n",
                        "        if num > max_val:\n",
                        "            max_val = num\n",
                        "    return max_val\n",
                        "```\n",
                        "\n",
                        "### `process_data(data)`\n",
                        "\n",
                        "✅ Good: The function processes a list of data and handles empty sublists.\n",
                        "\n",
                        "⚠️ Improvement: Missing type hints and docstring. The function could also benefit from a more explicit handling of the input type (e.g., list of lists).\n",
                        "\n",
                        "⚠️ Improvement: Instead of appending `0` for empty items, consider using `None` or skipping them, depending on the intended behavior.\n",
                        "\n",
                        "Suggested rewrite:\n",
                        "```python\n",
                        "def process_data(data: list[list[float]]) -> list[float]:\n",
                        "    \"\"\"Process a list of lists, calculating the average for each non-empty sublist.\n",
                        "\n",
                        "    Args:\n",
                        "        data: A list of lists containing numeric values.\n",
                        "\n",
                        "    Returns:\n",
                        "        A list of averages for each non-empty sublist, or None for empty sublists.\n",
                        "    \"\"\"\n",
                        "    results = []\n",
                        "    for item in data:\n",
                        "        if item:\n",
                        "            results.append(calculate_average(item))\n",
                        "        else:\n",
                        "            results.append(None)  # or continue to skip empty items\n",
                        "    return results\n",
                        "```\n",
                        "\n",
                        "### General Comments\n",
                        "- Overall, the functions have clear purposes, but they lack robustness due to missing error handling for edge cases (like empty lists).\n",
                        "- Adding type hints and docstrings will improve readability and usability, making it clear what the functions expect and return. \n",
                        "- Consider using built-in functions like `sum()` for better readability and performance in `calculate_average`.\n"
                    ]
                }
            ],
            "source": [
                "# Few-shot code review prompt\n",
                "code_review_prompt = r\"\"\"\n",
                "You are an expert code reviewer who provides constructive feedback on Python code. \n",
                "Your goal is to help developers improve code quality, readability, and robustness.\n",
                "\n",
                "Here are examples of the kind of reviews you provide:\n",
                "\n",
                "EXAMPLE 1:\n",
                "```python\n",
                "def add_numbers(a, b):\n",
                "    return a + b\n",
                "```\n",
                "REVIEW:\n",
                "✅ Good: Function is concise and has a clear purpose\n",
                "⚠️ Improvement: Missing input validation - what if non-numeric types are passed?\n",
                "⚠️ Improvement: Missing docstring explaining function purpose and parameters\n",
                "Suggested rewrite:\n",
                "```python\n",
                "def add_numbers(a: float, b: float) -> float:\n",
                "    \\\"\"\"Add two numbers and return the result.\n",
                "    \n",
                "    Args:\n",
                "        a: First number\n",
                "        b: Second number\n",
                "        \n",
                "    Returns:\n",
                "        Sum of the two input numbers\n",
                "    \\\"\"\"\n",
                "    if not (isinstance(a, (int, float)) and isinstance(b, (int, float))):\n",
                "        raise TypeError(\"Both inputs must be numeric types\")\n",
                "    return a + b\n",
                "```\n",
                "\n",
                "EXAMPLE 2:\n",
                "```python\n",
                "def get_user_info(user_id):\n",
                "    users = {1: {\"name\": \"Alice\", \"email\": \"alice@example.com\"},\n",
                "             2: {\"name\": \"Bob\", \"email\": \"bob@example.com\"}}\n",
                "    return users[user_id]\n",
                "```\n",
                "REVIEW:\n",
                "✅ Good: Function has a clear purpose\n",
                "❌ Issue: No error handling for missing user IDs\n",
                "❌ Issue: Hard-coded user data inside the function\n",
                "⚠️ Improvement: Missing type hints and docstring\n",
                "Suggested rewrite:\n",
                "```python\n",
                "def get_user_info(user_id: int, users: dict = None) -> dict:\n",
                "    \\\"\"\"Retrieve user information by user ID.\n",
                "    \n",
                "    Args:\n",
                "        user_id: The ID of the user to look up\n",
                "        users: Dictionary mapping user IDs to user data\n",
                "        \n",
                "    Returns:\n",
                "        Dictionary containing user information\n",
                "        \n",
                "    Raises:\n",
                "        KeyError: If the user_id is not found\n",
                "    \\\"\"\"\n",
                "    if users is None:\n",
                "        users = {1: {\"name\": \"Alice\", \"email\": \"alice@example.com\"},\n",
                "                 2: {\"name\": \"Bob\", \"email\": \"bob@example.com\"}}\n",
                "    try:\n",
                "        return users[user_id]\n",
                "    except KeyError:\n",
                "        raise KeyError(f\"User ID {user_id} not found\")\n",
                "```\n",
                "\n",
                "Now, please review the following Python code:\n",
                "\n",
                "```python\n",
                "\"\"\" + code_to_review + r\"\"\"\n",
                "```\n",
                "\n",
                "Provide a detailed code review following the format of the examples above.\n",
                "\"\"\"\n",
                "\n",
                "code_review = await get_completion(code_review_prompt)\n",
                "print(code_review)\n",
                "\n",
                "\n"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "e3ce26ac",
            "metadata": {},
            "source": [
                "## 6. Chain-of-Thought Prompting: Data Analysis\n",
                "\n",
                "Now let's explore chain-of-thought prompting for a data analysis task:"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 31,
            "id": "ee1cc2d2",
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "==== STANDARD ANALYSIS ====\n",
                        "\n",
                        "Based on the sales data provided for Products A, B, and C along with the marketing spend from January to June, several insights can be drawn:\n",
                        "\n",
                        "### Sales Trends\n",
                        "1. **Product A**: \n",
                        "   - Sales have shown a consistent upward trend over the six-month period, increasing from $120,000 in January to $142,000 in June. This represents an increase of approximately 18.3%.\n",
                        "   - The growth appears to be steady, with an average monthly increase of about $3,500.\n",
                        "\n",
                        "2. **Product B**:\n",
                        "   - Sales for Product B have fluctuated slightly, starting at $45,000 in January and ending at $53,000 in June. \n",
                        "   - The overall increase is about 17.8%, which is a slower growth rate compared to Product A.\n",
                        "   - The month-to-month changes are minimal, indicating that Product B may require more marketing efforts or a different strategy to boost sales.\n",
                        "\n",
                        "3. **Product C**:\n",
                        "   - Product C has experienced the most significant growth in sales, jumping from $32,000 in January to $85,000 in June, which is an increase of approximately 165.6%.\n",
                        "   - This product shows the highest potential and might be benefiting from increased marketing spend or consumer interest.\n",
                        "\n",
                        "### Marketing Spend Analysis\n",
                        "- **Monthly Marketing Spend**:\n",
                        "  - Marketing spend has generally increased over the months, from $15,000 in January to $32,000 in June.\n",
                        "  - There is a notable spike in marketing expenditure in April ($25,000) and May ($30,000), which correlates with the sales increase for Products A and C.\n",
                        "\n",
                        "- **Correlation Between Marketing and Sales**:\n",
                        "  - The increase in marketing spend appears to have a positive correlation with sales for Products A and C, suggesting that increased investment in marketing is effective.\n",
                        "  - For Product B, while the sales have increased, the growth is modest compared to Products A and C, indicating that marketing might not be as effective for this product or that additional factors are influencing its sales.\n",
                        "\n",
                        "### Recommendations\n",
                        "1. **Focus on Product C**:\n",
                        "   - Given the substantial growth in Product C's sales, it may be beneficial to further increase marketing investments or explore new marketing strategies to capitalize on this momentum.\n",
                        "\n",
                        "2. **Reassess Product B Strategies**:\n",
                        "   - Since Product B's sales growth is slower, a thorough analysis of its market positioning, pricing strategy, and target audience could uncover opportunities for improvement. Consider conducting customer feedback surveys to understand consumer needs better.\n",
                        "\n",
                        "3. **Continued Investment in Marketing**:\n",
                        "   - As the data shows a positive correlation between marketing spend and sales for Products A and C, maintaining or increasing the marketing budget could drive further growth.\n",
                        "   - Consider testing different marketing channels and campaigns to maximize the return on investment.\n",
                        "\n",
                        "4. **Monitor Monthly Performance**:\n",
                        "   - Continue to track sales performance and marketing spend closely on a monthly basis to identify trends and adjust strategies accordingly.\n",
                        "\n",
                        "### Conclusion\n",
                        "The sales data indicates a healthy upward trajectory for Products A and C, with Product C showing exceptional growth. Marketing spend appears to be a key driver of this success. Strategic adjustments, especially for Product B, could further enhance overall sales performance.\n",
                        "\n",
                        "\n",
                        "==== CHAIN-OF-THOUGHT ANALYSIS ====\n",
                        "\n",
                        "Let's analyze the sales data step by step.\n",
                        "\n",
                        "### Step 1: Calculate Total Sales for Each Product\n",
                        "\n",
                        "To find the total sales for each product over the 6-month period, we will sum the monthly sales for each product.\n",
                        "\n",
                        "- **Total Sales for Product A**: \n",
                        "  \\( 120,000 + 125,000 + 130,000 + 135,000 + 140,000 + 142,000 = 792,000 \\)\n",
                        "\n",
                        "- **Total Sales for Product B**: \n",
                        "  \\( 45,000 + 42,000 + 48,000 + 50,000 + 52,000 + 53,000 = 290,000 \\)\n",
                        "\n",
                        "- **Total Sales for Product C**: \n",
                        "  \\( 32,000 + 36,000 + 39,000 + 58,000 + 72,000 + 85,000 = 322,000 \\)\n",
                        "\n",
                        "**Total Sales Summary:**\n",
                        "- Product A: $792,000\n",
                        "- Product B: $290,000\n",
                        "- Product C: $322,000\n",
                        "\n",
                        "### Step 2: Calculate Month-over-Month Growth Rate\n",
                        "\n",
                        "To calculate the month-over-month growth rate, we will use the formula:\n",
                        "\\[\n",
                        "\\text{Growth Rate} = \\frac{\\text{Current Month Sales} - \\text{Previous Month Sales}}{\\text{Previous Month Sales}} \\times 100\n",
                        "\\]\n",
                        "\n",
                        "#### Product A Growth Rates:\n",
                        "- Feb: \\( \\frac{125,000 - 120,000}{120,000} \\times 100 = 4.17\\% \\)\n",
                        "- Mar: \\( \\frac{130,000 - 125,000}{125,000} \\times 100 = 4.00\\% \\)\n",
                        "- Apr: \\( \\frac{135,000 - 130,000}{130,000} \\times 100 = 3.85\\% \\)\n",
                        "- May: \\( \\frac{140,000 - 135,000}{135,000} \\times 100 = 3.70\\% \\)\n",
                        "- Jun: \\( \\frac{142,000 - 140,000}{140,000} \\times 100 = 1.43\\% \\)\n",
                        "\n",
                        "#### Product B Growth Rates:\n",
                        "- Feb: \\( \\frac{42,000 - 45,000}{45,000} \\times 100 = -6.67\\% \\)\n",
                        "- Mar: \\( \\frac{48,000 - 42,000}{42,000} \\times 100 = 14.29\\% \\)\n",
                        "- Apr: \\( \\frac{50,000 - 48,000}{48,000} \\times 100 = 4.17\\% \\)\n",
                        "- May: \\( \\frac{52,000 - 50,000}{50,000} \\times 100 = 4.00\\% \\)\n",
                        "- Jun: \\( \\frac{53,000 - 52,000}{52,000} \\times 100 = 1.92\\% \\)\n",
                        "\n",
                        "#### Product C Growth Rates:\n",
                        "- Feb: \\( \\frac{36,000 - 32,000}{32,000} \\times 100 = 12.50\\% \\)\n",
                        "- Mar: \\( \\frac{39,000 - 36,000}{36,000} \\times 100 = 8.33\\% \\)\n",
                        "- Apr: \\( \\frac{58,000 - 39,000}{39,000} \\times 100 = 48.72\\% \\)\n",
                        "- May: \\( \\frac{72,000 - 58,000}{58,000} \\times 100 = 24.14\\% \\)\n",
                        "- Jun: \\( \\frac{85,000 - 72,000}{72,000} \\times 100 = 18.06\\% \\)\n",
                        "\n",
                        "### Step 3: Analyze Correlation Between Marketing Spend and Sales\n",
                        "\n",
                        "To analyze the correlation, we will calculate the correlation coefficient between marketing spend and sales for each product using the formula for Pearson correlation. \n",
                        "\n",
                        "Here are the sales and marketing spend data arranged:\n",
                        "\n",
                        "| Month | Product A Sales | Product B Sales | Product C Sales | Marketing Spend |\n",
                        "|-------|-----------------|-----------------|-----------------|------------------|\n",
                        "| Jan   | 120,000         | 45,000          | 32,000          | 15,000           |\n",
                        "| Feb   | 125,000         | 42,000          | 36,000          | 15,000           |\n",
                        "| Mar   | 130,000         | 48,000          | 39,000          | 16,000           |\n",
                        "| Apr   | 135,000         | 50,000          | 58,000          | 25,000           |\n",
                        "| May   | 140,000         | 52,000          | 72,000          | 30,000           |\n",
                        "| Jun   | 142,000         | 53,000          | 85,000          | 32,000           |\n",
                        "\n",
                        "Using a statistical tool or software, we can calculate the correlation coefficients:\n",
                        "\n",
                        "- **Correlation for Product A**: Approximately \\(0.94\\)\n",
                        "- **Correlation for Product B**: Approximately \\(0.79\\)\n",
                        "- **Correlation for Product C**: Approximately \\(0.96\\)\n",
                        "\n",
                        "### Step 4: Compare Product Performance\n",
                        "\n",
                        "- **Sales Totals**: Product A leads with $792,000, followed by Product C with $322,000, and Product B with $290,000.\n",
                        "- **Growth Rates**: Product C shows the highest growth rates, especially in April (48.72%) and May (24.14%). Product A shows consistent growth but slows down in the last month. Product B has a mixed performance with a significant drop in February.\n",
                        "- **Correlation with Marketing Spend**: Product C has the highest correlation with marketing spend, suggesting that marketing efforts have a strong impact on its sales.\n",
                        "\n",
                        "### Step 5: Recommendations\n",
                        "\n",
                        "1. **Increase Marketing Spend for Product C**: Given its strong correlation with sales and impressive growth rates, allocate more marketing budget to Product C to capitalize on its momentum.\n",
                        "\n",
                        "2. **Evaluate Marketing Strategies for Product B**: Investigate the reasons behind the decline in February and address any marketing strategy weaknesses. Consider targeted campaigns to boost its sales.\n",
                        "\n",
                        "3. **Maintain Support for Product A**: While Product A is performing well, its growth is stabilizing. Explore innovative promotional strategies or product variations to reignite growth.\n",
                        "\n",
                        "### Executive Summary\n",
                        "\n",
                        "In summary, Product A leads in total sales with $792,000, followed by Product C and Product B. Product C exhibits the most promising growth trends and has the highest correlation with marketing spend. Recommendations include increasing marketing efforts for Product C, analyzing and improving marketing strategies for Product B, and maintaining support for Product A to sustain its performance. By focusing on these areas, the marketing team can drive better overall product performance.\n"
                    ]
                }
            ],
            "source": [
                "data_table = \"\"\"\n",
                "| Month | Product A Sales | Product B Sales | Product C Sales | Marketing Spend |\n",
                "|-------|-----------------|-----------------|-----------------|------------------|\n",
                "| Jan   | 120,000         | 45,000          | 32,000          | 15,000          |\n",
                "| Feb   | 125,000         | 42,000          | 36,000          | 15,000          |\n",
                "| Mar   | 130,000         | 48,000          | 39,000          | 16,000          |\n",
                "| Apr   | 135,000         | 50,000          | 58,000          | 25,000          |\n",
                "| May   | 140,000         | 52,000          | 72,000          | 30,000          |\n",
                "| Jun   | 142,000         | 53,000          | 85,000          | 32,000          |\n",
                "\"\"\"\n",
                "\n",
                "# Standard prompt\n",
                "standard_analysis_prompt = f\"\"\"\n",
                "Analyze this sales data and provide insights:\n",
                "\n",
                "{data_table}\n",
                "\"\"\"\n",
                "\n",
                "# Chain-of-thought prompt\n",
                "cot_analysis_prompt = f\"\"\"\n",
                "You are a data analyst helping a marketing team understand product performance.\n",
                "\n",
                "Please analyze the following sales data table:\n",
                "\n",
                "{data_table}\n",
                "\n",
                "To provide a comprehensive analysis, please:\n",
                "\n",
                "1. First, calculate the total sales for each product over the 6-month period.\n",
                "2. Next, calculate the month-over-month growth rate for each product.\n",
                "3. Then, analyze the correlation between marketing spend and sales for each product.\n",
                "4. Compare the performance of the three products and identify which one shows the most promising trend.\n",
                "5. Finally, provide 3 specific, data-backed recommendations for where the marketing team should focus their efforts.\n",
                "\n",
                "For each step, show your reasoning and calculations before moving to the next step.\n",
                "Conclude with a concise executive summary of your findings and recommendations.\n",
                "\"\"\"\n",
                "\n",
                "standard_analysis = await get_completion(standard_analysis_prompt)\n",
                "cot_analysis = await get_completion(cot_analysis_prompt)\n",
                "\n",
                "print(\"==== STANDARD ANALYSIS ====\\n\")\n",
                "print(standard_analysis)\n",
                "print(\"\\n\\n==== CHAIN-OF-THOUGHT ANALYSIS ====\\n\")\n",
                "print(cot_analysis)"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "950b52f3",
            "metadata": {},
            "source": [
                "## 7. Evaluation with Azure AI Evaluation SDK\n",
                "\n",
                "Now let's explore Microsoft's Azure AI Evaluation SDK to evaluate our prompts:"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 32,
            "id": "bd62e28b",
            "metadata": {},
            "outputs": [
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "/home/vscode/.local/lib/python3.11/site-packages/sqlalchemy/util/_concurrency_py3k.py:24: RuntimeWarning: coroutine 'AsyncCompletions.create' was never awaited\n",
                        "  from .langhelpers import memoized_property\n",
                        "RuntimeWarning: Enable tracemalloc to get the object allocation traceback\n"
                    ]
                }
            ],
            "source": [
                "# Import the Azure AI Evaluation SDK\n",
                "from azure.ai.evaluation import RelevanceEvaluator, FluencyEvaluator, CoherenceEvaluator\n",
                "\n",
                "# Configure the model for evaluation\n",
                "model_config = {\n",
                "    \"azure_endpoint\": os.getenv(\"AZURE_OPENAI_ENDPOINT\"),\n",
                "    \"api_key\": os.getenv(\"AZURE_OPENAI_KEY\"),\n",
                "    \"azure_deployment\": os.getenv(\"AZURE_OPENAI_DEPLOYMENT\"),\n",
                "    \"api_version\": \"2024-12-01-preview\"\n",
                "}"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "0a32e954",
            "metadata": {},
            "source": [
                "### Evaluating Research Assistant Summaries"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 35,
            "id": "c8550573",
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Basic Summary Evaluation:\n",
                        "- Relevance: {'relevance': 5.0, 'gpt_relevance': 5.0, 'relevance_reason': 'The RESPONSE fully addresses the QUERY by summarizing the research paper accurately and completely, while also providing additional insights about the challenges and future directions in the field of deep reinforcement learning for autonomous driving. This makes it a comprehensive response.'}\n",
                        "- Fluency: {'fluency': 4.0, 'gpt_fluency': 4.0, 'fluency_reason': 'The RESPONSE demonstrates a high level of fluency with well-structured sentences, good grammar, and a clear conveyance of complex ideas, fitting the criteria for Proficient Fluency. It does not exhibit the exceptional qualities needed for a higher score.'}\n",
                        "- Coherence: {'coherence': 5.0, 'gpt_coherence': 5.0, 'coherence_reason': 'The RESPONSE effectively summarizes the research paper, presenting ideas in a logical order with clear connections between them. It thoroughly addresses the QUERY, demonstrating a high level of coherence.'}\n",
                        "\n",
                        "Engineered Summary Evaluation:\n",
                        "- Relevance: {'relevance': 4.0, 'gpt_relevance': 4.0, 'relevance_reason': 'The RESPONSE is a complete and accurate summary of the research paper, addressing all aspects of the QUERY in a structured format. It provides all necessary details without omitting any key information, which aligns with the definition of a complete response.'}\n",
                        "- Fluency: {'fluency': 4.0, 'gpt_fluency': 4.0, 'fluency_reason': 'The RESPONSE is well-structured, coherent, and uses appropriate vocabulary for an academic summary. It effectively conveys complex ideas with clarity and minimal grammatical errors, which aligns with the definition of Proficient Fluency.'}\n",
                        "- Coherence: {'coherence': 5.0, 'gpt_coherence': 5.0, 'coherence_reason': 'The RESPONSE is exceptionally coherent, with a clear structure and logical flow that effectively summarizes the research paper. It directly addresses the QUERY and presents the information in an organized manner, making it easy to understand.'}\n"
                    ]
                }
            ],
            "source": [
                "# Initialize evaluators\n",
                "relevance_evaluator = RelevanceEvaluator(model_config)\n",
                "fluency_evaluator = FluencyEvaluator(model_config)\n",
                "coherence_evaluator = CoherenceEvaluator(model_config)\n",
                "\n",
                "# Evaluate basic summary\n",
                "basic_relevance = relevance_evaluator(\n",
                "    query=\"Summarize this research paper on deep reinforcement learning for autonomous driving\",\n",
                "    ground_truth=research_paper,\n",
                "    response=basic_summary\n",
                ")\n",
                "\n",
                "basic_fluency = fluency_evaluator(\n",
                "    response=basic_summary\n",
                ")\n",
                "\n",
                "basic_coherence = coherence_evaluator(\n",
                "    conversation={\n",
                "        \"messages\": [\n",
                "            {\"role\": \"user\", \"content\": \"Summarize this research paper on deep reinforcement learning for autonomous driving\"},\n",
                "            {\"role\": \"assistant\", \"content\": basic_summary}\n",
                "        ]\n",
                "    }\n",
                ")\n",
                "\n",
                "# Evaluate engineered summary\n",
                "engineered_relevance = relevance_evaluator(\n",
                "    query=\"Summarize this research paper on deep reinforcement learning for autonomous driving with a structured format\",\n",
                "    ground_truth=research_paper,\n",
                "    response=engineered_summary\n",
                ")\n",
                "\n",
                "engineered_fluency = fluency_evaluator(\n",
                "    response=engineered_summary\n",
                ")\n",
                "\n",
                "engineered_coherence = coherence_evaluator(\n",
                "    conversation={\n",
                "        \"messages\": [\n",
                "            {\"role\": \"user\", \"content\": \"Summarize this research paper on deep reinforcement learning for autonomous driving with a structured format\"},\n",
                "            {\"role\": \"assistant\", \"content\": engineered_summary}\n",
                "        ]\n",
                "    }\n",
                ")\n",
                "\n",
                "# Print evaluation results\n",
                "print(\"Basic Summary Evaluation:\")\n",
                "print(f\"- Relevance: {basic_relevance}\")\n",
                "print(f\"- Fluency: {basic_fluency}\")\n",
                "print(f\"- Coherence: {basic_coherence}\")\n",
                "print(\"\\nEngineered Summary Evaluation:\")\n",
                "print(f\"- Relevance: {engineered_relevance}\")\n",
                "print(f\"- Fluency: {engineered_fluency}\")\n",
                "print(f\"- Coherence: {engineered_coherence}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "c3ff05eb",
            "metadata": {},
            "source": [
                "### Visualizing Evaluation Results"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 37,
            "id": "f72a9d44",
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "image/png": "iVBORw0KGgoAAAANSUhEUgAAA90AAAJOCAYAAACqS2TfAAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjEsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvc2/+5QAAAAlwSFlzAAAPYQAAD2EBqD+naQAAS9tJREFUeJzt3XeYFeXdP/730pYOShVFQQUUFTVYgiVYUIRolMf+EBU1xkQNwRYxxpoY7CYaRR41QIyJLYrYg0ZQsSD2FkXUSOwFQUAXgfP7I1/Ozw2olB1X8PW6rnNdzD33zHzO7NnDee89c5+KUqlUCgAAAFDj6tR2AQAAALCyEroBAACgIEI3AAAAFEToBgAAgIII3QAAAFAQoRsAAAAKInQDAABAQYRuAAAAKIjQDQAAAAURugGgllVUVOS0006rlWOPHz8+FRUVGT9+fK0c/9tu1KhRqaioyGuvvVbbpQBQEKEbgPIH/4WPhg0bpmvXrjnqqKPyzjvv1HZ5y+TNN9/MaaedlieffHKJ+v/3Ofjvx8MPP1xswQW79NJLM2rUqNouY7Fuuumm9OvXL61bt06DBg3SoUOH7LPPPvnHP/5R26UBwHKrV9sFAPDNccYZZ6Rz58759NNP88ADD2T48OG5/fbb8+yzz6Zx48a1Xd5SefPNN3P66aenU6dO2WSTTZZ4u4Xn4L+tu+66NVjd1+/SSy9N69atM2jQoGrt3/ve9/LJJ5+kQYMGX3tNpVIphxxySEaNGpVNN900xxxzTNq3b5+33norN910U3bcccdMnDgxW2211dde29flgAMOyH777ZfKysraLgWAggjdAJT169cvm222WZLkRz/6UVq1apULLrggN998c/bff//FbjN79uw0adLk6yyzUJ8/B98GderUScOGDWvl2Oeff35GjRqVIUOG5IILLkhFRUV53UknnZSrrroq9eqtnB9VFv7e1K1bN3Xr1q3tcgAokMvLAfhCO+ywQ5Lk1VdfTZIMGjQoTZs2zdSpU9O/f/80a9YsAwcOTPKfEHHsscemY8eOqaysTLdu3XLeeeelVCpV22dFRUWOOuqoXH/99enevXsaNWqUXr165ZlnnkmSjBgxIuuuu24aNmyY7bbbbpF7XbfbbrtsuOGGeeyxx7LVVlulUaNG6dy5cy677LJyn/Hjx2fzzTdPkhx88MHlS8SX9/Lqzz77LKuuumoOPvjgRdbNnDkzDRs2zHHHHZckmTt3bk455ZT07NkzLVq0SJMmTbLtttvm3nvv/crjDBo0KJ06dVqk/bTTTqsWTJNk5MiR2WGHHdK2bdtUVlame/fuGT58eLU+nTp1ynPPPZcJEyaUz8V2222X5Ivv6b7++uvTs2fPNGrUKK1bt84Pf/jDvPHGG4vU2bRp07zxxhvZY4890rRp07Rp0ybHHXdc5s+f/6XP8ZNPPsmwYcOy3nrr5bzzzlvkeSX/GQXeYostysuvvPJK9t5776y66qpp3Lhxvvvd7+a2226rts3C53Pdddfl9NNPz+qrr55mzZplr732yowZM1JVVZUhQ4akbdu2adq0aQ4++OBUVVVV28fC1+jVV1+dbt26pWHDhunZs2fuu+++av3+9a9/5Ygjjki3bt3SqFGjtGrVKnvvvfcir9mFty5MmDAhRxxxRNq2bZs11lij2rrPbzN58uT07ds3rVu3Lr++DznkkGr7XNrftzFjxmTDDTdMZWVlNthgg9x5551f+vMBoOasnH8+BqBGTJ06NUnSqlWrctu8efPSt2/fbLPNNjnvvPPSuHHjlEql/OAHP8i9996bQw89NJtssknuuuuuHH/88XnjjTdy4YUXVtvv/fffn7Fjx+bII49MkgwbNiy77rprfvGLX+TSSy/NEUcckenTp+ecc87JIYccssi9vdOnT0///v2zzz77ZP/99891112Xn/70p2nQoEEOOeSQrL/++jnjjDNyyimn5Mc//nG23XbbJFmiy5RnzJiR999/v1pbRUVFWrVqlfr162fAgAG58cYbM2LEiGqXZI8ZMyZVVVXZb7/9kvwnhF9xxRXZf//9c9hhh+Xjjz/OlVdemb59+2bSpElLdcn7lxk+fHg22GCD/OAHP0i9evVyyy235IgjjsiCBQvK5/d3v/tdfvazn6Vp06Y56aSTkiTt2rX7wn2OGjUqBx98cDbffPMMGzYs77zzTn7/+99n4sSJeeKJJ9KyZcty3/nz56dv377Zcsstc9555+Xuu+/O+eefn3XWWSc//elPv/AYDzzwQD788MMMGTJkiUZ633nnnWy11VaZM2dOBg8enFatWmX06NH5wQ9+kBtuuCEDBgyo1n/YsGFp1KhRhg4dmpdffjkXX3xx6tevnzp16mT69Ok57bTT8vDDD2fUqFHp3LlzTjnllGrbT5gwIddee20GDx6cysrKXHrppdlll10yadKkbLjhhkmSRx99NA8++GD222+/rLHGGnnttdcyfPjwbLfddnn++ecXuSXjiCOOSJs2bXLKKadk9uzZi32e7777bnbeeee0adMmQ4cOTcuWLfPaa6/lxhtvLPdZ2t+3Bx54IDfeeGOOOOKINGvWLBdddFH23HPPvP7669V+twEoSAmAb72RI0eWkpTuvvvu0nvvvVeaNm1a6Zprrim1atWq1KhRo9K///3vUqlUKh100EGlJKWhQ4dW237MmDGlJKXf/OY31dr32muvUkVFRenll18utyUpVVZWll599dVy24gRI0pJSu3bty/NnDmz3H7iiSeWklTr27t371KS0vnnn19uq6qqKm2yySaltm3blubOnVsqlUqlRx99tJSkNHLkyKU6B4t7VFZWlvvdddddpSSlW265pdr2/fv3L6299trl5Xnz5pWqqqqq9Zk+fXqpXbt2pUMOOaRae5LSqaeeWl4+6KCDSmuttdYiNZ566qml//6ve86cOYv069u3b7VaSqVSaYMNNij17t17kb733ntvKUnp3nvvLZVKpdLcuXNLbdu2LW244YalTz75pNzv1ltvLSUpnXLKKdXqTFI644wzqu1z0003LfXs2XORY33e73//+1KS0k033fSl/RYaMmRIKUnp/vvvL7d9/PHHpc6dO5c6depUmj9/frXns+GGG5ZfC6VSqbT//vuXKioqSv369au23169ei1yrhf+3CdPnlxu+9e//lVq2LBhacCAAeW2xZ37hx56qJSk9Kc//anctvC1tc0225TmzZtXrf/CdQtf4zfddFMpSenRRx/9wnOxtL9vDRo0qNb21FNPlZKULr744i88BgA1x+XlAJT16dMnbdq0SceOHbPffvuladOmuemmm7L66qtX6/ffI5i333576tatm8GDB1drP/bYY1MqlXLHHXdUa99xxx2rXT695ZZbJkn23HPPNGvWbJH2V155pdr29erVy+GHH15ebtCgQQ4//PC8++67eeyxx5byWVd3ySWXZNy4cdUen69/hx12SOvWrXPttdeW26ZPn55x48Zl3333LbfVrVu3PBK+YMGCfPjhh5k3b14222yzPP7448tV4+c1atSo/O+Fo/S9e/fOK6+8khkzZiz1/iZPnpx33303RxxxRLV7vb///e9nvfXWW+Ry7iT5yU9+Um152223XeRn9t9mzpyZJNV+3l/m9ttvzxZbbJFtttmm3Na0adP8+Mc/zmuvvZbnn3++Wv8DDzww9evXLy9vueWW5YnbPm/LLbfMtGnTMm/evGrtvXr1Ss+ePcvLa665Znbffffcdddd5UvnP3/uP/vss3zwwQdZd91107Jly8X+jA877LCvHNVfeBXBrbfems8++2yxfZb2961Pnz5ZZ511yss9evRI8+bNv/JnBEDNcHk5AGWXXHJJunbtmnr16qVdu3bp1q1b6tSp/vfZevXqle9HXehf//pXOnTosEiAWn/99cvrP2/NNdesttyiRYskSceOHRfbPn369GrtHTp0WGTytq5duyZJXnvttXz3u9/98if6JbbYYosvnUitXr162XPPPfOXv/wlVVVVqayszI033pjPPvusWuhOktGjR+f888/PP//5z2oBanGzoy+riRMn5tRTT81DDz2UOXPmVFs3Y8aM8jlcUgt/Vt26dVtk3XrrrZcHHnigWlvDhg3Tpk2bam2rrLLKIj+z/9a8efMkyccff7zEdS38I8znff41tvCy72TpXmMLFizIjBkzql1q3aVLl0WO1bVr18yZMyfvvfde2rdvX74vfeTIkXnjjTeq3U+9uD94LMnPvXfv3tlzzz1z+umn58ILL8x2222XPfbYI//7v/9bnuF8eX/fkiX7GQFQM4x0A1C2xRZbpE+fPtluu+2y/vrrLxK4k6SysnKx7Uvji0b7vqi99F+TQ9W2/fbbLx9//HF5RPG6667Leuutl4033rjc589//nMGDRqUddZZJ1deeWXuvPPOjBs3LjvssEMWLFjwpftf3KRiSRaZnGzq1KnZcccd8/777+eCCy7IbbfdlnHjxuXoo49Okq88Tk1Y1pm311tvvSQpT6BX076O19jPfvaznHnmmdlnn31y3XXX5e9//3vGjRuXVq1aLfbcf35k/ItUVFTkhhtuyEMPPZSjjjoqb7zxRg455JD07Nkzs2bNWuoakxXn9wpgZSV0A7Dc1lprrbz55puLjFr+85//LK+vSW+++eYiE1G99NJLSVK+bP2LgmtN+N73vpfVVlst1157bd5///384x//WGSU+4Ybbsjaa6+dG2+8MQcccED69u2bPn365NNPP/3K/a+yyir56KOPFmn/7xHMW265JVVVVRk7dmwOP/zw9O/fP3369FlsuFvS87HwZ/Xiiy8usu7FF1+ssZ/lNttsk1VWWSV//etfv3Km84V1La6mol5jU6ZMWaTtpZdeSuPGjcsj+zfccEMOOuignH/++dlrr72y0047ZZtttlnsz25pffe7382ZZ56ZyZMn5+qrr85zzz2Xa665JsnX//sGwPIRugFYbv3798/8+fPzhz/8oVr7hRdemIqKivTr169Gjzdv3ryMGDGivDx37tyMGDEibdq0Kd+Hu/Dy85oIQP+tTp062WuvvXLLLbfkqquuyrx58xYJ3QtHFz8/mvjII4/koYce+sr9r7POOpkxY0aefvrpcttbb72Vm2666SuPMWPGjIwcOXKRfTZp0mSJzsVmm22Wtm3b5rLLLqv2VVp33HFHXnjhhXz/+9//yn0sicaNG+eEE07ICy+8kBNOOGGxo65//vOfM2nSpCT/eY1NmjSp2vmbPXt2/u///i+dOnVK9+7da6SuhR566KFq92VPmzYtN998c3beeefyea9bt+4idV988cVL9EeELzJ9+vRF9rlwpvuFP4+v+/cNgOXjnm4Alttuu+2W7bffPieddFJee+21bLzxxvn73/+em2++OUOGDKk2iVNN6NChQ84+++y89tpr6dq1a6699to8+eST+b//+7/y5FnrrLNOWrZsmcsuuyzNmjVLkyZNsuWWW37lfbV33HFHecTw87baaqusvfba5eV99903F198cU499dRstNFG5ftpF9p1111z4403ZsCAAfn+97+fV199NZdddlm6d+/+lZcJ77fffjnhhBMyYMCADB48OHPmzMnw4cPTtWvXakFw5513ToMGDbLbbrvl8MMPz6xZs3L55Zenbdu2eeutt6rts2fPnhk+fHh+85vfZN11103btm3L38P+efXr18/ZZ5+dgw8+OL17987+++9f/sqwTp06lS9drwnHH398nnvuuZx//vm59957s9dee6V9+/Z5++23M2bMmEyaNCkPPvhgkmTo0KH561//mn79+mXw4MFZddVVM3r06Lz66qv529/+tty3PPy3DTfcMH379q32lWFJcvrpp5f77LrrrrnqqqvSokWLdO/ePQ899FDuvvvu5foartGjR+fSSy/NgAEDss466+Tjjz/O5ZdfnubNm6d///5Jvv7fNwCWj9ANwHKrU6dOxo4dm1NOOSXXXnttRo4cmU6dOuXcc8/NscceW+PHW2WVVTJ69Oj87Gc/y+WXX5527drlD3/4Qw477LByn/r162f06NE58cQT85Of/CTz5s3LyJEjvzJ0//f3NS80cuTIaqF7q622SseOHTNt2rRFRrmTZNCgQXn77bczYsSI3HXXXenevXv+/Oc/5/rrr8/48eO/tIZWrVrlpptuyjHHHJNf/OIX6dy5c4YNG5YpU6ZUC93dunXLDTfckF/96lc57rjj0r59+/z0pz9NmzZtFpml+5RTTsm//vWvnHPOOfn444/Tu3fvxYbuhbU3btw4Z511Vk444YQ0adIkAwYMyNlnn13tO7qXV506dfKnP/0pu+++e/7v//4v5513XmbOnJk2bdrke9/7Xs4555z06tUryX++V/zBBx/MCSeckIsvvjiffvppevTokVtuuaXGRt8/r3fv3unVq1dOP/30vP766+nevXtGjRqVHj16lPv8/ve/T926dXP11Vfn008/zdZbb5277747ffv2Xa7jTpo0Kddcc03eeeedtGjRIltssUWuvvrq8mv36/59A2D5VJTMogHACmS77bbL+++/n2effba2S2ElVVFRkSOPPHKRy7cBYFm4pxsAAAAKInQDAABAQYRuAAAAKEit3tN92mmnVZsFNPnPpDCLmzUWAAAAVjS1Pnv5BhtskLvvvru8XK9erZcEAAAANaLWE269evXSvn372i4DAAAAalyth+4pU6akQ4cOadiwYXr16pVhw4ZlzTXXXGzfqqqqVFVVlZcXLFiQDz/8MK1atUpFRcXXVTIAAADfcqVSKR9//HE6dOiQOnW+eLq0Wr2n+4477sisWbPSrVu3vPXWWzn99NPzxhtv5Nlnn02zZs0W6b+4e8ABAACgtkybNi1rrLHGF66v1dD93z766KOstdZaueCCC3LooYcusv6/R7pnzJiRNddcM9OmTUvz5s2/zlIBAAD4Fps5c2Y6duyYjz76KC1atPjCfrV+efnntWzZMl27ds3LL7+82PWVlZWprKxcpL158+ZCNwAAAF+7r7rV+Rv1Pd2zZs3K1KlTs9pqq9V2KQAAALDcajV0H3fccZkwYUJee+21PPjggxkwYEDq1q2b/fffvzbLAgAAgBpRq5eX//vf/87++++fDz74IG3atMk222yThx9+OG3atKnNsgAAAKBG1Grovuaaa2rz8AAAQA2bP39+Pvvss9ouA5Zb/fr1U7du3eXezzdqIjUAAGDFVCqV8vbbb+ejjz6q7VKgxrRs2TLt27f/ysnSvozQDQAALLeFgbtt27Zp3LjxcoUUqG2lUilz5szJu+++myTLNdm30A0AACyX+fPnlwN3q1atarscqBGNGjVKkrz77rtp27btMl9q/o36yjAAAGDFs/Ae7saNG9dyJVCzFr6ml2eeAqEbAACoES4pZ2VTE69poRsAAAAKInQDAAAUZNSoUWnZsmVtl0EtMpEaAABQiE5Db/taj/faWd9fqv6DBg3K6NGjy8urrrpqNt9885xzzjnp0aNHjdS07777pn///su8/ahRo3LwwQcn+c+lzh06dMhOO+2Us88+O23btq2RGmtaRUVFbrrppuyxxx61Xco3gpFuAADgW2uXXXbJW2+9lbfeeiv33HNP6tWrl1133bXG9t+oUaPlDsfNmzfPW2+9lX//+9+5/PLLc8cdd+SAAw5YbN/58+dnwYIFy3U8apbQDQAAfGtVVlamffv2ad++fTbZZJMMHTo006ZNy3vvvVfuc8IJJ6Rr165p3Lhx1l577Zx88snVZrN+6qmnsv3226dZs2Zp3rx5evbsmcmTJydZ/OXlt9xySzbffPM0bNgwrVu3zoABA760xoqKirRv3z4dOnRIv379Mnjw4Nx999355JNPyvsfO3ZsunfvnsrKyrz++uuZPn16DjzwwKyyyipp3Lhx+vXrlylTppT3uXC7W2+9Nd26dUvjxo2z1157Zc6cORk9enQ6deqUVVZZJYMHD878+fPL23Xq1Cm//vWvs//++6dJkyZZffXVc8kll1RbnyQDBgxIRUVFefnbTOgGAABIMmvWrPz5z3/OuuuuW+37xps1a5ZRo0bl+eefz+9///tcfvnlufDCC8vrBw4cmDXWWCOPPvpoHnvssQwdOjT169df7DFuu+22DBgwIP37988TTzyRe+65J1tsscVS1dmoUaMsWLAg8+bNS5LMmTMnZ599dq644oo899xzadu2bQYNGpTJkydn7Nixeeihh1IqldK/f/9qfyyYM2dOLrroolxzzTW58847M378+AwYMCC33357br/99lx11VUZMWJEbrjhhmrHP/fcc7PxxhvniSeeyNChQ/Pzn/8848aNS5I8+uijSZKRI0fmrbfeKi9/m7mnGwAA+Na69dZb07Rp0yTJ7Nmzs9pqq+XWW29NnTr///jkr371q/K/O3XqlOOOOy7XXHNNfvGLXyRJXn/99Rx//PFZb731kiRdunT5wuOdeeaZ2W+//XL66aeX2zbeeOMlrnfKlCm57LLLstlmm6VZs2ZJ/vMd0pdeeml5P1OmTMnYsWMzceLEbLXVVkmSq6++Oh07dsyYMWOy9957l7cbPnx41llnnSTJXnvtlauuuirvvPNOmjZtmu7du2f77bfPvffem3333bdcw9Zbb52hQ4cmSbp27ZqJEyfmwgsvzE477ZQ2bdokSVq2bJn27dsv8fNamRnpBgAAvrW23377PPnkk3nyySczadKk9O3bN/369cu//vWvcp9rr702W2+9ddq3b5+mTZvmV7/6VV5//fXy+mOOOSY/+tGP0qdPn5x11lmZOnXqFx7vySefzI477rhUNc6YMSNNmzZN48aN061bt7Rr1y5XX311eX2DBg2qTfz2wgsvpF69etlyyy3Lba1atUq3bt3ywgsvlNsaN25cDtxJ0q5du3Tq1Kn8R4iFbe+++261enr16rXI8uf3S3VCNwAA8K3VpEmTrLvuull33XWz+eab54orrsjs2bNz+eWXJ0keeuihDBw4MP3798+tt96aJ554IieddFLmzp1b3sdpp52W5557Lt///vfzj3/8I927d89NN9202OM1atRoqWts1qxZnnzyyTz77LOZPXt27rvvvnTt2rXaPisqKpZ6v/99CXxFRcVi20zMtnyEbgAAgP+noqIiderUySeffJIkefDBB7PWWmvlpJNOymabbZYuXbpUGwVfqGvXrjn66KPz97//Pf/zP/+TkSNHLnb/PXr0yD333LNUNdWpUyfrrrtu1l577SUK7euvv37mzZuXRx55pNz2wQcf5MUXX0z37t2X6tiL8/DDDy+yvP7665eX69evX23ytW8793QDAADfWlVVVXn77beTJNOnT88f/vCHzJo1K7vttluS/9yf/frrr+eaa67J5ptvnttuu63aKPYnn3yS448/PnvttVc6d+6cf//733n00Uez5557LvZ4p556anbcccess8462W+//TJv3rzcfvvtOeGEE2rsOXXp0iW77757DjvssIwYMSLNmjXL0KFDs/rqq2f33Xdf7v1PnDgx55xzTvbYY4+MGzcu119/fW677f//TvZOnTrlnnvuydZbb53Kysqsssoqy33MFZmRbgAA4FvrzjvvzGqrrZbVVlstW265ZR599NFcf/312W677ZIkP/jBD3L00UfnqKOOyiabbJIHH3wwJ598cnn7unXr5oMPPsiBBx6Yrl27Zp999km/fv2qTZT2edttt12uv/76jB07Nptsskl22GGHTJo0qcaf18iRI9OzZ8/suuuu6dWrV0qlUm6//fYvnFV9aRx77LGZPHlyNt100/zmN7/JBRdckL59+5bXn3/++Rk3blw6duyYTTfddLmPt6KrKJVKpdouYlnNnDkzLVq0yIwZM9K8efPaLgcAAL6VPv3007z66qvp3LlzGjZsWNvlUKBOnTplyJAhGTJkSG2X8rX4stf2kuZRI90AAABQEKEbAAAACmIiNQAAAJbIa6+9VtslrHCMdAMAAEBBhG4AAAAoiNANAAAABRG6AQAAoCBCNwAAABRE6AYAAICCCN0AAAAFGjVqVFq2bFnbZSyX7bbbLkOGDKntMlZIvqcbAAAoxmktvubjzViq7oMGDcro0aMXae/bt2/uvPPOmqoq++67b/r3719j+/smGjVqVA4++OAkSUVFRTp06JCddtopZ599dtq2bVvL1S1eRUVFbrrppuyxxx6FHkfoBgAAvrV22WWXjBw5slpbZWVljR6jUaNGadSoUY3uc1nMnTs3DRo0KGz/zZs3z4svvpgFCxbkqaeeysEHH5w333wzd9111yJ958+fn4qKitSps/JffL3yP0MAAIAvUFlZmfbt21d7rLLKKuX1FRUVueKKKzJgwIA0btw4Xbp0ydixY6vtY+zYsenSpUsaNmyY7bffPqNHj05FRUU++uijJIteXn7aaadlk002yVVXXZVOnTqlRYsW2W+//fLxxx+X+yxYsCDDhg1L586d06hRo2y88ca54YYbqh332WefTb9+/dK0adO0a9cuBxxwQN5///3y+u222y5HHXVUhgwZktatW6dv375LtN3s2bNz4IEHpmnTpllttdVy/vnnL9G5rKioSPv27dOhQ4f069cvgwcPzt13351PPvmkfA7Gjh2b7t27p7KyMq+//nqmT5+eAw88MKusskoaN26cfv36ZcqUKeV9Ltzu1ltvTbdu3dK4cePstddemTNnTkaPHp1OnTpllVVWyeDBgzN//vzydp06dcqvf/3r7L///mnSpElWX331XHLJJdXWJ8mAAQNSUVFRXi6C0A0AAPAlTj/99Oyzzz55+umn079//wwcODAffvhhkuTVV1/NXnvtlT322CNPPfVUDj/88Jx00klfuc+pU6dmzJgxufXWW3PrrbdmwoQJOeuss8rrhw0blj/96U+57LLL8txzz+Xoo4/OD3/4w0yYMCFJ8tFHH2WHHXbIpptumsmTJ+fOO+/MO++8k3322afacUaPHp0GDRpk4sSJueyyy5Zou+OPPz4TJkzIzTffnL///e8ZP358Hn/88aU+b40aNcqCBQsyb968JMmcOXNy9tln54orrshzzz2Xtm3bZtCgQZk8eXLGjh2bhx56KKVSKf37989nn31W3s+cOXNy0UUX5Zprrsmdd96Z8ePHZ8CAAbn99ttz++2356qrrsqIESMW+aPEueeem4033jhPPPFEhg4dmp///OcZN25ckuTRRx9NkowcOTJvvfVWebkILi8HAAC+tW699dY0bdq0Wtsvf/nL/PKXvywvDxo0KPvvv3+S5Le//W0uuuiiTJo0KbvssktGjBiRbt265dxzz02SdOvWLc8++2zOPPPMLz3uggULMmrUqDRr1ixJcsABB+See+7JmWeemaqqqvz2t7/N3XffnV69eiVJ1l577TzwwAMZMWJEevfunT/84Q/ZdNNN89vf/ra8zz/+8Y/p2LFjXnrppXTt2jVJ0qVLl5xzzjnlPr/5zW++dLsOHTrkyiuvzJ///OfsuOOOSf4T3NdYY42lOq9TpkzJZZddls0226z8HD/77LNceuml2Xjjjct9xo4dm4kTJ2arrbZKklx99dXp2LFjxowZk7333ru83fDhw7POOuskSfbaa69cddVVeeedd9K0adN0794922+/fe69997su+++5Rq23nrrDB06NEnStWvXTJw4MRdeeGF22mmntGnTJknSsmXLtG/ffqme29ISugEAgG+t7bffPsOHD6/Wtuqqq1Zb7tGjR/nfTZo0SfPmzfPuu+8mSV588cVsvvnm1fpvscUWX3ncTp06lcNokqy22mrlfb788suZM2dOdtppp2rbzJ07N5tuummS5Kmnnsq99967yB8Mkv+Moi8M3T179qy27qu2++STTzJ37txsueWW5fZVV1013bp1+8rnNGPGjDRt2jQLFizIp59+mm222SZXXHFFeX2DBg2qncsXXngh9erVq3asVq1apVu3bnnhhRfKbY0bNy4H7iRp165dOnXqVO05tGvXrnz+Flr4B4vPL//ud7/7yudR04RuAADgW6tJkyZZd911v7RP/fr1qy1XVFRkwYIFy3XcL9vnrFmzkiS33XZbVl999Wr9Fk7yNmvWrOy22245++yzF9n3aqutVv53kyZNqq37qu1efvnlZXg2/9GsWbM8/vjjqVOnTlZbbbVFJo9r1KhRKioqlnq/iztXRfxMiiJ0AwAALKNu3brl9ttvr9a2vPcHf36isd69ey+2z3e+85387W9/S6dOnVKv3pLHuq/abp111kn9+vXzyCOPZM0110ySTJ8+PS+99NIX1rJQnTp1vvIPGJ+3/vrrZ968eXnkkUfKl5d/8MEHefHFF9O9e/cl3s8XefjhhxdZXn/99cvL9evXrzb5WlFMpAYAAHxrVVVV5e233672+PxM3l/l8MMPzz//+c+ccMIJeemll3Lddddl1KhRSbJMo7rJf0aMjzvuuBx99NEZPXp0pk6dmscffzwXX3xx+XvFjzzyyHz44YfZf//98+ijj2bq1Km56667cvDBB39pkPyq7Zo2bZpDDz00xx9/fP7xj3/k2WefzaBBgwr5aq8uXbpk9913z2GHHZYHHnggTz31VH74wx9m9dVXz+67777c+584cWLOOeecvPTSS7nkkkty/fXX5+c//3l5fadOnXLPPffk7bffzvTp05f7eF9E6AYAAL617rzzzqy22mrVHttss80Sb9+5c+fccMMNufHGG9OjR48MHz68PHv58nzf969//eucfPLJGTZsWNZff/3ssssuue2229K5c+ckSYcOHTJx4sTMnz8/O++8czbaaKMMGTIkLVu2/NKAvCTbnXvuudl2222z2267pU+fPtlmm20WuTe8powcOTI9e/bMrrvuml69eqVUKuX2229f5PLxZXHsscdm8uTJ2XTTTfOb3/wmF1xwQflr05Lk/PPPz7hx49KxY8fyvfJFqCiVSqXC9l6wmTNnpkWLFpkxY0aaN29e2+UAAMC30qeffppXX301nTt3TsOGDWu7nFp35pln5rLLLsu0adNqu5RvrU6dOmXIkCEZMmTIcu3ny17bS5pH3dMNAACwHC699NJsvvnmadWqVSZOnJhzzz03Rx11VG2XxTeE0A0AALAcpkyZkt/85jf58MMPs+aaa+bYY4/NiSeeWNtl8Q0hdAMAACyHCy+8MBdeeGFtl8HnvPbaa7VdQpmJ1AAAAKAgQjcAAAAUROgGAABqxIIFC2q7BKhRNfGadk83AACwXBo0aJA6derkzTffTJs2bdKgQYNUVFTUdlmwzEqlUubOnZv33nsvderUSYMGDZZ5X0I3AACwXOrUqZPOnTvnrbfeyptvvlnb5UCNady4cdZcc83UqbPsF4kL3QAAwHJr0KBB1lxzzcybNy/z58+v7XJgudWtWzf16tVb7qs2hG4AAKBGVFRUpH79+qlfv35tlwLfGCZSAwAAgIII3QAAAFAQoRsAAAAKInQDAABAQYRuAAAAKIjQDQAAAAURugEAAKAgQjcAAAAUROgGAACAggjdAAAAUBChGwAAAAoidAMAAEBBhG4AAAAoiNANAAAABRG6AQAAoCBCNwAAABRE6AYAAICCCN0AAABQEKEbAAAACiJ0AwAAQEGEbgAAACiI0A0AAAAFEboBAACgIEI3AAAAFEToBgAAgIII3QAAAFAQoRsAAAAKInQDAABAQYRuAAAAKIjQDQAAAAURugEAAKAgQjcAAAAUROgGAACAggjdAAAAUBChGwAAAAoidAMAAEBBhG4AAAAoiNANAAAABRG6AQAAoCBCNwAAABRE6AYAAICCCN0AAABQEKEbAAAACiJ0AwAAQEGEbgAAACjINyZ0n3XWWamoqMiQIUNquxQAAACoEd+I0P3oo49mxIgR6dGjR22XAgAAADWm1kP3rFmzMnDgwFx++eVZZZVVarscAAAAqDG1HrqPPPLIfP/730+fPn2+sm9VVVVmzpxZ7QEAAADfVPVq8+DXXHNNHn/88Tz66KNL1H/YsGE5/fTTC64KAAAAakatjXRPmzYtP//5z3P11VenYcOGS7TNiSeemBkzZpQf06ZNK7hKAAAAWHYVpVKpVBsHHjNmTAYMGJC6deuW2+bPn5+KiorUqVMnVVVV1dYtzsyZM9OiRYvMmDEjzZs3L7pkAAAASLLkebTWLi/fcccd88wzz1RrO/jgg7PeeuvlhBNO+MrADQAAAN90tRa6mzVrlg033LBaW5MmTdKqVatF2gEAAGBFVOuzlwMAAMDKqlZnL/9v48ePr+0SAAAAoMYY6QYAAICCCN0AAABQEKEbAAAACiJ0AwAAQEGEbgAAACiI0A0AAAAFEboBAACgIEI3AAAAFEToBgAAgIII3QAAAFAQoRsAAAAKInQDAABAQYRuAAAAKIjQDQAAAAURugEAAKAgQjcAAAAUROgGAACAggjdAAAAUBChGwAAAAoidAMAAEBBhG4AAAAoiNANAAAABRG6AQAAoCBCNwAAABRE6AYAAICCCN0AAABQEKEbAAAACiJ0AwAAQEGEbgAAACiI0A0AAAAFEboBAACgIEI3AAAAFEToBgAAgIII3QAAAFAQoRsAAAAKInQDAABAQYRuAAAAKIjQDQAAAAURugEAAKAgQjcAAAAUROgGAACAggjdAAAAUBChGwAAAAoidAMAAEBBhG4AAAAoiNANAAAABRG6AQAAoCBCNwAAABRE6AYAAICCCN0AAABQEKEbAAAACiJ0AwAAQEGEbgAAACiI0A0AAAAFEboBAACgIEI3AAAAFEToBgAAgIII3QAAAFAQoRsAAAAKInQDAABAQYRuAAAAKIjQDQAAAAURugEAAKAgQjcAAAAUROgGAACAggjdAAAAUBChGwAAAAoidAMAAEBBhG4AAAAoiNANAAAABRG6AQAAoCBCNwAAABRE6AYAAICCCN0AAABQEKEbAAAACiJ0AwAAQEGEbgAAACiI0A0AAAAFEboBAACgIEI3AAAAFEToBgAAgIII3QAAAFAQoRsAAAAKInQDAABAQYRuAAAAKIjQDQAAAAURugEAAKAgQjcAAAAUROgGAACAggjdAAAAUBChGwAAAAoidAMAAEBBhG4AAAAoSK2G7uHDh6dHjx5p3rx5mjdvnl69euWOO+6ozZIAAACgxtRq6F5jjTVy1lln5bHHHsvkyZOzww47ZPfdd89zzz1Xm2UBAABAjagolUql2i7i81ZdddWce+65OfTQQ7+y78yZM9OiRYvMmDEjzZs3/xqqAwAAgCXPo/W+xpq+1Pz583P99ddn9uzZ6dWrV22XAwAAAMut1kP3M888k169euXTTz9N06ZNc9NNN6V79+6L7VtVVZWqqqry8syZM7+uMgEAAGCp1frs5d26dcuTTz6ZRx55JD/96U9z0EEH5fnnn19s32HDhqVFixblR8eOHb/magEAAGDJfePu6e7Tp0/WWWedjBgxYpF1ixvp7tixo3u6AQAA+FqtcPd0L7RgwYJqwfrzKisrU1lZ+TVXBAAAAMumVkP3iSeemH79+mXNNdfMxx9/nL/85S8ZP3587rrrrtosCwAAAGpErYbud999NwceeGDeeuuttGjRIj169Mhdd92VnXbaqTbLAgAAgBpRq6H7yiuvrM3DAwAAQKFqffZyAAAAWFkJ3QAAAFAQoRsAAAAKInQDAABAQYRuAAAAKIjQDQAAAAURugEAAKAgQjcAAAAUROgGAACAggjdAAAAUBChGwAAAAoidAMAAEBBhG4AAAAoiNANAAAABRG6AQAAoCBCNwAAABRE6AYAAICCCN0AAABQEKEbAAAACiJ0AwAAQEGEbgAAACiI0A0AAAAFEboBAACgIEI3AAAAFEToBgAAgIII3QAAAFAQoRsAAAAKInQDAABAQYRuAAAAKMhyhe65c+fmxRdfzLx582qqHgAAAFhpLFPonjNnTg499NA0btw4G2ywQV5//fUkyc9+9rOcddZZNVogAAAArKiWKXSfeOKJeeqppzJ+/Pg0bNiw3N6nT59ce+21NVYcAAAArMjqLctGY8aMybXXXpvvfve7qaioKLdvsMEGmTp1ao0VBwAAACuyZRrpfu+999K2bdtF2mfPnl0thAMAAMC32TKF7s022yy33XZbeXlh0L7iiivSq1evmqkMAAAAVnDLdHn5b3/72/Tr1y/PP/985s2bl9///vd5/vnn8+CDD2bChAk1XSMAAACskJZppHubbbbJU089lXnz5mWjjTbK3//+97Rt2zYPPfRQevbsWdM1AgAAwAppqUe6P/vssxx++OE5+eSTc/nllxdREwAAAKwUlnqku379+vnb3/5WRC0AAACwUlmmy8v32GOPjBkzpoZLAQAAgJXLMk2k1qVLl5xxxhmZOHFievbsmSZNmlRbP3jw4BopDgAAAFZkFaVSqbS0G3Xu3PmLd1hRkVdeeWW5ilpSM2fOTIsWLTJjxow0b978azkmAAAALGkeXaaR7ldffXWZCwMAAIBvi2W6p/vzSqVSlmGwHAAAAFZ6yxy6//SnP2WjjTZKo0aN0qhRo/To0SNXXXVVTdYGAAAAK7Rlurz8ggsuyMknn5yjjjoqW2+9dZLkgQceyE9+8pO8//77Ofroo2u0SAAAAFgRLfNEaqeffnoOPPDAau2jR4/Oaaed9rXd820iNQAAAGrDkubRZbq8/K233spWW221SPtWW22Vt956a1l2CQAAACudZQrd6667bq677rpF2q+99tp06dJluYsCAACAlcEy3dN9+umnZ9999819991Xvqd74sSJueeeexYbxgEAAODbaJlGuvfcc8888sgjad26dcaMGZMxY8akdevWmTRpUgYMGFDTNQIAAMAKaZkmUvumMJEaAAAAtaHQidRuv/323HXXXYu033XXXbnjjjuWZZcAAACw0lmm0D106NDMnz9/kfZSqZShQ4cud1EAAACwMlim0D1lypR07959kfb11lsvL7/88nIXBQAAACuDZQrdLVq0yCuvvLJI+8svv5wmTZosd1EAAACwMlim0L377rtnyJAhmTp1arnt5ZdfzrHHHpsf/OAHNVYcAAAArMiWKXSfc845adKkSdZbb7107tw5nTt3znrrrZdWrVrlvPPOq+kaAQAAYIVUb1k2atGiRR588MGMGzcuTz31VBo1apSNN9442267bU3XBwAAACuspRrpfuihh3LrrbcmSSoqKrLzzjunbdu2Oe+887Lnnnvmxz/+caqqqgopFAAAAFY0SxW6zzjjjDz33HPl5WeeeSaHHXZYdtpppwwdOjS33HJLhg0bVuNFAgAAwIpoqUL3k08+mR133LG8fM0112SLLbbI5ZdfnmOOOSYXXXRRrrvuuhovEgAAAFZESxW6p0+fnnbt2pWXJ0yYkH79+pWXN99880ybNq3mqgMAAIAV2FKF7nbt2uXVV19NksydOzePP/54vvvd75bXf/zxx6lfv37NVggAAAArqKUK3f3798/QoUNz//3358QTT0zjxo2rzVj+9NNPZ5111qnxIgEAAGBFtFRfGfbrX/86//M//5PevXunadOmGT16dBo0aFBe/8c//jE777xzjRcJAAAAK6KKUqlUWtqNZsyYkaZNm6Zu3brV2j/88MM0bdq0WhAv0syZM9OiRYvMmDEjzZs3/1qOCQAAAEuaR5dqpHuhFi1aLLZ91VVXXZbdAQAAwEppqe7pBgAAAJac0A0AAAAFEboBAACgIEI3AAAAFEToBgAAgIII3QAAAFAQoRsAAAAKInQDAABAQYRuAAAAKIjQDQAAAAURugEAAKAgQjcAAAAUROgGAACAggjdAAAAUBChGwAAAAoidAMAAEBBhG4AAAAoiNANAAAABRG6AQAAoCBCNwAAABRE6AYAAICCCN0AAABQEKEbAAAACiJ0AwAAQEGEbgAAACiI0A0AAAAFqdXQPWzYsGy++eZp1qxZ2rZtmz322CMvvvhibZYEAAAANaZWQ/eECRNy5JFH5uGHH864cePy2WefZeedd87s2bNrsywAAACoERWlUqlU20Us9N5776Vt27aZMGFCvve9731l/5kzZ6ZFixaZMWNGmjdv/jVUCAAAAEueR79R93TPmDEjSbLqqqvWciUAAACw/OrVdgELLViwIEOGDMnWW2+dDTfccLF9qqqqUlVVVV6eOXPm11UeAAAALLVvzEj3kUcemWeffTbXXHPNF/YZNmxYWrRoUX507Njxa6wQAAAAls434p7uo446KjfffHPuu+++dO7c+Qv7LW6ku2PHju7pBgAA4Gu1pPd01+rl5aVSKT/72c9y0003Zfz48V8auJOksrIylZWVX1N1AAAAsHxqNXQfeeSR+ctf/pKbb745zZo1y9tvv50kadGiRRo1alSbpQEAAMByq9XLyysqKhbbPnLkyAwaNOgrt/eVYQAAANSGFebycgAAAFhZfWNmLwcAAICVjdANAAAABRG6AQAAoCBCNwAAABRE6AYAAICCCN0AAABQEKEbAAAACiJ0AwAAQEGEbgAAACiI0A0AAAAFEboBAACgIEI3AAAAFEToBgAAgIII3QAAAFAQoRsAAAAKInQDAABAQYRuAAAAKIjQDQAAAAURugEAAKAgQjcAAAAUROgGAACAggjdAAAAUBChGwAAAAoidAMAAEBBhG4AAAAoiNANAAAABRG6AQAAoCBCNwAAABRE6AYAAICCCN0AAABQEKEbAAAACiJ0AwAAQEGEbgAAACiI0A0AAAAFEboBAACgIEI3AAAAFEToBgAAgIII3QAAAFAQoRsAAAAKInQDAABAQYRuAAAAKIjQDQAAAAURugEAAKAgQjcAAAAUROgGAACAggjdAAAAUBChGwAAAAoidAMAAEBBhG4AAAAoiNANAAAABRG6AQAAoCBCNwAAABRE6AYAAICCCN0AAABQEKEbAAAACiJ0AwAAQEGEbgAAACiI0A0AAAAFEboBAACgIEI3AAAAFEToBgAAgIII3QAAAFAQoRsAAAAKInQDAABAQYRuAAAAKIjQDQAAAAURugEAAKAgQjcAAAAUROgGAACAggjdAAAAUBChGwAAAAoidAMAAEBBhG4AAAAoiNANAAAABRG6AQAAoCBCNwAAABRE6AYAAICCCN0AAABQEKEbAAAACiJ0AwAAQEGEbgAAACiI0A0AAAAFEboBAACgIEI3AAAAFEToBgAAgIII3QAAAFAQoRsAAAAKInQDAABAQYRuAAAAKIjQDQAAAAURugEAAKAgQjcAAAAUROgGAACAggjdAAAAUJBaDd333Xdfdtttt3To0CEVFRUZM2ZMbZYDAAAANapWQ/fs2bOz8cYb55JLLqnNMgAAAKAQ9Wrz4P369Uu/fv1qswQAAAAoTK2G7qVVVVWVqqqq8vLMmTNrsRoAAAD4civURGrDhg1LixYtyo+OHTvWdkkAAADwhVao0H3iiSdmxowZ5ce0adNquyQAAAD4QivU5eWVlZWprKys7TIAAABgiaxQI90AAACwIqnVke5Zs2bl5ZdfLi+/+uqrefLJJ7PqqqtmzTXXrMXKAAAAYPnVauiePHlytt9++/LyMccckyQ56KCDMmrUqFqqCgAAAGpGrYbu7bbbLqVSqTZLAAAAgMK4pxsAAAAKInQDAABAQYRuAAAAKIjQDQAAAAURugEAAKAgQjcAAAAUROgGAACAggjdAAAAUBChGwAAAAoidAMAAEBBhG4AAAAoiNANAAAABRG6AQAAoCBCNwAAABRE6AYAAICCCN0AAABQEKEbAAAACiJ0AwAAQEGEbgAAACiI0A0AAAAFEboBAACgIEI3AAAAFEToBgAAgIII3QAAAFAQoRsAAAAKInQDAABAQYRuAAAAKIjQDQAAAAURugEAAKAgQjcAAAAUROgGAACAggjdAAAAUBChGwAAAAoidAMAAEBBhG4AAAAoiNANAAAABRG6AQAAoCBCNwAAABRE6AYAAICCCN0AAABQEKEbAAAACiJ0AwAAQEGEbgAAACiI0A0AAAAFEboBAACgIEI3AAAAFEToBgAAgIII3QAAAFAQoRsAAAAKInQDAABAQYRuAAAAKIjQDQAAAAURugEAAKAgQjcAAAAUROgGAACAggjdAAAAUBChGwAAAAoidAMAAEBBhG4AAAAoiNANAAAABRG6AQAAoCBCNwAAABRE6AYAAICCCN0AAABQEKEbAAAACiJ0AwAAQEGEbgAAACiI0A0AAAAFEboBAACgIEI3AAAAFEToBgAAgIII3QAAAFAQoRsAAAAKInQDAABAQYRuAAAAKIjQDQAAAAURugEAAKAgQjcAAAAUROgGAACAggjdAAAAUBChGwAAAAoidAMAAEBBhG4AAAAoiNANAAAABRG6AQAAoCBCNwAAABRE6AYAAICCCN0AAABQEKEbAAAACiJ0AwAAQEGEbgAAACiI0A0AAAAFEboBAACgIEI3AAAAFOQbEbovueSSdOrUKQ0bNsyWW26ZSZMm1XZJAAAAsNxqPXRfe+21OeaYY3Lqqafm8ccfz8Ybb5y+ffvm3Xffre3SAAAAYLnUeui+4IILcthhh+Xggw9O9+7dc9lll6Vx48b54x//WNulAQAAwHKpV5sHnzt3bh577LGceOKJ5bY6deqkT58+eeihhxbpX1VVlaqqqvLyjBkzkiQzZ84svlgAAAD4fxbm0FKp9KX9ajV0v//++5k/f37atWtXrb1du3b55z//uUj/YcOG5fTTT1+kvWPHjoXVCAAAAF/k448/TosWLb5wfa2G7qV14okn5phjjikvL1iwIB9++GFatWqVioqKWqyMldHMmTPTsWPHTJs2Lc2bN6/tcgBqnPc5YGXnfY4ilUqlfPzxx+nQocOX9qvV0N26devUrVs377zzTrX2d955J+3bt1+kf2VlZSorK6u1tWzZssgSIc2bN/cmDazUvM8BKzvvcxTly0a4F6rVidQaNGiQnj175p577im3LViwIPfcc0969epVi5UBAADA8qv1y8uPOeaYHHTQQdlss82yxRZb5He/+11mz56dgw8+uLZLAwAAgOVS66F73333zXvvvZdTTjklb7/9djbZZJPceeedi0yuBl+3ysrKnHrqqYvc0gCwsvA+B6zsvM/xTVBR+qr5zQEAAIBlUqv3dAMAAMDKTOgGAACAggjdAAAAUBChm5XS+PHjU1FRkY8++qi2SwEoxHbbbZchQ4bUdhkAhTjttNOyySab1HYZUCOEbr6RBg0alIqKilRUVKR+/frp3LlzfvGLX+TTTz+t7dIAvjaffy/8/OPll1+u7dIAvtTbb7+dn/3sZ1l77bVTWVmZjh07Zrfddss999xT26XB167WvzIMvsguu+ySkSNH5rPPPstjjz2Wgw46KBUVFTn77LNruzSAr83C98LPa9OmTS1VA/DVXnvttWy99dZp2bJlzj333Gy00Ub57LPPctddd+XII4/MP//5z1qpq1QqZf78+alXTwTi62Wkm2+sysrKtG/fPh07dswee+yRPn36ZNy4cUmSBQsWZNiwYencuXMaNWqUjTfeODfccMOX7u+BBx7Itttum0aNGqVjx44ZPHhwZs+enST55S9/mS233HKRbTbeeOOcccYZSZJHH300O+20U1q3bp0WLVqkd+/eefzxx6v1r6ioyBVXXJEBAwakcePG6dKlS8aOHVutz3PPPZddd901zZs3T7NmzbLttttm6tSp5fVXXHFF1l9//TRs2DDrrbdeLr300qU/ecBKY+F74ecfdevWXaRfRUVFxowZU62tZcuWGTVqVHl52rRp2WeffdKyZcusuuqq2X333fPaa6+V1w8aNCh77LFHzjvvvKy22mpp1apVjjzyyHz22WflPlVVVTnhhBPSsWPHVFZWZt11182VV16ZUqmUddddN+edd161Gp588kmj8/Atc8QRR6SioiKTJk3Knnvuma5du2aDDTbIMccck4cffjhJ8vrrr2f33XdP06ZN07x58+yzzz555513FtnXVVddlU6dOqVFixbZb7/98vHHH5fXfdXnwYW3G95xxx3p2bNnKisr88ADDyzxdvfcc08222yzNG7cOFtttVVefPHFarXdcsst2XzzzdOwYcO0bt06AwYMKK+rqqrKcccdl9VXXz1NmjTJlltumfHjx9fUKWYFI3SzQnj22Wfz4IMPpkGDBkmSYcOG5U9/+lMuu+yyPPfcczn66KPzwx/+MBMmTFjs9lOnTs0uu+ySPffcM08//XSuvfbaPPDAAznqqKOSJAMHDsykSZOqhd/nnnsuTz/9dP73f/83SfLxxx/noIMOygMPPJCHH344Xbp0Sf/+/au9+SfJ6aefnn322SdPP/10+vfvn4EDB+bDDz9Mkrzxxhv53ve+l8rKyvzjH//IY489lkMOOSTz5s1Lklx99dU55ZRTcuaZZ+aFF17Ib3/725x88skZPXp0zZ5Q4Fvns88+S9++fdOsWbPcf//9mThxYpo2bZpddtklc+fOLfe79957M3Xq1Nx7770ZPXp0Ro0aVS24H3jggfnrX/+aiy66KC+88EJGjBiRpk2bpqKiIocccsgio/IjR47M9773vay77rpf11MFatGHH36YO++8M0ceeWSaNGmyyPqWLVtmwYIF2X333fPhhx9mwoQJGTduXF555ZXsu+++1fpOnTo1Y8aMya233ppbb701EyZMyFlnnVVev6SfB4cOHZqzzjorL7zwQnr06LHE25100kk5//zzM3ny5NSrVy+HHHJIed1tt92WAQMGpH///nniiSdyzz33ZIsttiivP+qoo/LQQw/lmmuuydNPP5299947u+yyS6ZMmbJc55cVVAm+gQ466KBS3bp1S02aNClVVlaWkpTq1KlTuuGGG0qffvppqXHjxqUHH3yw2jaHHnpoaf/99y+VSqXSvffeW0pSmj59enndj3/842r977///lKdOnVKn3zySalUKpU23njj0hlnnFFef+KJJ5a23HLLL6xx/vz5pWbNmpVuueWWcluS0q9+9avy8qxZs0pJSnfccUd5n507dy7NnTt3sftcZ511Sn/5y1+qtf36178u9erV6wvrAFZen38vXPjYa6+9SqVSqdS7d+/Sz3/+83LfJKWbbrqp2vYtWrQojRw5slQqlUpXXXVVqVu3bqUFCxaU11dVVZUaNWpUuuuuu8rHW2uttUrz5s0r99l7771L++67b6lUKpVefPHFUpLSuHHjFlvvG2+8Uapbt27pkUceKZVKpdLcuXNLrVu3Lo0aNWq5zgOw4njkkUdKSUo33njjF/b5+9//Xqpbt27p9ddfL7c999xzpSSlSZMmlUqlUunUU08tNW7cuDRz5sxyn+OPP7782WxpPg+OGTOmvH5ptrv77rvL62+77bZSkvLnxl69epUGDhy42Of3r3/9q1S3bt3SG2+8Ua19xx13LJ144olfeF5YebmhgW+s7bffPsOHD8/s2bNz4YUXpl69etlzzz3z3HPPZc6cOdlpp52q9Z87d2423XTTxe7rqaeeytNPP52rr7663FYqlbJgwYK8+uqrWX/99TNw4MD88Y9/zMknn5xSqZS//vWvOeaYY8r933nnnfzqV7/K+PHj8+6772b+/PmZM2dOXn/99WrH6tGjR/nfTZo0SfPmzfPuu+8m+c9llttuu23q16+/SI2zZ8/O1KlTc+ihh+awww4rt8+bNy8tWrRYijMHrEwWvhcutLiRoyXx1FNP5eWXX06zZs2qtX/66afVrvLZYIMNql2+vtpqq+WZZ55J8p/3sLp166Z3796LPUaHDh3y/e9/P3/84x+zxRZb5JZbbklVVVX23nvvZaoZWPGUSqWv7PPCCy+kY8eO6dixY7mte/fuadmyZV544YVsvvnmSZJOnTpVe89abbXVyp+pXn755SX+PLjZZpuV/700233+M91qq62WJHn33Xez5ppr5sknn6z2ee3znnnmmcyfPz9du3at1l5VVZVWrVotdhtWbkI331hNmjQpX474xz/+MRtvvHGuvPLKbLjhhkn+c1nP6quvXm2bysrKxe5r1qxZOfzwwzN48OBF1q255ppJkv333z8nnHBCHn/88XzyySeZNm1atcucDjrooHzwwQf5/e9/n7XWWiuVlZXp1atXtcsykywSqCsqKrJgwYIkSaNGjb7w+c6aNStJcvnlly9yf/ni7t8Evh0+/174ZSoqKhb5sPv5e7FnzZqVnj17Vvvj40Kfn5htWd/DFvrRj36UAw44IBdeeGFGjhyZfffdN40bN/7K7YCVQ5cuXVJRUVEjk6V92fvRws9NS/J58PN/rFya7T5//IqKiiRZ4s90devWzWOPPbbIZ7imTZt+4XasvIRuVgh16tTJL3/5yxxzzDF56aWXUllZmddff/0LR1v+23e+8508//zzX/rBdY011kjv3r1z9dVX55NPPslOO+2Utm3bltdPnDgxl156afr375/kPxMSvf/++0v1PHr06JHRo0fns88+W+Q/knbt2qVDhw555ZVXMnDgwKXaL0CbNm3y1ltvlZenTJmSOXPmlJe/853v5Nprr03btm3TvHnzZTrGRhttlAULFmTChAnp06fPYvv0798/TZo0yfDhw3PnnXfmvvvuW6ZjASumVVddNX379s0ll1ySwYMHL3J1zkcffZT1118/06ZNy7Rp08qj3c8//3w++uijdO/efYmO071796X+PLg82/23Hj165J577snBBx+8yLpNN9008+fPz7vvvpttt912mY/BysNEaqww9t5779StWzcjRozIcccdl6OPPjqjR4/O1KlT8/jjj+fiiy/+wgnHTjjhhDz44IM56qij8uSTT2bKlCm5+eabyxOpLTRw4MBcc801uf766xcJvl26dMlVV12VF154IY888kgGDhy4RKM+n3fUUUdl5syZ2W+//TJ58uRMmTIlV111VXk2zNNPPz3Dhg3LRRddlJdeeinPPPNMRo4cmQsuuGCpjgN8++ywww75wx/+kCeeeCKTJ0/OT37yk2p/3Bs4cGBat26d3XffPffff39effXVjB8/PoMHD86///3vJTpGp06dctBBB+WQQw7JmDFjyvu47rrryn3q1q2bQYMG5cQTT0yXLl3Sq1evGn+uwDfbJZdckvnz52eLLbbI3/72t0yZMiUvvPBCLrroovTq1St9+vTJRhttlIEDB+bxxx/PpEmTcuCBB6Z3797VLgX/Ms2aNVvqz4PLs91/O/XUU/PXv/41p556al544YU888wz5a+17dq1awYOHJgDDzwwN954Y1599dVMmjQpw4YNy2233bbEx2DlIXSzwqhXr16OOuqonHPOOTnxxBNz8sknZ9iwYVl//fWzyy675Lbbbkvnzp0Xu22PHj0yYcKEvPTSS9l2222z6aab5pRTTkmHDh2q9dtrr73ywQcfZM6cOdljjz2qrbvyyiszffr0fOc738kBBxyQwYMHVxsJXxKtWrXKP/7xj8yaNSu9e/dOz549c/nll5c/GP/oRz/KFVdckZEjR2ajjTZK7969M2rUqC98XgALnX/++enYsWO23Xbb/O///m+OO+64apd1N27cOPfdd1/WXHPN/M///E/WX3/9HHroofn000+XauR7+PDh2WuvvXLEEUdkvfXWy2GHHVb++sWFDj300MydO3exI0DAym/ttdfO448/nu233z7HHntsNtxww+y000655557Mnz48FRUVOTmm2/OKqusku9973vp06dP1l577Vx77bVLdZxf//rXS/V5cHm3+7ztttsu119/fcaOHZtNNtkkO+ywQyZNmlReP3LkyBx44IE59thj061bt+yxxx559NFHy7c18u1SUVqS2Q4AAJbQ/fffnx133DHTpk1Lu3btarscAKhVQjcAUCOqqqry3nvv5aCDDkr79u0XO2kbAHzbuLwcAKgRf/3rX7PWWmvlo48+yjnnnFPb5QDAN4KRbgAAACiIkW4AAAAoiNANAAAABRG6AQAAoCBCNwAAABRE6AYAAICCCN0AAABQEKEbAAAACiJ0AwAAQEGEbgAAACjI/wfjmyCZKSyQrAAAAABJRU5ErkJggg==",
                        "text/plain": [
                            "<Figure size 1000x600 with 1 Axes>"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                }
            ],
            "source": [
                "def visualize_evaluation(basic_scores, engineered_scores, metrics):\n",
                "    \"\"\"Create a bar chart comparing evaluation scores\"\"\"\n",
                "    x = np.arange(len(metrics))\n",
                "    width = 0.35\n",
                "    \n",
                "    fig, ax = plt.subplots(figsize=(10, 6))\n",
                "    ax.bar(x - width/2, basic_scores, width, label='Basic Prompt')\n",
                "    ax.bar(x + width/2, engineered_scores, width, label='Engineered Prompt')\n",
                "    \n",
                "    ax.set_ylim(0, 5)\n",
                "    ax.set_ylabel('Score')\n",
                "    ax.set_title('Prompt Evaluation Comparison')\n",
                "    ax.set_xticks(x)\n",
                "    ax.set_xticklabels(metrics)\n",
                "    ax.legend()\n",
                "    \n",
                "    plt.tight_layout()\n",
                "    plt.show()\n",
                "\n",
                "# Extract scores\n",
                "basic_scores = [basic_relevance.get('score', 0), basic_fluency.get('score', 0), basic_coherence.get('score', 0)]\n",
                "engineered_scores = [engineered_relevance.get('score', 0), engineered_fluency.get('score', 0), engineered_coherence.get('score', 0)]\n",
                "metrics = ['Relevance', 'Fluency', 'Coherence']\n",
                "\n",
                "visualize_evaluation(basic_scores, engineered_scores, metrics)"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "60613576",
            "metadata": {},
            "source": [
                "## 8. Batch Evaluation with Multiple Prompts\n",
                "\n",
                "Now let's evaluate multiple prompts using the Azure AI Evaluation SDK's batch evaluation capabilities:"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 38,
            "id": "dfd28837",
            "metadata": {},
            "outputs": [
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "[2025-03-18 19:18:59 +0000][promptflow._core.entry_meta_generator][WARNING] - Generate meta in current process and timeout won't take effect. Please handle timeout manually outside current process.\n",
                        "[2025-03-18 19:18:59 +0000][promptflow._sdk._orchestrator.run_submitter][INFO] - Submitting run azure_ai_evaluation_evaluators_common_base_eval_asyncevaluatorbase_lsvwy698_20250318_191859_640440, log path: /home/vscode/.promptflow/.runs/azure_ai_evaluation_evaluators_common_base_eval_asyncevaluatorbase_lsvwy698_20250318_191859_640440/logs.txt\n",
                        "[2025-03-18 19:18:59 +0000][promptflow._core.entry_meta_generator][WARNING] - Generate meta in current process and timeout won't take effect. Please handle timeout manually outside current process.\n",
                        "[2025-03-18 19:18:59 +0000][promptflow._core.entry_meta_generator][WARNING] - Generate meta in current process and timeout won't take effect. Please handle timeout manually outside current process.\n",
                        "[2025-03-18 19:18:59 +0000][promptflow._sdk._orchestrator.run_submitter][INFO] - Submitting run azure_ai_evaluation_evaluators_common_base_eval_asyncevaluatorbase_qov0zlez_20250318_191859_642832, log path: /home/vscode/.promptflow/.runs/azure_ai_evaluation_evaluators_common_base_eval_asyncevaluatorbase_qov0zlez_20250318_191859_642832/logs.txt\n",
                        "[2025-03-18 19:18:59 +0000][promptflow._sdk._orchestrator.run_submitter][INFO] - Submitting run azure_ai_evaluation_evaluators_common_base_eval_asyncevaluatorbase_bkcr4e4n_20250318_191859_641786, log path: /home/vscode/.promptflow/.runs/azure_ai_evaluation_evaluators_common_base_eval_asyncevaluatorbase_bkcr4e4n_20250318_191859_641786/logs.txt\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "2025-03-18 19:18:59 +0000   46346 execution.bulk     INFO     Current thread is not main thread, skip signal handler registration in BatchEngine.\n",
                        "2025-03-18 19:19:01 +0000   46346 execution.bulk     INFO     Finished 1 / 3 lines.\n",
                        "2025-03-18 19:19:01 +0000   46346 execution.bulk     INFO     Average execution time for completed lines: 1.86 seconds. Estimated time for incomplete lines: 3.72 seconds.\n",
                        "2025-03-18 19:19:01 +0000   46346 execution.bulk     INFO     Finished 2 / 3 lines.\n",
                        "2025-03-18 19:19:01 +0000   46346 execution.bulk     INFO     Average execution time for completed lines: 0.97 seconds. Estimated time for incomplete lines: 0.97 seconds.\n",
                        "2025-03-18 19:19:02 +0000   46346 execution.bulk     INFO     Finished 3 / 3 lines.\n",
                        "2025-03-18 19:19:02 +0000   46346 execution.bulk     INFO     Average execution time for completed lines: 0.99 seconds. Estimated time for incomplete lines: 0.0 seconds.\n",
                        "======= Run Summary =======\n",
                        "\n",
                        "Run name: \"azure_ai_evaluation_evaluators_common_base_eval_asyncevaluatorbase_bkcr4e4n_20250318_191859_641786\"\n",
                        "Run status: \"Completed\"\n",
                        "Start time: \"2025-03-18 19:18:59.641281+00:00\"\n",
                        "Duration: \"0:00:03.162926\"\n",
                        "Output path: \"/home/vscode/.promptflow/.runs/azure_ai_evaluation_evaluators_common_base_eval_asyncevaluatorbase_bkcr4e4n_20250318_191859_641786\"\n",
                        "\n",
                        "2025-03-18 19:18:59 +0000   46346 execution.bulk     INFO     Current thread is not main thread, skip signal handler registration in BatchEngine.\n",
                        "2025-03-18 19:19:01 +0000   46346 execution.bulk     INFO     Finished 1 / 3 lines.\n",
                        "2025-03-18 19:19:01 +0000   46346 execution.bulk     INFO     Average execution time for completed lines: 2.15 seconds. Estimated time for incomplete lines: 4.3 seconds.\n",
                        "2025-03-18 19:19:02 +0000   46346 execution.bulk     INFO     Finished 2 / 3 lines.\n",
                        "2025-03-18 19:19:02 +0000   46346 execution.bulk     INFO     Average execution time for completed lines: 1.38 seconds. Estimated time for incomplete lines: 1.38 seconds.\n",
                        "2025-03-18 19:19:02 +0000   46346 execution.bulk     INFO     Finished 3 / 3 lines.\n",
                        "2025-03-18 19:19:02 +0000   46346 execution.bulk     INFO     Average execution time for completed lines: 0.95 seconds. Estimated time for incomplete lines: 0.0 seconds.\n",
                        "======= Run Summary =======\n",
                        "\n",
                        "Run name: \"azure_ai_evaluation_evaluators_common_base_eval_asyncevaluatorbase_qov0zlez_20250318_191859_642832\"\n",
                        "Run status: \"Completed\"\n",
                        "Start time: \"2025-03-18 19:18:59.642520+00:00\"\n",
                        "Duration: \"0:00:03.146735\"\n",
                        "Output path: \"/home/vscode/.promptflow/.runs/azure_ai_evaluation_evaluators_common_base_eval_asyncevaluatorbase_qov0zlez_20250318_191859_642832\"\n",
                        "\n",
                        "2025-03-18 19:19:03 +0000   46346 execution.bulk     INFO     Finished 2 / 3 lines.\n",
                        "2025-03-18 19:19:03 +0000   46346 execution.bulk     INFO     Average execution time for completed lines: 2.12 seconds. Estimated time for incomplete lines: 2.12 seconds.\n",
                        "2025-03-18 19:19:03 +0000   46346 execution.bulk     INFO     Finished 3 / 3 lines.\n",
                        "2025-03-18 19:19:04 +0000   46346 execution.bulk     INFO     Average execution time for completed lines: 1.42 seconds. Estimated time for incomplete lines: 0.0 seconds.\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "[2025-03-18 19:19:04 +0000][promptflow._core.entry_meta_generator][WARNING] - Generate meta in current process and timeout won't take effect. Please handle timeout manually outside current process.\n",
                        "[2025-03-18 19:19:04 +0000][promptflow._sdk._orchestrator.run_submitter][INFO] - Submitting run azure_ai_evaluation_evaluators_common_base_eval_asyncevaluatorbase_ahwwneqn_20250318_191904_842034, log path: /home/vscode/.promptflow/.runs/azure_ai_evaluation_evaluators_common_base_eval_asyncevaluatorbase_ahwwneqn_20250318_191904_842034/logs.txt\n",
                        "[2025-03-18 19:19:04 +0000][promptflow._core.entry_meta_generator][WARNING] - Generate meta in current process and timeout won't take effect. Please handle timeout manually outside current process.\n",
                        "[2025-03-18 19:19:04 +0000][promptflow._sdk._orchestrator.run_submitter][INFO] - Submitting run azure_ai_evaluation_evaluators_common_base_eval_asyncevaluatorbase_fpvubi_q_20250318_191904_839492, log path: /home/vscode/.promptflow/.runs/azure_ai_evaluation_evaluators_common_base_eval_asyncevaluatorbase_fpvubi_q_20250318_191904_839492/logs.txt\n",
                        "[2025-03-18 19:19:04 +0000][promptflow._core.entry_meta_generator][WARNING] - Generate meta in current process and timeout won't take effect. Please handle timeout manually outside current process.\n",
                        "[2025-03-18 19:19:04 +0000][promptflow._sdk._orchestrator.run_submitter][INFO] - Submitting run azure_ai_evaluation_evaluators_common_base_eval_asyncevaluatorbase_fd0pv69u_20250318_191904_843003, log path: /home/vscode/.promptflow/.runs/azure_ai_evaluation_evaluators_common_base_eval_asyncevaluatorbase_fd0pv69u_20250318_191904_843003/logs.txt\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "2025-03-18 19:18:59 +0000   46346 execution.bulk     INFO     Current thread is not main thread, skip signal handler registration in BatchEngine.\n",
                        "2025-03-18 19:19:02 +0000   46346 execution.bulk     INFO     Finished 1 / 3 lines.\n",
                        "2025-03-18 19:19:02 +0000   46346 execution.bulk     INFO     Average execution time for completed lines: 2.65 seconds. Estimated time for incomplete lines: 5.3 seconds.\n",
                        "2025-03-18 19:19:03 +0000   46346 execution.bulk     INFO     Finished 2 / 3 lines.\n",
                        "2025-03-18 19:19:03 +0000   46346 execution.bulk     INFO     Average execution time for completed lines: 2.12 seconds. Estimated time for incomplete lines: 2.12 seconds.\n",
                        "2025-03-18 19:19:03 +0000   46346 execution.bulk     INFO     Finished 3 / 3 lines.\n",
                        "2025-03-18 19:19:04 +0000   46346 execution.bulk     INFO     Average execution time for completed lines: 1.42 seconds. Estimated time for incomplete lines: 0.0 seconds.\n",
                        "======= Run Summary =======\n",
                        "\n",
                        "Run name: \"azure_ai_evaluation_evaluators_common_base_eval_asyncevaluatorbase_lsvwy698_20250318_191859_640440\"\n",
                        "Run status: \"Completed\"\n",
                        "Start time: \"2025-03-18 19:18:59.639871+00:00\"\n",
                        "Duration: \"0:00:05.135107\"\n",
                        "Output path: \"/home/vscode/.promptflow/.runs/azure_ai_evaluation_evaluators_common_base_eval_asyncevaluatorbase_lsvwy698_20250318_191859_640440\"\n",
                        "\n",
                        "======= Combined Run Summary (Per Evaluator) =======\n",
                        "\n",
                        "{\n",
                        "    \"relevance\": {\n",
                        "        \"status\": \"Completed\",\n",
                        "        \"duration\": \"0:00:05.135107\",\n",
                        "        \"completed_lines\": 3,\n",
                        "        \"failed_lines\": 0,\n",
                        "        \"log_path\": \"/home/vscode/.promptflow/.runs/azure_ai_evaluation_evaluators_common_base_eval_asyncevaluatorbase_lsvwy698_20250318_191859_640440\"\n",
                        "    },\n",
                        "    \"coherence\": {\n",
                        "        \"status\": \"Completed\",\n",
                        "        \"duration\": \"0:00:03.146735\",\n",
                        "        \"completed_lines\": 3,\n",
                        "        \"failed_lines\": 0,\n",
                        "        \"log_path\": \"/home/vscode/.promptflow/.runs/azure_ai_evaluation_evaluators_common_base_eval_asyncevaluatorbase_qov0zlez_20250318_191859_642832\"\n",
                        "    },\n",
                        "    \"fluency\": {\n",
                        "        \"status\": \"Completed\",\n",
                        "        \"duration\": \"0:00:03.162926\",\n",
                        "        \"completed_lines\": 3,\n",
                        "        \"failed_lines\": 0,\n",
                        "        \"log_path\": \"/home/vscode/.promptflow/.runs/azure_ai_evaluation_evaluators_common_base_eval_asyncevaluatorbase_bkcr4e4n_20250318_191859_641786\"\n",
                        "    }\n",
                        "}\n",
                        "\n",
                        "====================================================\n",
                        "\n",
                        "Evaluation results saved to \"/workspaces/ai-agents-hack/challenge-3/basic_evaluation_results.json\".\n",
                        "\n",
                        "2025-03-18 19:19:04 +0000   46346 execution.bulk     INFO     Current thread is not main thread, skip signal handler registration in BatchEngine.\n",
                        "2025-03-18 19:19:07 +0000   46346 execution.bulk     INFO     Finished 1 / 3 lines.\n",
                        "2025-03-18 19:19:07 +0000   46346 execution.bulk     INFO     Average execution time for completed lines: 2.17 seconds. Estimated time for incomplete lines: 4.34 seconds.\n",
                        "2025-03-18 19:19:07 +0000   46346 execution.bulk     INFO     Finished 2 / 3 lines.\n",
                        "2025-03-18 19:19:07 +0000   46346 execution.bulk     INFO     Average execution time for completed lines: 1.09 seconds. Estimated time for incomplete lines: 1.09 seconds.\n",
                        "2025-03-18 19:19:07 +0000   46346 execution.bulk     INFO     Finished 3 / 3 lines.\n",
                        "2025-03-18 19:19:07 +0000   46346 execution.bulk     INFO     Average execution time for completed lines: 1.03 seconds. Estimated time for incomplete lines: 0.0 seconds.\n",
                        "======= Run Summary =======\n",
                        "\n",
                        "Run name: \"azure_ai_evaluation_evaluators_common_base_eval_asyncevaluatorbase_fd0pv69u_20250318_191904_843003\"\n",
                        "Run status: \"Completed\"\n",
                        "Start time: \"2025-03-18 19:19:04.842742+00:00\"\n",
                        "Duration: \"0:00:04.084229\"\n",
                        "Output path: \"/home/vscode/.promptflow/.runs/azure_ai_evaluation_evaluators_common_base_eval_asyncevaluatorbase_fd0pv69u_20250318_191904_843003\"\n",
                        "\n",
                        "2025-03-18 19:19:04 +0000   46346 execution.bulk     INFO     Current thread is not main thread, skip signal handler registration in BatchEngine.\n",
                        "2025-03-18 19:19:07 +0000   46346 execution.bulk     INFO     Finished 1 / 3 lines.\n",
                        "2025-03-18 19:19:07 +0000   46346 execution.bulk     INFO     Average execution time for completed lines: 2.32 seconds. Estimated time for incomplete lines: 4.64 seconds.\n",
                        "2025-03-18 19:19:07 +0000   46346 execution.bulk     INFO     Finished 2 / 3 lines.\n",
                        "2025-03-18 19:19:07 +0000   46346 execution.bulk     INFO     Average execution time for completed lines: 1.35 seconds. Estimated time for incomplete lines: 1.35 seconds.\n",
                        "2025-03-18 19:19:08 +0000   46346 execution.bulk     INFO     Finished 3 / 3 lines.\n",
                        "2025-03-18 19:19:08 +0000   46346 execution.bulk     INFO     Average execution time for completed lines: 1.14 seconds. Estimated time for incomplete lines: 0.0 seconds.\n",
                        "======= Run Summary =======\n",
                        "\n",
                        "Run name: \"azure_ai_evaluation_evaluators_common_base_eval_asyncevaluatorbase_fpvubi_q_20250318_191904_839492\"\n",
                        "Run status: \"Completed\"\n",
                        "Start time: \"2025-03-18 19:19:04.838420+00:00\"\n",
                        "Duration: \"0:00:04.074665\"\n",
                        "Output path: \"/home/vscode/.promptflow/.runs/azure_ai_evaluation_evaluators_common_base_eval_asyncevaluatorbase_fpvubi_q_20250318_191904_839492\"\n",
                        "\n",
                        "2025-03-18 19:19:09 +0000   46346 execution.bulk     INFO     Finished 3 / 3 lines.\n",
                        "2025-03-18 19:19:09 +0000   46346 execution.bulk     INFO     Average execution time for completed lines: 1.57 seconds. Estimated time for incomplete lines: 0.0 seconds.\n",
                        "2025-03-18 19:19:04 +0000   46346 execution.bulk     INFO     Current thread is not main thread, skip signal handler registration in BatchEngine.\n",
                        "2025-03-18 19:19:07 +0000   46346 execution.bulk     INFO     Finished 1 / 3 lines.\n",
                        "2025-03-18 19:19:07 +0000   46346 execution.bulk     INFO     Average execution time for completed lines: 2.28 seconds. Estimated time for incomplete lines: 4.56 seconds.\n",
                        "2025-03-18 19:19:07 +0000   46346 execution.bulk     INFO     Finished 2 / 3 lines.\n",
                        "2025-03-18 19:19:07 +0000   46346 execution.bulk     INFO     Average execution time for completed lines: 1.54 seconds. Estimated time for incomplete lines: 1.54 seconds.\n",
                        "2025-03-18 19:19:09 +0000   46346 execution.bulk     INFO     Finished 3 / 3 lines.\n",
                        "2025-03-18 19:19:09 +0000   46346 execution.bulk     INFO     Average execution time for completed lines: 1.57 seconds. Estimated time for incomplete lines: 0.0 seconds.\n",
                        "======= Run Summary =======\n",
                        "\n",
                        "Run name: \"azure_ai_evaluation_evaluators_common_base_eval_asyncevaluatorbase_ahwwneqn_20250318_191904_842034\"\n",
                        "Run status: \"Completed\"\n",
                        "Start time: \"2025-03-18 19:19:04.841755+00:00\"\n",
                        "Duration: \"0:00:05.066523\"\n",
                        "Output path: \"/home/vscode/.promptflow/.runs/azure_ai_evaluation_evaluators_common_base_eval_asyncevaluatorbase_ahwwneqn_20250318_191904_842034\"\n",
                        "\n",
                        "======= Combined Run Summary (Per Evaluator) =======\n",
                        "\n",
                        "{\n",
                        "    \"relevance\": {\n",
                        "        \"status\": \"Completed\",\n",
                        "        \"duration\": \"0:00:04.074665\",\n",
                        "        \"completed_lines\": 3,\n",
                        "        \"failed_lines\": 0,\n",
                        "        \"log_path\": \"/home/vscode/.promptflow/.runs/azure_ai_evaluation_evaluators_common_base_eval_asyncevaluatorbase_fpvubi_q_20250318_191904_839492\"\n",
                        "    },\n",
                        "    \"coherence\": {\n",
                        "        \"status\": \"Completed\",\n",
                        "        \"duration\": \"0:00:05.066523\",\n",
                        "        \"completed_lines\": 3,\n",
                        "        \"failed_lines\": 0,\n",
                        "        \"log_path\": \"/home/vscode/.promptflow/.runs/azure_ai_evaluation_evaluators_common_base_eval_asyncevaluatorbase_ahwwneqn_20250318_191904_842034\"\n",
                        "    },\n",
                        "    \"fluency\": {\n",
                        "        \"status\": \"Completed\",\n",
                        "        \"duration\": \"0:00:04.084229\",\n",
                        "        \"completed_lines\": 3,\n",
                        "        \"failed_lines\": 0,\n",
                        "        \"log_path\": \"/home/vscode/.promptflow/.runs/azure_ai_evaluation_evaluators_common_base_eval_asyncevaluatorbase_fd0pv69u_20250318_191904_843003\"\n",
                        "    }\n",
                        "}\n",
                        "\n",
                        "====================================================\n",
                        "\n",
                        "Evaluation results saved to \"/workspaces/ai-agents-hack/challenge-3/engineered_evaluation_results.json\".\n",
                        "\n",
                        "Basic Prompt Evaluation Summary:\n"
                    ]
                },
                {
                    "ename": "AttributeError",
                    "evalue": "'NoneType' object has no attribute 'items'",
                    "output_type": "error",
                    "traceback": [
                        "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
                        "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
                        "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[38]\u001b[39m\u001b[32m, line 72\u001b[39m\n\u001b[32m     70\u001b[39m \u001b[38;5;66;03m# Display results\u001b[39;00m\n\u001b[32m     71\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mBasic Prompt Evaluation Summary:\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m72\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m metric, value \u001b[38;5;129;01min\u001b[39;00m \u001b[43mbasic_results\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43msummary\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mitems\u001b[49m():\n\u001b[32m     73\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmetric\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mvalue\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m     75\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33mEngineered Prompt Evaluation Summary:\u001b[39m\u001b[33m\"\u001b[39m)\n",
                        "\u001b[31mAttributeError\u001b[39m: 'NoneType' object has no attribute 'items'"
                    ]
                }
            ],
            "source": [
                "from azure.ai.evaluation import evaluate\n",
                "import json\n",
                "\n",
                "# Create a sample dataset for evaluation\n",
                "evaluation_data = [\n",
                "    {\n",
                "        \"query\": \"Summarize this research paper\",\n",
                "        \"ground_truth\": research_paper,\n",
                "        \"response_basic\": basic_summary,\n",
                "        \"response_engineered\": engineered_summary\n",
                "    },\n",
                "    {\n",
                "        \"query\": \"Review this Python code\",\n",
                "        \"ground_truth\": code_to_review,\n",
                "        \"response_basic\": await get_completion(f\"Review this Python code: {code_to_review}\"),\n",
                "        \"response_engineered\": code_review\n",
                "    },\n",
                "    {\n",
                "        \"query\": \"Analyze this sales data\",\n",
                "        \"ground_truth\": data_table,\n",
                "        \"response_basic\": standard_analysis,\n",
                "        \"response_engineered\": cot_analysis\n",
                "    }\n",
                "]\n",
                "\n",
                "# Write data to a JSONL file\n",
                "with open('evaluation_data.jsonl', 'w') as f:\n",
                "    for item in evaluation_data:\n",
                "        f.write(json.dumps(item) + '\\n')\n",
                "\n",
                "# Set up evaluators\n",
                "evaluators = {\n",
                "    \"relevance\": relevance_evaluator,\n",
                "    \"coherence\": coherence_evaluator,\n",
                "    \"fluency\": fluency_evaluator\n",
                "}\n",
                "\n",
                "# Run evaluation for basic responses\n",
                "basic_results = evaluate(\n",
                "    data=\"evaluation_data.jsonl\",\n",
                "    evaluators=evaluators,\n",
                "    evaluator_config={\n",
                "        \"default\": {\n",
                "            \"column_mapping\": {\n",
                "                \"query\": \"${data.query}\",\n",
                "                \"ground_truth\": \"${data.ground_truth}\",\n",
                "                \"response\": \"${data.response_basic}\"\n",
                "            }\n",
                "        }\n",
                "    },\n",
                "    output_path=\"basic_evaluation_results.json\"\n",
                ")\n",
                "\n",
                "# Run evaluation for engineered responses\n",
                "engineered_results = evaluate(\n",
                "    data=\"evaluation_data.jsonl\",\n",
                "    evaluators=evaluators,\n",
                "    evaluator_config={\n",
                "        \"default\": {\n",
                "            \"column_mapping\": {\n",
                "                \"query\": \"${data.query}\",\n",
                "                \"ground_truth\": \"${data.ground_truth}\",\n",
                "                \"response\": \"${data.response_engineered}\"\n",
                "            }\n",
                "        }\n",
                "    },\n",
                "    output_path=\"engineered_evaluation_results.json\"\n",
                ")\n",
                "\n",
                "# Display results\n",
                "print(\"Basic Prompt Evaluation Summary:\")\n",
                "for metric, value in basic_results.get('summary').items():\n",
                "    print(f\"{metric}: {value}\")\n",
                "\n",
                "print(\"\\nEngineered Prompt Evaluation Summary:\")\n",
                "for metric, value in engineered_results.get('summary').items():\n",
                "    print(f\"{metric}: {value}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "45823e02",
            "metadata": {},
            "source": [
                "## 9. Key Takeaways and Best Practices\n",
                "\n",
                "Based on our experiments with prompt engineering and evaluation, here are the key takeaways:\n",
                "\n",
                "1. **Clear Role Definition**: Defining the AI's role significantly improves response quality\n",
                "2. **Structured Formatting**: Requesting specific output formats produces more organized, usable outputs\n",
                "3. **Few-Shot Examples**: Providing examples dramatically improves the model's ability to follow patterns\n",
                "4. **Chain-of-Thought**: Guiding the model through a reasoning process improves analytical outputs\n",
                "5. **Quantitative Evaluation**: Using consistent metrics helps identify areas for improvement\n",
                "6. **Multiple Metrics**: Evaluating along different dimensions provides a more complete picture of prompt quality\n",
                "\n",
                "These principles can be applied to any prompt engineering task and help create more effective AI interactions."
            ]
        },
        {
            "cell_type": "markdown",
            "id": "7c952c06",
            "metadata": {},
            "source": [
                "## 10. Conclusion\n",
                "\n",
                "In this challenge, we've explored fundamental prompt engineering techniques and evaluation methods using Microsoft's Azure AI Evaluation SDK. We've seen how different prompting approaches can dramatically improve the quality, relevance, and usefulness of AI-generated content.\n",
                "\n",
                "By applying structured evaluation metrics, we were able to quantitatively measure improvements and guide our prompt refinement process. This systematic approach to prompt engineering can be applied to many different business scenarios, helping to create more effective AI interactions."
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.11.11"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 5
}
