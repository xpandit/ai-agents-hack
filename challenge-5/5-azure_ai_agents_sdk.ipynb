{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "66ee8996",
   "metadata": {},
   "source": [
    "# Challenge 5: Azure AI Agents SDK - Employee Onboarding & IT Support\n",
    "\n",
    "In this notebook, we'll explore the Azure AI Agents SDK through a series of focused examples. Unlike the previous notebook that used Semantic Kernel, this one will leverage the Azure AI Agents SDK to create AI assistants with various capabilities.\n",
    "\n",
    "The examples all revolve around employee onboarding and IT support, but each one focuses on a different capability of the Azure AI Agents SDK. You can run them independently and modify them to experiment with different aspects of the SDK.\n",
    "\n",
    "## What is Azure AI Agents SDK?\n",
    "\n",
    "The Azure AI Agents SDK is a client library that allows you to build and run AI agents in Azure. It provides capabilities to:\n",
    "\n",
    "- Create agents that can execute tasks and answer questions\n",
    "- Add tools like file search, code interpreter, and custom functions\n",
    "- Set up conversational threads to maintain context\n",
    "- Process runs to get agent responses\n",
    "- Track detailed run steps to understand agent behavior\n",
    "\n",
    "## Azure AI Agent Service Overview\n",
    "\n",
    "Azure AI Agent Service is a fully managed service designed to empower developers to securely build, deploy, and scale high-quality, and extensible AI agents without needing to manage the underlying compute and storage resources. What originally took hundreds of lines of code to support client-side function calling can now be done in just a few lines of code with Azure AI Agent Service.\n",
    "\n",
    "Within Azure AI Foundry, an AI Agent acts as a \"smart\" microservice that can be used to:\n",
    "\n",
    "- Answer questions (RAG)\n",
    "- Perform actions\n",
    "- Completely automate workflows\n",
    "\n",
    "It achieves this by combining the power of generative AI models with tools that allow it to access and interact with real-world data sources.\n",
    "\n",
    "## How Azure AI Agent Service Works\n",
    "\n",
    "The basic workflow of Azure AI Agent Service consists of:\n",
    "\n",
    "1. **Creating an agent** - Define the model, instructions, and tools the agent can use\n",
    "2. **Creating a thread** - This represents a conversation context\n",
    "3. **Adding messages** - Add user queries to the thread\n",
    "4. **Processing a run** - This invokes the agent to work on the thread\n",
    "5. **Getting responses** - Retrieve the agent's responses from the thread\n",
    "\n",
    "Whenever a run operation is invoked, Azure AI Agent Service completes the entire tool calling lifecycle by:\n",
    "1. Running the model with the provided instructions\n",
    "2. Invoking the tools as the agent calls them\n",
    "3. Returning the results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01c17acb",
   "metadata": {},
   "source": [
    "## Setting up the Environment\n",
    "\n",
    "First, let's install the necessary packages and set up our environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e1aecbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install azure-ai-projects azure-identity openai python-dotenv PyPDF2 matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b3bf8f1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import uuid\n",
    "import datetime\n",
    "from pathlib import Path\n",
    "from dotenv import load_dotenv\n",
    "from typing import List, Dict, Any, Optional, TypedDict, Annotated\n",
    "from enum import Enum\n",
    "from pydantic import BaseModel\n",
    "\n",
    "import asyncio\n",
    "import PyPDF2  # For reading PDF documents\n",
    "import matplotlib.pyplot as plt  # For creating charts\n",
    "import numpy as np\n",
    "from azure.core.credentials import AzureKeyCredential\n",
    "from azure.identity import DefaultAzureCredential\n",
    "\n",
    "# Import the Azure AI Projects SDK components\n",
    "from azure.ai.projects import AIProjectClient\n",
    "from azure.ai.projects.models import (\n",
    "    CodeInterpreterTool,\n",
    "    FunctionTool,\n",
    "    FileSearchTool,\n",
    "    ToolSet,\n",
    "    MessageTextContent,\n",
    "    MessageAttachment,\n",
    "    ResponseFormatJsonSchemaType,\n",
    "    ResponseFormatJsonSchema\n",
    ")\n",
    "\n",
    "# Load environment variables\n",
    "load_dotenv()\n",
    "\n",
    "# Azure AI Project configuration\n",
    "project_connection_string = os.getenv(\"PROJECT_CONNECTION_STRING\")\n",
    "model_deployment_name = os.getenv(\"MODEL_DEPLOYMENT_NAME\", \"gpt-4o-mini\")\n",
    "\n",
    "# Initialize the AI Project client\n",
    "project_client = AIProjectClient.from_connection_string(\n",
    "    credential=DefaultAzureCredential(),\n",
    "    conn_str=project_connection_string,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b40f0d1",
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "!az login >/dev/null && SUBSCRIPTION_ID=$(grep AZURE_SUBSCRIPTION_ID ../.env | cut -d= -f2) && az account set --subscription \"$SUBSCRIPTION_ID\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c8c05b6",
   "metadata": {},
   "source": [
    "## 1. Basic Agent for Employee Onboarding\n",
    "\n",
    "In this example, we'll create a simple agent that can answer basic questions about employee onboarding without any special tools.\n",
    "\n",
    "This is the most basic form of an agent that relies solely on the model's knowledge and the instructions we provide. It demonstrates the fundamental workflow of agent creation, conversation, and management.\n",
    "\n",
    "Let's break down the process step by step:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2168b8d5",
   "metadata": {},
   "source": [
    "### Step 1: Create a Basic Agent\n",
    "\n",
    "First, we'll create a basic agent with instructions about its role as an employee onboarding assistant.\n",
    "\n",
    "When creating an agent, we need to specify:\n",
    "- The AI model to use (model_deployment_name)\n",
    "- A descriptive name for the agent\n",
    "- Detailed instructions that define the agent's purpose, capabilities, and tone\n",
    "\n",
    "These instructions serve as the agent's \"system prompt\" that guides its behavior and responses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76a21f8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a basic agent\n",
    "agent = project_client.agents.create_agent(\n",
    "    model=model_deployment_name,\n",
    "    name=\"Onboarding Agent\",\n",
    "    instructions=\"\"\"\n",
    "    You are an Employee Onboarding Assistant designed to help new employees \n",
    "    get familiar with company policies and procedures. \n",
    "    \n",
    "    Answer questions about:\n",
    "    - First day procedures\n",
    "    - HR policies\n",
    "    - Company culture\n",
    "    - Office locations\n",
    "    - IT setup\n",
    "    \n",
    "    Always be helpful, concise, and welcoming to new employees.\n",
    "    \"\"\"\n",
    ")\n",
    "\n",
    "print(f\"Created agent, ID: {agent.id}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22598b21",
   "metadata": {},
   "source": [
    "If you navigate to Azure AI Foundry and click on the \"Agents\" tab, you will see the agent we just created.\n",
    "\n",
    "![Azure AI Foundry Agent Service](./images/agents-service.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bb51357",
   "metadata": {},
   "source": [
    "### Step 2: Create a Conversation Thread\n",
    "\n",
    "Next, we need to create a thread to hold our conversation with the agent. \n",
    "\n",
    "A thread represents a conversation session and maintains the context of the entire interaction. It stores all messages between the user and agent in chronological order, allowing the agent to reference previous parts of the conversation.\n",
    "\n",
    "Think of a thread like a messaging thread in a chat application - it contains the full history of a conversation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7bdc083",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a thread for the conversation\n",
    "thread = project_client.agents.create_thread()\n",
    "print(f\"Created thread, ID: {thread.id}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b32639b",
   "metadata": {},
   "source": [
    "### Step 3: Send a Message to the Agent\n",
    "\n",
    "Now we'll add a user message to the thread. This message contains the question or statement from the user that the agent will respond to.\n",
    "\n",
    "Messages always have a role (\"user\" or \"assistant\") and content (the actual text). \n",
    "\n",
    "At this point, we've only added the user's message to the thread, but the agent hasn't processed it yet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcea47d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add a message to the thread\n",
    "message = project_client.agents.create_message(\n",
    "    thread_id=thread.id,\n",
    "    role=\"user\",\n",
    "    content=\"Hi! I'm a new employee starting next week. What should I expect on my first day?\"\n",
    ")\n",
    "print(f\"Created message, ID: {message.id}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfa0086d",
   "metadata": {},
   "source": [
    "### Step 4: Process the Conversation\n",
    "\n",
    "After adding a message, we need to create and process a run to get the agent's response.\n",
    "\n",
    "A run represents a single execution of the agent on the thread. When we create and process a run:\n",
    "1. The agent reviews all messages in the thread (the conversation history)\n",
    "2. It generates a response based on its instructions and the messages\n",
    "3. The run completes with a status (completed, failed, etc.)\n",
    "\n",
    "This step is where the actual work happens - the model processes the conversation and generates a response."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1d8441e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create and process a run\n",
    "run = project_client.agents.create_and_process_run(\n",
    "    thread_id=thread.id, \n",
    "    agent_id=agent.id,\n",
    ")\n",
    "print(f\"Run finished with status: {run.status}\")\n",
    "\n",
    "if run.status == \"failed\":\n",
    "    print(f\"Run failed: {run.last_error}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26aa7810",
   "metadata": {},
   "source": [
    "### Step 5: Retrieve and Display Messages\n",
    "\n",
    "Let's retrieve all messages in the thread and display them. This will include both the user's message and the agent's response.\n",
    "\n",
    "The `list_messages` method returns all messages in the thread. We iterate through them in reverse order (newest to oldest) to display the conversation in chronological order.\n",
    "\n",
    "Each message has content which can be of different types. In this case, we're only interested in text content."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be69605f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get all messages in the thread\n",
    "messages = project_client.agents.list_messages(thread_id=thread.id)\n",
    "\n",
    "# The messages are following in the reverse order,\n",
    "# we will iterate them and output only text contents.\n",
    "for message in reversed(messages.data):\n",
    "    last_message_content = message.content[-1]\n",
    "    if isinstance(last_message_content, MessageTextContent):\n",
    "        print(f\"{message.role}: {last_message_content.text.value}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ca7d17f",
   "metadata": {},
   "source": [
    "### Step 6: Send a Follow-up Question\n",
    "\n",
    "Let's see how the agent handles a follow-up question about IT equipment.\n",
    "\n",
    "One of the advantages of using threads is that they maintain context across multiple messages. This means the agent can understand the follow-up question in the context of the previous conversation.\n",
    "\n",
    "We simply add another user message to the existing thread."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1754d4bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ask a follow-up question\n",
    "follow_up = project_client.agents.create_message(\n",
    "    thread_id=thread.id,\n",
    "    role=\"user\",\n",
    "    content=\"What IT equipment will I be provided with?\"\n",
    ")\n",
    "print(f\"Created follow-up message, ID: {follow_up.id}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "445b8eb4",
   "metadata": {},
   "source": [
    "### Step 7: Process the Follow-up Question\n",
    "\n",
    "Process the run to get the agent's response to the follow-up. This creates a new run on the same thread.\n",
    "\n",
    "The agent will have access to the entire conversation history when generating its response to the follow-up question."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12db6ff6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process the follow-up\n",
    "run = project_client.agents.create_and_process_run(\n",
    "    thread_id=thread.id, \n",
    "    agent_id=agent.id\n",
    ")\n",
    "print(f\"Run finished with status: {run.status}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b750ea0",
   "metadata": {},
   "source": [
    "### Step 8: Display the Updated Conversation\n",
    "\n",
    "Now let's see all messages in the conversation, including the agent's response to our follow-up.\n",
    "\n",
    "This demonstrates how the thread maintains the entire conversation history, allowing for contextual, multi-turn interactions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d64ca8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get updated messages\n",
    "messages = project_client.agents.list_messages(thread_id=thread.id)\n",
    "\n",
    "# Display the assistant's response to the follow-up\n",
    "for message in reversed(messages.data):\n",
    "    last_message_content = message.content[-1]\n",
    "    if isinstance(last_message_content, MessageTextContent):\n",
    "        print(f\"{message.role}: {last_message_content.text.value}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39d080b5",
   "metadata": {},
   "source": [
    "### Step 9: Clean Up Resources\n",
    "\n",
    "When we're done with the agent, we should clean up by deleting it.\n",
    "\n",
    "It's good practice to clean up resources when they're no longer needed to avoid accumulating unused agents in your Azure subscription."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18ff828a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean up\n",
    "project_client.agents.delete_agent(agent.id)\n",
    "print(f\"Deleted agent: {agent.id}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4147665",
   "metadata": {},
   "source": [
    "## Understanding the Flow\n",
    "\n",
    "The above example demonstrates the basic flow of working with an agent:\n",
    "\n",
    "1. **Create an agent** - Define its capabilities and instructions\n",
    "2. **Create a thread** - This represents a conversation\n",
    "3. **Add messages** - Add user messages to the thread\n",
    "4. **Process a run** - This makes the agent respond to the messages\n",
    "5. **Retrieve messages** - Get all messages, including the agent's responses\n",
    "\n",
    "This pattern is common across all agent interactions, even when using more advanced capabilities like tools."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60255a3d",
   "metadata": {},
   "source": [
    "## 2. Agent with File Search\n",
    "\n",
    "In this example, we'll create an agent that can search through company documentation to find relevant information for new employees.\n",
    "\n",
    "This demonstrates one of the most powerful capabilities of Azure AI Agent Service - the ability to search through documents to find relevant information. This is known as Retrieval Augmented Generation (RAG) and allows the agent to provide responses based on specific information in your documents rather than just its pre-trained knowledge.\n",
    "\n",
    "We'll break down the process into individual steps:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "176a5c8e",
   "metadata": {},
   "source": [
    "### Step 1: Upload a File to the Agent Service\n",
    "\n",
    "First, we need to upload a document that the agent will be able to search through.\n",
    "\n",
    "The document contains information about company policies, procedures, and other details that the agent will use to answer questions. The `upload_file_and_poll` method uploads the file and waits for it to be processed.\n",
    "\n",
    "The `purpose` parameter is set to \"assistants\" to indicate that this file will be used by an agent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "182291f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Upload file to the agent service\n",
    "print(\"Step 1: Uploading document...\")\n",
    "file = project_client.agents.upload_file_and_poll(\n",
    "    file_path=\"./docs/contoso_electronics.pdf\", \n",
    "    purpose=\"assistants\"\n",
    ")\n",
    "print(f\"Uploaded file, file ID: {file.id}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dff17d96",
   "metadata": {},
   "source": [
    "### Step 2: Create a Vector Store from the File\n",
    "\n",
    "Next, we create a vector store that will allow the agent to search through the document efficiently.\n",
    "\n",
    "A vector store is a specialized database that converts text into numerical vectors (embeddings) and allows for semantic search. This means the agent can find information based on meaning, not just keyword matching.\n",
    "\n",
    "The vector store process:\n",
    "1. Breaks the document into chunks\n",
    "2. Converts each chunk into a vector representation\n",
    "3. Indexes these vectors for efficient retrieval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0b7d867",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a vector store with the uploaded file\n",
    "print(\"Step 2: Creating vector store...\")\n",
    "vector_store = project_client.agents.create_vector_store_and_poll(\n",
    "    file_ids=[file.id], \n",
    "    name=\"employee_handbook\"\n",
    ")\n",
    "print(f\"Created vector store, vector store ID: {vector_store.id}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dccb0f1",
   "metadata": {},
   "source": [
    "### Step 3: Create a File Search Tool\n",
    "\n",
    "Now we create a file search tool that will enable the agent to search through the vector store.\n",
    "\n",
    "The file search tool is a specialized capability that allows the agent to:\n",
    "1. Take the user's question\n",
    "2. Convert it to a vector representation\n",
    "3. Find the most semantically similar content in the vector store\n",
    "4. Use that content to inform its response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f7b3c5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create file search tool\n",
    "print(\"Step 3: Creating file search tool...\")\n",
    "file_search = FileSearchTool(vector_store_ids=[vector_store.id])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1c4713b",
   "metadata": {},
   "source": [
    "### Step 4: Create an Agent with File Search Capability\n",
    "\n",
    "We'll create an agent that knows how to use the file search tool to find information.\n",
    "\n",
    "Note how we pass the file search tool to the agent:\n",
    "- `tools=file_search.definitions` tells the agent what tools are available\n",
    "- `tool_resources=file_search.resources` provides the necessary resources for the tools\n",
    "\n",
    "The instructions guide the agent on how to use these tools to answer questions based on document content."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28542fee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the agent with file search capability\n",
    "print(\"Step 4: Creating agent with file search...\")\n",
    "search_agent = project_client.agents.create_agent(\n",
    "    model=model_deployment_name,\n",
    "    name=\"Document Search Agent\",\n",
    "    instructions=\"\"\"\n",
    "    You are a Document Search Assistant designed to help employees find information \n",
    "    in company documentation. \n",
    "    \n",
    "    When asked a question:\n",
    "    1. Search the company documents for relevant information\n",
    "    2. Provide a clear, concise answer based on the search results\n",
    "    3. Include specific references to the source document when appropriate\n",
    "    4. If the information isn't in the documents, acknowledge that and provide a general response\n",
    "    \n",
    "    Always maintain a helpful, professional tone.\n",
    "    \"\"\",\n",
    "    tools=file_search.definitions,\n",
    "    tool_resources=file_search.resources\n",
    ")\n",
    "\n",
    "print(f\"Created agent, ID: {search_agent.id}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bd87992",
   "metadata": {},
   "source": [
    "### Step 5: Create a Conversation Thread\n",
    "\n",
    "Create a new thread for the conversation with our document search agent.\n",
    "\n",
    "As in Example 1, a thread represents a conversation session and maintains context."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66d0c6de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a thread for the conversation\n",
    "print(\"Step 5: Creating a conversation thread...\")\n",
    "search_thread = project_client.agents.create_thread()\n",
    "print(f\"Created thread, ID: {search_thread.id}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77e80caf",
   "metadata": {},
   "source": [
    "### Step 6: Ask a Question About Company Policy\n",
    "\n",
    "Let's ask a question that should be answerable from the document.\n",
    "\n",
    "This is where we'll see the agent search through the document to find relevant information about remote work policies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c01c9df4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ask a question that should be answerable from the document\n",
    "question = \"What is the company's policy on remote work?\"\n",
    "print(f\"Asking: '{question}'\")\n",
    "\n",
    "search_message = project_client.agents.create_message(\n",
    "    thread_id=search_thread.id,\n",
    "    role=\"user\",\n",
    "    content=question\n",
    ")\n",
    "print(f\"Created message, ID: {search_message.id}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54523b94",
   "metadata": {},
   "source": [
    "### Step 7: Process the Conversation\n",
    "\n",
    "Process a run to get the agent's response to our question.\n",
    "\n",
    "During this process, the agent will:\n",
    "1. Understand the user's question\n",
    "2. Use the file search tool to find relevant information in the document\n",
    "3. Formulate a response based on the search results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03756f86",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create and process a run\n",
    "search_run = project_client.agents.create_and_process_run(\n",
    "    thread_id=search_thread.id, \n",
    "    agent_id=search_agent.id\n",
    ")\n",
    "print(f\"Run finished with status: {search_run.status}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "581a354a",
   "metadata": {},
   "source": [
    "### Step 8: Display the Agent's Response\n",
    "\n",
    "Let's see what the agent found in the document about our question.\n",
    "\n",
    "The response should be based on information from the document, not just the model's pre-trained knowledge."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58437eaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get messages in the thread\n",
    "search_messages = project_client.agents.list_messages(thread_id=search_thread.id)\n",
    "\n",
    "# Display the assistant's response\n",
    "for message in reversed(search_messages.data):\n",
    "    last_message_content = message.content[-1]\n",
    "    if isinstance(last_message_content, MessageTextContent):\n",
    "        print(f\"{message.role}: {last_message_content.text.value}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0309f4a",
   "metadata": {},
   "source": [
    "### Step 9: Ask a Follow-up Question\n",
    "\n",
    "Now let's ask a related follow-up question to see how the agent handles it.\n",
    "\n",
    "The agent should be able to understand that this follow-up is related to the previous question about remote work, and will search for information about equipment provided to remote workers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73e613bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ask a follow-up question\n",
    "follow_up = \"What equipment is provided to remote workers?\"\n",
    "print(f\"Asking follow-up: '{follow_up}'\")\n",
    "\n",
    "project_client.agents.create_message(\n",
    "    thread_id=search_thread.id,\n",
    "    role=\"user\",\n",
    "    content=follow_up\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dbad02d",
   "metadata": {},
   "source": [
    "### Step 10: Process the Follow-up Question\n",
    "\n",
    "Process another run to get the agent's response to our follow-up.\n",
    "\n",
    "Again, the agent will use the file search tool to find information in the document relevant to the follow-up question."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1358fda7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process the follow-up\n",
    "follow_up_run = project_client.agents.create_and_process_run(\n",
    "    thread_id=search_thread.id, \n",
    "    agent_id=search_agent.id\n",
    ")\n",
    "print(f\"Run finished with status: {follow_up_run.status}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebf612ab",
   "metadata": {},
   "source": [
    "### Step 11: Display the Updated Conversation\n",
    "\n",
    "Let's see the agent's response to our follow-up question.\n",
    "\n",
    "The agent's response should be based on information from the document that specifically addresses equipment for remote workers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92cc9c80",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get updated messages\n",
    "updated_messages = project_client.agents.list_messages(thread_id=search_thread.id)\n",
    "\n",
    "# Display the assistant's response to the follow-up\n",
    "for message in reversed(updated_messages.data):\n",
    "    last_message_content = message.content[-1]\n",
    "    if isinstance(last_message_content, MessageTextContent):\n",
    "        print(f\"{message.role}: {last_message_content.text.value}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bf9544b",
   "metadata": {},
   "source": [
    "### Step 12: View Run Steps (Optional)\n",
    "\n",
    "We can look at the run steps to understand how the agent used the file search tool.\n",
    "\n",
    "Run steps provide detailed information about what happened during the run, including:\n",
    "- What tools were called\n",
    "- What parameters were passed to the tools\n",
    "- What results were returned\n",
    "\n",
    "This is useful for debugging and understanding the agent's decision-making process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "614689e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# View run steps to understand the file search process\n",
    "print(\"Viewing run steps to understand file search process...\")\n",
    "run_steps = project_client.agents.list_run_steps(thread_id=search_thread.id, run_id=follow_up_run.id)\n",
    "\n",
    "for step in run_steps.data:\n",
    "    print(f\"Step {step['id']} status: {step['status']}\")\n",
    "\n",
    "    # Check if there are tool calls in the step details\n",
    "    step_details = step.get(\"step_details\", {})\n",
    "    tool_calls = step_details.get(\"tool_calls\", [])\n",
    "\n",
    "    if tool_calls:\n",
    "        print(\"  Tool calls:\")\n",
    "        for call in tool_calls:\n",
    "            print(f\"    Tool Call ID: {call.get('id')}\")\n",
    "            print(f\"    Type: {call.get('type')}\")\n",
    "\n",
    "            function_details = call.get(\"function\", {})\n",
    "            if function_details:\n",
    "                print(f\"    Function name: {function_details.get('name')}\")\n",
    "    print()  # add an extra newline between steps"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b7f1d7c",
   "metadata": {},
   "source": [
    "### Step 13: Experiment with the Agent's Capabilities\n",
    "\n",
    "Now that we've seen how the agent works, let's experiment with its capabilities.\n",
    "\n",
    "Try modifying the agent's instructions to see how it responds. Explore other questions that should be answerable from the document.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a507fe6d",
   "metadata": {},
   "source": [
    "### Step 14: Clean Up Resources\n",
    "\n",
    "Finally, let's clean up by deleting the agent.\n",
    "\n",
    "Remember, it's good practice to clean up resources when they're no longer needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "551b0175",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "# Clean up\n",
    "project_client.agents.delete_agent(search_agent.id)\n",
    "print(f\"Deleted agent: {search_agent.id}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "accb0867",
   "metadata": {},
   "source": [
    "## Understanding File Search in Agents\n",
    "\n",
    "In this example, we've seen how to:\n",
    "\n",
    "1. **Upload documents** - Provide knowledge sources for the agent\n",
    "2. **Create vector stores** - For efficient semantic search of document content\n",
    "3. **Create a file search tool** - Enable the agent to search documents\n",
    "4. **Use the agent to answer questions** - Based on document content rather than pre-trained knowledge\n",
    "\n",
    "This capability is particularly useful for knowledge-intensive applications where information is contained in documents.\n",
    "\n",
    "File search allows agents to:\n",
    "- Answer questions with company-specific information\n",
    "- Stay up-to-date with the latest documents\n",
    "- Provide more accurate and relevant responses\n",
    "- Reduce hallucinations by grounding responses in factual content"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1cfa646",
   "metadata": {},
   "source": [
    "## 3: Expense Document Classification Agent with JSON Schema Output\n",
    "\n",
    "In this example, we'll create an intelligent expense classification system that:\n",
    "1. Reads expense documents using PyPDF2\n",
    "2. Extracts the text content from the documents\n",
    "3. Sends the content to an agent for processing\n",
    "4. Receives structured JSON data about the expenses\n",
    "5. Prepares this data for storage in Azure Table Storage\n",
    "\n",
    "This demonstrates how to combine PDF text extraction with structured JSON schema output - a powerful combination for document processing workflows."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc715504",
   "metadata": {},
   "source": [
    "### Step 1: Define the JSON Schema for Expense Classification\n",
    "\n",
    "First, we'll define the structure we want our expense data to follow. This schema will guide the agent to output information in a consistent, structured format that's ready for database storage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "76826ecc",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "# Define JSON schema for expense document information\n",
    "class ExpenseCategory(str, Enum):\n",
    "    TRAVEL = \"Travel\"\n",
    "    MEALS = \"Meals\"\n",
    "    ACCOMMODATION = \"Accommodation\"\n",
    "    OFFICE_SUPPLIES = \"Office Supplies\"\n",
    "    CLIENT_ENTERTAINMENT = \"Client Entertainment\"\n",
    "    TRAINING = \"Training\"\n",
    "    OTHER = \"Other\"\n",
    "\n",
    "class ExpenseStatus(str, Enum):\n",
    "    PENDING = \"Pending\"\n",
    "    APPROVED = \"Approved\"\n",
    "    REJECTED = \"Rejected\"\n",
    "    NEEDS_CLARIFICATION = \"Needs Clarification\"\n",
    "\n",
    "class ExpenseClassification(BaseModel):\n",
    "    date: str  # Date of the expense\n",
    "    merchant: str  # Name of the vendor/merchant\n",
    "    amount: float  # Total amount\n",
    "    currency: str  # Currency code (USD, EUR, etc.)\n",
    "    category: ExpenseCategory  # Type of expense\n",
    "    description: str  # Description of the expense\n",
    "    employee_id: str  # ID of the employee submitting the expense\n",
    "    status: ExpenseStatus = ExpenseStatus.PENDING  # Default status is pending\n",
    "    notes: Optional[str] = None  # Any additional notes from the processor\n",
    "    invoice_id: str  # Unique identifier for the invoice"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1aeda18d",
   "metadata": {},
   "source": [
    "### Step 2: Function to Extract Text from PDF Documents\n",
    "\n",
    "Next, we'll create a utility function to extract text from PDF documents using PyPDF2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "2ec5458d",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def extract_text_from_pdf(file_path: str) -> str:\n",
    "    \"\"\"\n",
    "    Extract text content from a PDF file.\n",
    "    \n",
    "    Args:\n",
    "        file_path: Path to the PDF file\n",
    "        \n",
    "    Returns:\n",
    "        The extracted text content\n",
    "    \"\"\"\n",
    "    text = \"\"\n",
    "    try:\n",
    "        with open(file_path, 'rb') as file:\n",
    "            pdf_reader = PyPDF2.PdfReader(file)\n",
    "            \n",
    "            # Extract text from each page\n",
    "            for page_num in range(len(pdf_reader.pages)):\n",
    "                page = pdf_reader.pages[page_num]\n",
    "                text += page.extract_text() + \"\\n\\n\"\n",
    "                \n",
    "        return text\n",
    "    except Exception as e:\n",
    "        print(f\"Error extracting text from PDF: {str(e)}\")\n",
    "        return f\"Error processing PDF: {str(e)}\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b7b1aca",
   "metadata": {},
   "source": [
    "### Step 3: Create a Function to Save Data as Local JSON Files\n",
    "\n",
    "Next, we'll define a function that will save our structured expense data as JSON files in a local \"processed\" folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "0d031611",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to save expense data to local JSON file\n",
    "async def save_expense_to_file(expense_data: dict) -> str:\n",
    "    \"\"\"\n",
    "    Save classified expense data to a local JSON file in the 'processed' folder.\n",
    "    \n",
    "    Args:\n",
    "        expense_data: The structured expense data from the agent\n",
    "        \n",
    "    Returns:\n",
    "        The path to the saved file\n",
    "    \"\"\"\n",
    "    # Create processed directory if it doesn't exist\n",
    "    processed_dir = Path(\"./docs/processed\")\n",
    "    processed_dir.mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "    # Generate a filename based on the invoice ID or a timestamp if not available\n",
    "    if \"invoice_id\" in expense_data and expense_data[\"invoice_id\"]:\n",
    "        filename = f\"{expense_data['invoice_id']}.json\"\n",
    "    else:\n",
    "        timestamp = datetime.datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "        filename = f\"expense_{timestamp}.json\"\n",
    "    \n",
    "    file_path = processed_dir / filename\n",
    "    \n",
    "    # Add a receipt ID and timestamp for tracking\n",
    "    expense_data[\"receipt_id\"] = f\"RCPT-{uuid.uuid4().hex[:8].upper()}\"\n",
    "    expense_data[\"processed_at\"] = datetime.datetime.now().isoformat()\n",
    "    \n",
    "    # Save to file\n",
    "    with open(file_path, 'w') as f:\n",
    "        json.dump(expense_data, indent=2, default=str, fp=f)\n",
    "    \n",
    "    print(f\"[LOCAL] Expense data saved to: {file_path}\")\n",
    "    print(f\"Receipt ID: {expense_data['receipt_id']}\")\n",
    "    \n",
    "    return str(file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e035186b",
   "metadata": {},
   "source": [
    "### Step 5: Create an Expense Processing Agent with JSON Schema Output\n",
    "\n",
    "Now, we'll create an agent specifically designed to process expense document text and output structured data according to our schema."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b31cd527",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the agent with JSON schema output format\n",
    "print(\"Creating Expense Processing Agent...\")\n",
    "expense_agent = project_client.agents.create_agent(\n",
    "    model=model_deployment_name,\n",
    "    name=\"Expense Classification Agent\",\n",
    "    instructions=\"\"\"\n",
    "    You are an Expense Classification Agent designed to process expense document text and extract key information.\n",
    "    \n",
    "    When provided with text extracted from an expense document (receipt, invoice, etc.):\n",
    "    1. Carefully analyze the document content\n",
    "    2. Extract all relevant expense information\n",
    "    3. Classify the expense into the appropriate category\n",
    "    4. Structure the output according to the JSON schema\n",
    "    5. If any information is uncertain, note it in the 'notes' field\n",
    "    \n",
    "    Be precise with numerical values and dates. If the document currency is not specified,\n",
    "    assume USD. If employee_id is not in the document, use 'UNKNOWN'.\n",
    "    \n",
    "    For invoice_id, look for an invoice number or receipt number in the document. \n",
    "    If none is found, generate a unique ID with prefix 'INV-' followed by the current date in YYYYMMDD format\n",
    "    and a 4-digit sequence number, e.g., 'INV-20231025-0001'.\n",
    "    \"\"\",\n",
    "    headers={\"x-ms-enable-preview\": \"true\"},\n",
    "    response_format=ResponseFormatJsonSchemaType(\n",
    "        json_schema=ResponseFormatJsonSchema(\n",
    "            name=\"expense_classification\",\n",
    "            description=\"Extract and classify expense information from document text.\",\n",
    "            schema=ExpenseClassification.model_json_schema(),\n",
    "        )\n",
    "    )\n",
    ")\n",
    "\n",
    "print(f\"Created agent, ID: {expense_agent.id}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68f90e30",
   "metadata": {},
   "source": [
    "### Step 6: Create a Function to Process Expense Documents\n",
    "\n",
    "Let's create a function that will handle the entire expense processing workflow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "ba958f34",
   "metadata": {},
   "outputs": [],
   "source": [
    "async def process_expense_document(file_path: str) -> dict:\n",
    "    \"\"\"\n",
    "    Process an expense document and return structured data.\n",
    "    \n",
    "    Args:\n",
    "        file_path: Path to the expense document file\n",
    "        \n",
    "    Returns:\n",
    "        Structured expense data ready for storage\n",
    "    \"\"\"\n",
    "    print(f\"Processing expense document: {file_path}\")\n",
    "    \n",
    "    # Step 1: Extract text from the PDF\n",
    "    document_text = extract_text_from_pdf(file_path)\n",
    "    if document_text.startswith(\"Error\"):\n",
    "        return {\"error\": document_text}\n",
    "    \n",
    "    print(f\"Successfully extracted text from PDF ({len(document_text)} characters)\")\n",
    "    \n",
    "    # Step 2: Create a thread for this document\n",
    "    thread = project_client.agents.create_thread()\n",
    "    print(f\"Created thread, ID: {thread.id}\")\n",
    "    \n",
    "    # Step 3: Create a message with the document text\n",
    "    message = project_client.agents.create_message(\n",
    "        thread_id=thread.id,\n",
    "        role=\"user\",\n",
    "        content=f\"Please analyze this expense document text and extract all relevant information:\\n\\n{document_text}\"\n",
    "    )\n",
    "    print(f\"Created message with document text, ID: {message.id}\")\n",
    "    \n",
    "    # Step 4: Process the run\n",
    "    run = project_client.agents.create_and_process_run(\n",
    "        thread_id=thread.id, \n",
    "        agent_id=expense_agent.id\n",
    "    )\n",
    "    print(f\"Run finished with status: {run.status}\")\n",
    "    \n",
    "    if run.status != \"completed\":\n",
    "        print(f\"Run failed with status: {run.status}\")\n",
    "        return {\"error\": f\"Processing failed with status: {run.status}\"}\n",
    "    \n",
    "    # Step 5: Get the agent's response\n",
    "    messages = project_client.agents.list_messages(thread_id=thread.id)\n",
    "    \n",
    "    # Find the agent's response (should be structured JSON)\n",
    "    for message in messages.data:\n",
    "        if message.role == \"assistant\":\n",
    "            last_message_content = message.content[-1]\n",
    "            if isinstance(last_message_content, MessageTextContent):\n",
    "                # Parse the JSON response\n",
    "                try:\n",
    "                    expense_data = json.loads(last_message_content.text.value)\n",
    "                    print(\"Successfully extracted expense data!\")\n",
    "                    \n",
    "                    # Step 6: Save to local file\n",
    "                    file_path = await save_expense_to_file(expense_data)\n",
    "                    \n",
    "                    # Add the file path to the data\n",
    "                    expense_data[\"file_path\"] = file_path\n",
    "                    \n",
    "                    return expense_data\n",
    "                except json.JSONDecodeError:\n",
    "                    print(\"Failed to parse JSON from agent response\")\n",
    "                    return {\"error\": \"Failed to parse JSON from agent response\"}\n",
    "    \n",
    "    return {\"error\": \"No valid response from agent\"}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f675f66",
   "metadata": {},
   "source": [
    "### Step 7: Test the Expense Processing System\n",
    "\n",
    "Now, let's test our expense classification system with a sample expense document."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39293ca8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path to a sample expense document\n",
    "sample_expense_path = \"./docs/expenses/contoso_foods.pdf\"\n",
    "\n",
    "expense_result = await process_expense_document(sample_expense_path)\n",
    "\n",
    "# Display the structured result\n",
    "print(\"\\nExpense Classification Result:\")\n",
    "print(json.dumps(expense_result, indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3b1f907",
   "metadata": {},
   "source": [
    "### Step 8: Process Multiple Documents\n",
    "\n",
    "In a real-world scenario, you might want to process multiple expense documents in batch. Here's how you could do that:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "fb1d144d",
   "metadata": {},
   "outputs": [],
   "source": [
    "async def process_expense_batch(file_paths: List[str]) -> List[dict]:\n",
    "    \"\"\"\n",
    "    Process multiple expense documents in batch.\n",
    "    \n",
    "    Args:\n",
    "        file_paths: List of paths to expense documents\n",
    "        \n",
    "    Returns:\n",
    "        List of structured expense data dictionaries\n",
    "    \"\"\"\n",
    "    results = []\n",
    "    \n",
    "    print(f\"Processing batch of {len(file_paths)} expense documents...\")\n",
    "    \n",
    "    for file_path in file_paths:\n",
    "        try:\n",
    "            result = await process_expense_document(file_path)\n",
    "            results.append(result)\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing {file_path}: {str(e)}\")\n",
    "            results.append({\"file\": file_path, \"error\": str(e)})\n",
    "    \n",
    "    print(f\"Batch processing complete. Processed {len(results)} documents.\")\n",
    "    return results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ca847f8",
   "metadata": {},
   "source": [
    "### Process a Batch of Documents\n",
    "\n",
    "If you have multiple expense documents, you can process them all at once:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "034bf5d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example of processing multiple documents\n",
    "expense_documents = [\n",
    "    \"./docs/expenses/contoso_coffee.pdf\",\n",
    "    \"./docs/expenses/contoso_air.pdf\"\n",
    "]\n",
    "# Uncomment to process multiple documents\n",
    "batch_results = await process_expense_batch(expense_documents)\n",
    "print(f\"Processed {len(batch_results)} documents\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "943078d0",
   "metadata": {},
   "source": [
    "### Step 9: Clean Up Resources\n",
    "\n",
    "When you're done with the agent, you should clean up by deleting it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e46e06bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "project_client.agents.delete_agent(expense_agent.id)  # This await will work in Jupyter\n",
    "print(f\"Deleted agent: {expense_agent.id}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "451b1b01",
   "metadata": {},
   "source": [
    "## Understanding the Expense Classification System\n",
    "\n",
    "In this example, we've created a sophisticated document processing system that combines:\n",
    "\n",
    "1. **PyPDF2 text extraction** - To read content from PDF documents\n",
    "2. **JSON schema output** - To ensure structured, consistent data extraction\n",
    "3. **Local JSON storage** - To persist the classified data for further analysis\n",
    "4. **Data visualization** - To analyze the processed expenses\n",
    "\n",
    "This approach demonstrates a powerful AI-driven workflow that could be used in many business contexts:\n",
    "\n",
    "- **Accounts payable automation** - Processing vendor invoices\n",
    "- **Employee expense report processing** - Validating and classifying expenses\n",
    "- **Document categorization systems** - Sorting and filing digital documents\n",
    "- **Data extraction pipelines** - Pulling structured data from unstructured documents\n",
    "\n",
    "By converting PDFs to text first and saving to local JSON files, we've created a simple but powerful system that:\n",
    "- Works offline after initial model setup\n",
    "- Keeps your data local and private\n",
    "- Allows for easy data analysis and visualization\n",
    "- Can be extended to process batches of documents"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2d29fbf",
   "metadata": {},
   "source": [
    "### Step 10: Analyze Expense Data Using Code Interpreter\n",
    "\n",
    "Now let's create a more dynamic analysis using the Azure AI Agents SDK's code interpreter capability.\n",
    "This approach allows the AI to write and execute custom analysis code based on the actual data.\n",
    "\n",
    "What this means is that the agent will dynamically generate and execute Python code to analyze and visualize the data. This is a powerful way to get the agent to do complex analysis and visualization tasks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "61fa438d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image, display\n",
    "from pathlib import Path\n",
    "\n",
    "# Function to retrieve and display images from Azure AI Agent Service\n",
    "def display_agent_generated_images(messages, project_client):\n",
    "    \"\"\"\n",
    "    Retrieves and displays images generated by an Azure AI Agent with code interpreter.\n",
    "    \n",
    "    Args:\n",
    "        messages: The messages object containing file references\n",
    "        project_client: The Azure AI Project client instance\n",
    "    \"\"\"\n",
    "    # Create a directory to store the images\n",
    "    output_dir = Path(\"./visualization_output\")\n",
    "    output_dir.mkdir(exist_ok=True)\n",
    "    \n",
    "    saved_images = []\n",
    "    \n",
    "    # Check for image contents (direct image files)\n",
    "    for message in messages.data:\n",
    "        for content_item in message.content:\n",
    "            if hasattr(content_item, 'image_file') and content_item.image_file:\n",
    "                # Save the image file\n",
    "                file_id = content_item.image_file.file_id\n",
    "                file_name = f\"{file_id}_image.png\"\n",
    "                file_path = output_dir / file_name\n",
    "                \n",
    "                # Save the file from the agent service\n",
    "                project_client.agents.save_file(file_id=file_id, file_name=file_name, target_dir=output_dir)\n",
    "                print(f\"Saved image file to: {file_path}\")\n",
    "                saved_images.append(file_path)\n",
    "    \n",
    "    # Check for file path annotations (references to saved files)\n",
    "    for message in messages.data:\n",
    "        if hasattr(message, 'file_path_annotations'):\n",
    "            for annotation in message.file_path_annotations:\n",
    "                file_id = annotation.file_path.file_id\n",
    "                file_name = Path(annotation.text).name\n",
    "                file_path = output_dir / file_name\n",
    "                \n",
    "                # Save the file from the agent service\n",
    "                project_client.agents.save_file(file_id=file_id, file_name=file_name, target_dir=output_dir)\n",
    "                print(f\"Saved file to: {file_path}\")\n",
    "                saved_images.append(file_path)\n",
    "    \n",
    "    # Display all saved images\n",
    "    for img_path in saved_images:\n",
    "        print(f\"\\nDisplaying: {img_path.name}\")\n",
    "        display(Image(str(img_path)))\n",
    "    \n",
    "    return saved_images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "c1fbcbab",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "async def analyze_expenses_with_code_interpreter():\n",
    "    \"\"\"\n",
    "    Use the AI Agent's code interpreter to analyze expense JSON files in the processed folder.\n",
    "    The agent will dynamically generate and execute Python code to analyze and visualize the data.\n",
    "    \"\"\"\n",
    "    # Use the correct path for the processed directory - look for it in multiple locations\n",
    "    processed_dir = Path(\"./docs/processed\")\n",
    "    if not processed_dir.exists():\n",
    "        processed_dir = Path(\"/workspaces/ai-agents-hack/challenge-5/docs/processed\")\n",
    "    \n",
    "    # Check if directory exists and has files\n",
    "    if not processed_dir.exists():\n",
    "        print(\"Processed directory not found. Please process some expense documents first.\")\n",
    "        return\n",
    "    \n",
    "    json_files = list(processed_dir.glob(\"*.json\"))\n",
    "    if not json_files:\n",
    "        print(\"No processed expense files found.\")\n",
    "        return\n",
    "    \n",
    "    print(f\"Found {len(json_files)} processed expense files in {processed_dir}\")\n",
    "    \n",
    "    # Load all expense data into a string representation\n",
    "    expenses_data = []\n",
    "    for file_path in json_files:\n",
    "        try:\n",
    "            with open(file_path, 'r') as f:\n",
    "                expense = json.load(f)\n",
    "                # Print the loaded expense for debugging\n",
    "                print(f\"Loaded expense from {file_path.name}:\")\n",
    "                print(f\"  Date: {expense.get('date')}\")\n",
    "                print(f\"  Merchant: {expense.get('merchant')}\")\n",
    "                print(f\"  Amount: {expense.get('amount')} {expense.get('currency')}\")\n",
    "                print(f\"  Category: {expense.get('category')}\")\n",
    "                expenses_data.append(expense)\n",
    "        except Exception as e:\n",
    "            print(f\"Error loading {file_path}: {str(e)}\")\n",
    "    \n",
    "    if not expenses_data:\n",
    "        print(\"No valid expense data found.\")\n",
    "        return\n",
    "    \n",
    "    print(f\"Successfully loaded {len(expenses_data)} expense records for analysis.\")\n",
    "    \n",
    "    # Convert the data to a JSON string for the agent\n",
    "    expenses_json = json.dumps(expenses_data, indent=2)\n",
    "    \n",
    "    # Create the code interpreter tool\n",
    "    code_interpreter = CodeInterpreterTool()\n",
    "    \n",
    "    # Create an agent with code interpreter capability\n",
    "    print(\"Creating expense analysis agent with code interpreter...\")\n",
    "    analysis_agent = project_client.agents.create_agent(\n",
    "        model=model_deployment_name,\n",
    "        name=\"Expense Analysis Agent\",\n",
    "        instructions=\"\"\"\n",
    "        You are an Expense Analysis Agent specialized in financial data analysis.\n",
    "        \n",
    "        When provided with expense data:\n",
    "        1. Analyze the data thoroughly using pandas and other data analysis libraries\n",
    "        2. Create insightful visualizations to reveal patterns and insights\n",
    "        3. Calculate key metrics such as total expenses by category, average costs, etc.\n",
    "        4. Identify outliers or unusual expense patterns\n",
    "        5. Provide a summary of your findings and recommendations\n",
    "        \n",
    "        Be thorough, data-driven, and focus on extracting meaningful insights.\n",
    "        Save all visualizations to files so they can be viewed later.\n",
    "        \"\"\",\n",
    "        tools=code_interpreter.definitions\n",
    "    )\n",
    "    \n",
    "    print(f\"Created agent, ID: {analysis_agent.id}\")\n",
    "    \n",
    "    # Create a thread for the analysis\n",
    "    thread = project_client.agents.create_thread()\n",
    "    print(f\"Created thread, ID: {thread.id}\")\n",
    "    \n",
    "    # Create a message with the expense data\n",
    "    analysis_prompt = f\"\"\"\n",
    "    Please analyze the following expense data from our processed JSON files.\n",
    "    Create visualizations and provide insights about spending patterns, categories, and any anomalies.\n",
    "    \n",
    "    Here's the expense data (in JSON format):\n",
    "    \n",
    "    {expenses_json}\n",
    "    \n",
    "    Please perform the following analyses:\n",
    "    1. Total expenses by category (pie chart)\n",
    "    2. Expenses by merchant (bar chart)\n",
    "    3. Identify any outliers in the expenses\n",
    "    4. Calculate summary statistics (mean, median, etc.)\n",
    "    5. Any other insights you can find in the data\n",
    "    \n",
    "    Save all visualizations to files in the current directory.\n",
    "    \"\"\"\n",
    "    \n",
    "    project_client.agents.create_message(\n",
    "        thread_id=thread.id,\n",
    "        role=\"user\",\n",
    "        content=analysis_prompt\n",
    "    )\n",
    "    \n",
    "    # Process the run\n",
    "    print(\"Processing analysis run...\")\n",
    "    run = project_client.agents.create_and_process_run(\n",
    "        thread_id=thread.id, \n",
    "        agent_id=analysis_agent.id\n",
    "    )\n",
    "    \n",
    "    print(f\"Run finished with status: {run.status}\")\n",
    "    \n",
    "    if run.status != \"completed\":\n",
    "        print(f\"Run failed with status: {run.status}\")\n",
    "        return\n",
    "    \n",
    "    # Get the agent's response\n",
    "    messages = project_client.agents.list_messages(thread_id=thread.id)\n",
    "    \n",
    "    # Find and display the agent's analysis\n",
    "    assistant_messages = [m for m in messages.data if m.role == \"assistant\"]\n",
    "    if assistant_messages:\n",
    "        last_message = assistant_messages[-1]\n",
    "        print(\"\\nExpense Analysis Results:\")\n",
    "        for content_item in last_message.content:\n",
    "            if isinstance(content_item, MessageTextContent):\n",
    "                print(content_item.text.value)\n",
    "    else:\n",
    "        print(\"No analysis results found.\")\n",
    "\n",
    "    # Retrieve and display images from the agent service\n",
    "    print(\"\\nRetrieving and displaying visualizations...\")\n",
    "    display_agent_generated_images(messages, project_client)\n",
    "    \n",
    "    # Clean up\n",
    "    project_client.agents.delete_agent(analysis_agent.id)\n",
    "    print(f\"Deleted agent: {analysis_agent.id}\")\n",
    "    \n",
    "    return \"Analysis complete\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4c3f2b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "expense_analysis_results = await analyze_expenses_with_code_interpreter()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7aa41bc",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "In this notebook, we explored the Azure AI Agents SDK through focused, independent examples that demonstrate its key capabilities:\n",
    "\n",
    "1. Creating basic agents for conversational interactions\n",
    "2. Enabling document search through file search tools\n",
    "3. Returning structured data with JSON schema functions\n",
    "4. Solving technical problems with code interpreter\n",
    "5. Combining multiple tools for comprehensive capabilities\n",
    "\n",
    "Each example is designed to be independently runnable, allowing you to experiment with specific features that interest you. Feel free to modify the examples, combine different techniques, or adapt them to your specific use cases.\n",
    "\n",
    "The Azure AI Agents SDK provides a powerful platform for building intelligent agents that can access various tools and resources to better assist users with their tasks. "
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "formats": "ipynb,py:percent"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
