{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7d3e6a46",
   "metadata": {},
   "source": [
    "# Challenge 5: Tool Usage & Agentic RAG\n",
    "\n",
    "In this challenge, we'll explore how to build an intelligent assistant that leverages Retrieval-Augmented Generation (RAG) in an agentic context. We'll create a system that can index company documentation, retrieve relevant information, and intelligently answer user queries.\n",
    "\n",
    "## What is Agentic RAG?\n",
    "\n",
    "Traditional RAG systems follow a linear process: retrieve relevant documents â†’ generate a response based on those documents. Agentic RAG takes this further by adding intelligent decision-making to the retrieval process:\n",
    "\n",
    "- **Dynamic Query Formulation**: The agent reformulates queries to improve search results\n",
    "- **Selective Retrieval**: The agent decides when to retrieve information and when to rely on its own knowledge\n",
    "- **Multi-step Reasoning**: The agent can perform multiple retrieval steps for complex questions\n",
    "- **Tool Integration**: The agent combines retrieval with other capabilities (calculations, API calls, etc.)\n",
    "\n",
    "## The Knowledge Base and Azure AI Search\n",
    "\n",
    "A knowledge base is a specialized database designed to store, organize, and retrieve information. In the context of AI applications:\n",
    "\n",
    "- **Knowledge bases** store structured or unstructured content (documents, FAQs, policies, etc.)\n",
    "- They're organized to facilitate quick and accurate information retrieval\n",
    "- They serve as the \"memory\" for AI agents, extending their knowledge beyond training data\n",
    "\n",
    "**Azure AI Search** (formerly Azure Cognitive Search) is Microsoft's cloud search service that enables:\n",
    "\n",
    "- **Document Ingestion**: Processing various file types (PDFs, Word, HTML, images with OCR, etc.)\n",
    "- **Indexing**: Creating searchable indexes with text analysis capabilities\n",
    "- **Semantic Search**: Using AI to understand query intent and contextual meaning\n",
    "- **Vector Search**: Utilizing embeddings to find conceptually similar content\n",
    "- **Hybrid Approaches**: Combining keyword and semantic search for optimal results\n",
    "\n",
    "In our agentic RAG system, Azure AI Search serves as the foundation for our knowledge base, enabling intelligent information retrieval to power our HR assistant."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6762493d",
   "metadata": {},
   "source": [
    "## 1. Setting up Our Environment\n",
    "\n",
    "First, let's install the necessary packages for our Agentic RAG implementation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9400a86",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: openai in /home/vscode/.local/lib/python3.11/site-packages (1.66.3)\n",
      "Requirement already satisfied: python-dotenv in /home/vscode/.local/lib/python3.11/site-packages (1.0.1)\n",
      "Requirement already satisfied: azure-search-documents in /home/vscode/.local/lib/python3.11/site-packages (11.5.2)\n",
      "Requirement already satisfied: semantic-kernel in /home/vscode/.local/lib/python3.11/site-packages (1.25.0)\n",
      "Requirement already satisfied: azure-identity in /home/vscode/.local/lib/python3.11/site-packages (1.21.0)\n",
      "Requirement already satisfied: PyPDF2 in /home/vscode/.local/lib/python3.11/site-packages (3.0.1)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in /home/vscode/.local/lib/python3.11/site-packages (from openai) (4.9.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /home/vscode/.local/lib/python3.11/site-packages (from openai) (1.9.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /home/vscode/.local/lib/python3.11/site-packages (from openai) (0.28.1)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in /home/vscode/.local/lib/python3.11/site-packages (from openai) (0.9.0)\n",
      "Requirement already satisfied: pydantic<3,>=1.9.0 in /home/vscode/.local/lib/python3.11/site-packages (from openai) (2.10.6)\n",
      "Requirement already satisfied: sniffio in /home/vscode/.local/lib/python3.11/site-packages (from openai) (1.3.1)\n",
      "Requirement already satisfied: tqdm>4 in /home/vscode/.local/lib/python3.11/site-packages (from openai) (4.67.1)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.11 in /home/vscode/.local/lib/python3.11/site-packages (from openai) (4.12.2)\n",
      "Requirement already satisfied: azure-core>=1.28.0 in /home/vscode/.local/lib/python3.11/site-packages (from azure-search-documents) (1.32.0)\n",
      "Requirement already satisfied: azure-common>=1.1 in /home/vscode/.local/lib/python3.11/site-packages (from azure-search-documents) (1.1.28)\n",
      "Requirement already satisfied: isodate>=0.6.0 in /home/vscode/.local/lib/python3.11/site-packages (from azure-search-documents) (0.7.2)\n",
      "Requirement already satisfied: aiohttp~=3.8 in /home/vscode/.local/lib/python3.11/site-packages (from semantic-kernel) (3.11.14)\n",
      "Requirement already satisfied: cloudevents~=1.0 in /home/vscode/.local/lib/python3.11/site-packages (from semantic-kernel) (1.11.0)\n",
      "Requirement already satisfied: pydantic-settings~=2.0 in /home/vscode/.local/lib/python3.11/site-packages (from semantic-kernel) (2.8.1)\n",
      "Requirement already satisfied: defusedxml~=0.7 in /home/vscode/.local/lib/python3.11/site-packages (from semantic-kernel) (0.7.1)\n",
      "Requirement already satisfied: numpy>=1.25.0 in /home/vscode/.local/lib/python3.11/site-packages (from semantic-kernel) (2.2.4)\n",
      "Requirement already satisfied: openapi_core<0.20,>=0.18 in /home/vscode/.local/lib/python3.11/site-packages (from semantic-kernel) (0.19.4)\n",
      "Requirement already satisfied: websockets<16,>=13 in /home/vscode/.local/lib/python3.11/site-packages (from semantic-kernel) (14.2)\n",
      "Requirement already satisfied: aiortc>=1.9.0 in /home/vscode/.local/lib/python3.11/site-packages (from semantic-kernel) (1.10.1)\n",
      "Requirement already satisfied: opentelemetry-api~=1.24 in /home/vscode/.local/lib/python3.11/site-packages (from semantic-kernel) (1.31.0)\n",
      "Requirement already satisfied: opentelemetry-sdk~=1.24 in /home/vscode/.local/lib/python3.11/site-packages (from semantic-kernel) (1.31.0)\n",
      "Requirement already satisfied: prance~=23.6.21.0 in /home/vscode/.local/lib/python3.11/site-packages (from semantic-kernel) (23.6.21.0)\n",
      "Requirement already satisfied: pybars4~=0.9 in /home/vscode/.local/lib/python3.11/site-packages (from semantic-kernel) (0.9.13)\n",
      "Requirement already satisfied: jinja2~=3.1 in /home/vscode/.local/lib/python3.11/site-packages (from semantic-kernel) (3.1.6)\n",
      "Requirement already satisfied: nest-asyncio~=1.6 in /home/vscode/.local/lib/python3.11/site-packages (from semantic-kernel) (1.6.0)\n",
      "Requirement already satisfied: scipy>=1.15.1 in /home/vscode/.local/lib/python3.11/site-packages (from semantic-kernel) (1.15.2)\n",
      "Requirement already satisfied: cryptography>=2.5 in /home/vscode/.local/lib/python3.11/site-packages (from azure-identity) (44.0.2)\n",
      "Requirement already satisfied: msal>=1.30.0 in /home/vscode/.local/lib/python3.11/site-packages (from azure-identity) (1.32.0)\n",
      "Requirement already satisfied: msal-extensions>=1.2.0 in /home/vscode/.local/lib/python3.11/site-packages (from azure-identity) (1.3.1)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /home/vscode/.local/lib/python3.11/site-packages (from aiohttp~=3.8->semantic-kernel) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /home/vscode/.local/lib/python3.11/site-packages (from aiohttp~=3.8->semantic-kernel) (1.3.2)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /home/vscode/.local/lib/python3.11/site-packages (from aiohttp~=3.8->semantic-kernel) (25.3.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /home/vscode/.local/lib/python3.11/site-packages (from aiohttp~=3.8->semantic-kernel) (1.5.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /home/vscode/.local/lib/python3.11/site-packages (from aiohttp~=3.8->semantic-kernel) (6.2.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /home/vscode/.local/lib/python3.11/site-packages (from aiohttp~=3.8->semantic-kernel) (0.3.0)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /home/vscode/.local/lib/python3.11/site-packages (from aiohttp~=3.8->semantic-kernel) (1.18.3)\n",
      "Requirement already satisfied: aioice<1.0.0,>=0.9.0 in /home/vscode/.local/lib/python3.11/site-packages (from aiortc>=1.9.0->semantic-kernel) (0.9.0)\n",
      "Requirement already satisfied: av<14.0.0,>=9.0.0 in /home/vscode/.local/lib/python3.11/site-packages (from aiortc>=1.9.0->semantic-kernel) (13.1.0)\n",
      "Requirement already satisfied: cffi>=1.0.0 in /home/vscode/.local/lib/python3.11/site-packages (from aiortc>=1.9.0->semantic-kernel) (1.17.1)\n",
      "Requirement already satisfied: google-crc32c>=1.1 in /home/vscode/.local/lib/python3.11/site-packages (from aiortc>=1.9.0->semantic-kernel) (1.7.0)\n",
      "Requirement already satisfied: pyee>=9.0.0 in /home/vscode/.local/lib/python3.11/site-packages (from aiortc>=1.9.0->semantic-kernel) (13.0.0)\n",
      "Requirement already satisfied: pylibsrtp>=0.10.0 in /home/vscode/.local/lib/python3.11/site-packages (from aiortc>=1.9.0->semantic-kernel) (0.11.0)\n",
      "Requirement already satisfied: pyopenssl>=24.0.0 in /home/vscode/.local/lib/python3.11/site-packages (from aiortc>=1.9.0->semantic-kernel) (25.0.0)\n",
      "Requirement already satisfied: idna>=2.8 in /home/vscode/.local/lib/python3.11/site-packages (from anyio<5,>=3.5.0->openai) (3.10)\n",
      "Requirement already satisfied: requests>=2.21.0 in /home/vscode/.local/lib/python3.11/site-packages (from azure-core>=1.28.0->azure-search-documents) (2.32.3)\n",
      "Requirement already satisfied: six>=1.11.0 in /home/vscode/.local/lib/python3.11/site-packages (from azure-core>=1.28.0->azure-search-documents) (1.17.0)\n",
      "Requirement already satisfied: deprecation<3.0,>=2.0 in /home/vscode/.local/lib/python3.11/site-packages (from cloudevents~=1.0->semantic-kernel) (2.1.0)\n",
      "Requirement already satisfied: certifi in /home/vscode/.local/lib/python3.11/site-packages (from httpx<1,>=0.23.0->openai) (2025.1.31)\n",
      "Requirement already satisfied: httpcore==1.* in /home/vscode/.local/lib/python3.11/site-packages (from httpx<1,>=0.23.0->openai) (1.0.7)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /home/vscode/.local/lib/python3.11/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.14.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/vscode/.local/lib/python3.11/site-packages (from jinja2~=3.1->semantic-kernel) (3.0.2)\n",
      "Requirement already satisfied: PyJWT<3,>=1.0.0 in /home/vscode/.local/lib/python3.11/site-packages (from PyJWT[crypto]<3,>=1.0.0->msal>=1.30.0->azure-identity) (2.10.1)\n",
      "Requirement already satisfied: jsonschema<5.0.0,>=4.18.0 in /home/vscode/.local/lib/python3.11/site-packages (from openapi_core<0.20,>=0.18->semantic-kernel) (4.23.0)\n",
      "Requirement already satisfied: jsonschema-path<0.4.0,>=0.3.1 in /home/vscode/.local/lib/python3.11/site-packages (from openapi_core<0.20,>=0.18->semantic-kernel) (0.3.4)\n",
      "Requirement already satisfied: more-itertools in /home/vscode/.local/lib/python3.11/site-packages (from openapi_core<0.20,>=0.18->semantic-kernel) (10.6.0)\n",
      "Requirement already satisfied: openapi-schema-validator<0.7.0,>=0.6.0 in /home/vscode/.local/lib/python3.11/site-packages (from openapi_core<0.20,>=0.18->semantic-kernel) (0.6.3)\n",
      "Requirement already satisfied: openapi-spec-validator<0.8.0,>=0.7.1 in /home/vscode/.local/lib/python3.11/site-packages (from openapi_core<0.20,>=0.18->semantic-kernel) (0.7.1)\n",
      "Requirement already satisfied: parse in /home/vscode/.local/lib/python3.11/site-packages (from openapi_core<0.20,>=0.18->semantic-kernel) (1.20.2)\n",
      "Requirement already satisfied: werkzeug in /home/vscode/.local/lib/python3.11/site-packages (from openapi_core<0.20,>=0.18->semantic-kernel) (3.1.3)\n",
      "Requirement already satisfied: deprecated>=1.2.6 in /home/vscode/.local/lib/python3.11/site-packages (from opentelemetry-api~=1.24->semantic-kernel) (1.2.18)\n",
      "Requirement already satisfied: importlib-metadata<8.7.0,>=6.0 in /home/vscode/.local/lib/python3.11/site-packages (from opentelemetry-api~=1.24->semantic-kernel) (8.6.1)\n",
      "Requirement already satisfied: opentelemetry-semantic-conventions==0.52b0 in /home/vscode/.local/lib/python3.11/site-packages (from opentelemetry-sdk~=1.24->semantic-kernel) (0.52b0)\n",
      "Requirement already satisfied: chardet>=3.0 in /home/vscode/.local/lib/python3.11/site-packages (from prance~=23.6.21.0->semantic-kernel) (5.2.0)\n",
      "Requirement already satisfied: ruamel.yaml>=0.17.10 in /home/vscode/.local/lib/python3.11/site-packages (from prance~=23.6.21.0->semantic-kernel) (0.18.10)\n",
      "Requirement already satisfied: packaging>=21.3 in /home/vscode/.local/lib/python3.11/site-packages (from prance~=23.6.21.0->semantic-kernel) (24.2)\n",
      "Requirement already satisfied: PyMeta3>=0.5.1 in /home/vscode/.local/lib/python3.11/site-packages (from pybars4~=0.9->semantic-kernel) (0.5.1)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /home/vscode/.local/lib/python3.11/site-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.27.2 in /home/vscode/.local/lib/python3.11/site-packages (from pydantic<3,>=1.9.0->openai) (2.27.2)\n",
      "Requirement already satisfied: dnspython>=2.0.0 in /home/vscode/.local/lib/python3.11/site-packages (from aioice<1.0.0,>=0.9.0->aiortc>=1.9.0->semantic-kernel) (2.7.0)\n",
      "Requirement already satisfied: ifaddr>=0.2.0 in /home/vscode/.local/lib/python3.11/site-packages (from aioice<1.0.0,>=0.9.0->aiortc>=1.9.0->semantic-kernel) (0.2.0)\n",
      "Requirement already satisfied: pycparser in /home/vscode/.local/lib/python3.11/site-packages (from cffi>=1.0.0->aiortc>=1.9.0->semantic-kernel) (2.22)\n",
      "Requirement already satisfied: wrapt<2,>=1.10 in /home/vscode/.local/lib/python3.11/site-packages (from deprecated>=1.2.6->opentelemetry-api~=1.24->semantic-kernel) (1.17.2)\n",
      "Requirement already satisfied: zipp>=3.20 in /home/vscode/.local/lib/python3.11/site-packages (from importlib-metadata<8.7.0,>=6.0->opentelemetry-api~=1.24->semantic-kernel) (3.21.0)\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /home/vscode/.local/lib/python3.11/site-packages (from jsonschema<5.0.0,>=4.18.0->openapi_core<0.20,>=0.18->semantic-kernel) (2024.10.1)\n",
      "Requirement already satisfied: referencing>=0.28.4 in /home/vscode/.local/lib/python3.11/site-packages (from jsonschema<5.0.0,>=4.18.0->openapi_core<0.20,>=0.18->semantic-kernel) (0.36.2)\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in /home/vscode/.local/lib/python3.11/site-packages (from jsonschema<5.0.0,>=4.18.0->openapi_core<0.20,>=0.18->semantic-kernel) (0.23.1)\n",
      "Requirement already satisfied: PyYAML>=5.1 in /home/vscode/.local/lib/python3.11/site-packages (from jsonschema-path<0.4.0,>=0.3.1->openapi_core<0.20,>=0.18->semantic-kernel) (6.0.2)\n",
      "Requirement already satisfied: pathable<0.5.0,>=0.4.1 in /home/vscode/.local/lib/python3.11/site-packages (from jsonschema-path<0.4.0,>=0.3.1->openapi_core<0.20,>=0.18->semantic-kernel) (0.4.4)\n",
      "Requirement already satisfied: rfc3339-validator in /home/vscode/.local/lib/python3.11/site-packages (from openapi-schema-validator<0.7.0,>=0.6.0->openapi_core<0.20,>=0.18->semantic-kernel) (0.1.4)\n",
      "Requirement already satisfied: lazy-object-proxy<2.0.0,>=1.7.1 in /home/vscode/.local/lib/python3.11/site-packages (from openapi-spec-validator<0.8.0,>=0.7.1->openapi_core<0.20,>=0.18->semantic-kernel) (1.10.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/vscode/.local/lib/python3.11/site-packages (from requests>=2.21.0->azure-core>=1.28.0->azure-search-documents) (3.4.1)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/vscode/.local/lib/python3.11/site-packages (from requests>=2.21.0->azure-core>=1.28.0->azure-search-documents) (2.3.0)\n",
      "Requirement already satisfied: ruamel.yaml.clib>=0.2.7 in /home/vscode/.local/lib/python3.11/site-packages (from ruamel.yaml>=0.17.10->prance~=23.6.21.0->semantic-kernel) (0.2.12)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.0\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.0.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install openai python-dotenv azure-search-documents semantic-kernel azure-identity PyPDF2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eec54d3b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import uuid\n",
    "import PyPDF2\n",
    "from dotenv import load_dotenv\n",
    "from typing import List, Dict, Any, Annotated, Optional\n",
    "\n",
    "import asyncio\n",
    "from azure.core.credentials import AzureKeyCredential\n",
    "from azure.search.documents import SearchClient\n",
    "from azure.search.documents.indexes import SearchIndexClient\n",
    "from azure.search.documents.indexes.models import (\n",
    "    SearchIndex, \n",
    "    SimpleField, \n",
    "    SearchFieldDataType, \n",
    "    SearchableField,\n",
    "    SearchField,\n",
    "    VectorSearch,\n",
    "    HnswAlgorithmConfiguration,\n",
    "    VectorSearchProfile,\n",
    "    VectorSearchAlgorithmKind\n",
    ")\n",
    "\n",
    "from openai import AsyncAzureOpenAI\n",
    "\n",
    "from semantic_kernel.kernel import Kernel\n",
    "from semantic_kernel.connectors.ai.open_ai import OpenAIChatCompletion\n",
    "from semantic_kernel.contents.chat_history import ChatHistory\n",
    "from semantic_kernel.functions import kernel_function\n",
    "from semantic_kernel.functions.kernel_arguments import KernelArguments\n",
    "from semantic_kernel.connectors.ai import FunctionChoiceBehavior\n",
    "from semantic_kernel.contents.function_call_content import FunctionCallContent\n",
    "from semantic_kernel.contents.function_result_content import FunctionResultContent\n",
    "from semantic_kernel.agents import ChatCompletionAgent\n",
    "\n",
    "from IPython.display import display, HTML, Markdown\n",
    "\n",
    "# Load environment variables\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee9a89a3",
   "metadata": {},
   "source": [
    "## 2. Initializing Azure Services\n",
    "\n",
    "Now let's set up our connections to Azure AI Search and Azure OpenAI."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebfee88e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Azure AI Search setup\n",
    "search_service_name = os.getenv(\"AZURE_SEARCH_SERVICE_NAME\")\n",
    "search_admin_key = os.getenv(\"AZURE_SEARCH_ADMIN_KEY\")\n",
    "search_endpoint = f\"https://{search_service_name}.search.windows.net\"\n",
    "\n",
    "# Azure OpenAI setup\n",
    "azure_openai_key = os.getenv(\"AZURE_OPENAI_KEY\")\n",
    "azure_openai_endpoint = os.getenv(\"AZURE_OPENAI_ENDPOINT\")\n",
    "azure_deployment = os.getenv(\"AZURE_OPENAI_DEPLOYMENT\", \"gpt-4o-mini\")\n",
    "azure_embedding_deployment = os.getenv(\"AZURE_OPENAI_EMBEDDING_DEPLOYMENT\", \"text-embedding-ada-002\")\n",
    "azure_openai_api_version = os.getenv(\"AZURE_OPENAI_API_VERSION\", \"2024-12-01-preview\")  # Update to match your endpoint\n",
    "\n",
    "# Initialize the asynchronous OpenAI client with proper Azure configuration\n",
    "client = AsyncAzureOpenAI(\n",
    "    azure_endpoint=azure_openai_endpoint,\n",
    "    azure_deployment=azure_deployment,\n",
    "    api_key=azure_openai_key,\n",
    "    api_version = azure_openai_api_version\n",
    ")\n",
    "\n",
    "embedding_client = AsyncAzureOpenAI(\n",
    "    azure_endpoint=azure_openai_endpoint,\n",
    "    azure_deployment=azure_embedding_deployment,\n",
    "    api_key=azure_openai_key,\n",
    "    api_version = azure_openai_api_version\n",
    ")\n",
    "\n",
    "# Create a Semantic Kernel instance\n",
    "kernel = Kernel()\n",
    "chat_completion_service = OpenAIChatCompletion(\n",
    "    ai_model_id=azure_deployment,\n",
    "    async_client=client,\n",
    "    service_id=\"agent\",\n",
    ")\n",
    "kernel.add_service(chat_completion_service)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6677b2c8",
   "metadata": {},
   "source": [
    "## Knowledge Base Creation with Azure AI Search\n",
    "\n",
    "Let's explore in more detail how Azure AI Search functions as a knowledge base for our system:\n",
    "\n",
    "### Key Components of an Azure AI Search Knowledge Base\n",
    "\n",
    "1. **Data Source Connection**: \n",
    "   - Azure AI Search connects to various data sources, including blob storage, SQL databases, and Cosmos DB\n",
    "   - In our example, we directly parsed a PDF document into text\n",
    "\n",
    "2. **Indexing Pipeline**:\n",
    "   - **Extraction**: Converting documents into text (e.g., extracting from PDFs)\n",
    "   - **Chunking**: Breaking down documents into smaller, manageable pieces\n",
    "   - **Enrichment**: Adding metadata, entity extraction, or image analysis\n",
    "   - **Normalization**: Transforming text for better search (lowercasing, lemmatization)\n",
    "\n",
    "3. **Search Index**:\n",
    "   - **Fields**: Structured data like title, content, page number\n",
    "   - **Analyzers**: Language-specific processing for better text matching\n",
    "   - **Scoring Profiles**: Customizing relevance based on specific fields or freshness\n",
    "\n",
    "4. **Query Types**:\n",
    "   - **Keyword Search**: Direct matching of terms (BM25 algorithm)\n",
    "   - **Semantic Search**: Understanding query intent (requires AI models)\n",
    "   - **Vector Search**: Finding similar concepts using embeddings\n",
    "   - **Filters**: Narrowing results by metadata (e.g., document category)\n",
    "\n",
    "### Why Azure AI Search Excels for Knowledge Bases\n",
    "\n",
    "- **Scale**: Handles millions of documents efficiently\n",
    "- **Relevance**: Sophisticated ranking algorithms ensure most relevant content appears first\n",
    "- **AI Integration**: Built-in natural language processing capabilities\n",
    "- **Security**: Role-based access control and document-level security\n",
    "- **Real-time**: Index updates appear in search results immediately\n",
    "\n",
    "In our agentic RAG system, Azure AI Search forms the foundation of the knowledge retrieval process, allowing the agent to quickly find and leverage the most relevant information from the employee handbook."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7d178eb",
   "metadata": {},
   "source": [
    "## 3. Document Indexing with Azure AI Search\n",
    "\n",
    "Let's set up our document indexing pipeline using Azure AI Search."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26dbc6c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index 'hr-documents' already exists\n"
     ]
    }
   ],
   "source": [
    "# Define constants for index\n",
    "INDEX_NAME = \"hr-documents\"\n",
    "MAX_TOKENS_PER_CHUNK = 1000\n",
    "MAX_CHUNKS_PER_DOC = 10\n",
    "VECTOR_DIMENSIONS = 1536  # Dimensions for text-embedding-ada-002\n",
    "\n",
    "# Define the schema for our search index\n",
    "def create_search_index(index_name: str, index_client: SearchIndexClient):\n",
    "    \"\"\"Create a search index if it doesn't exist.\"\"\"\n",
    "    \n",
    "    if index_name in [index.name for index in index_client.list_indexes()]:\n",
    "        print(f\"Index '{index_name}' already exists\")\n",
    "        return\n",
    "    \n",
    "    fields = [\n",
    "        SimpleField(name=\"id\", type=SearchFieldDataType.String, key=True),\n",
    "        SearchableField(name=\"content\", type=SearchFieldDataType.String, analyzer_name=\"en.microsoft\"),\n",
    "        SimpleField(name=\"title\", type=SearchFieldDataType.String),\n",
    "        SimpleField(name=\"category\", type=SearchFieldDataType.String),\n",
    "        SimpleField(name=\"page_num\", type=SearchFieldDataType.Int32),\n",
    "        SearchField(\n",
    "            name=\"vector\", \n",
    "            type=SearchFieldDataType.Collection(SearchFieldDataType.Single),\n",
    "            vector_search_dimensions=VECTOR_DIMENSIONS,\n",
    "            vector_search_profile_name=\"vector-profile\"\n",
    "        )\n",
    "    ]\n",
    "    \n",
    "    vector_search = VectorSearch(\n",
    "        algorithms=[\n",
    "            HnswAlgorithmConfiguration(\n",
    "                name=\"vector-algorithm\", \n",
    "                kind=VectorSearchAlgorithmKind.HNSW\n",
    "            )\n",
    "        ],\n",
    "        profiles=[\n",
    "            VectorSearchProfile(\n",
    "                name=\"vector-profile\", \n",
    "                algorithm_configuration_name=\"vector-algorithm\"\n",
    "            )\n",
    "        ]\n",
    "    )\n",
    "    \n",
    "    index = SearchIndex(name=index_name, fields=fields, vector_search=vector_search)\n",
    "    index_client.create_index(index)\n",
    "    print(f\"Created index '{index_name}' with vector search capability\")\n",
    "\n",
    "# Initialize search clients\n",
    "search_index_client = SearchIndexClient(\n",
    "    endpoint=search_endpoint,\n",
    "    credential=AzureKeyCredential(search_admin_key)\n",
    ")\n",
    "\n",
    "search_client = SearchClient(\n",
    "    endpoint=search_endpoint,\n",
    "    index_name=INDEX_NAME,\n",
    "    credential=AzureKeyCredential(search_admin_key)\n",
    ")\n",
    "\n",
    "# Create search index\n",
    "create_search_index(INDEX_NAME, search_index_client)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cacbd62c",
   "metadata": {},
   "source": [
    "## 4. Processing the Employee Handbook PDF with Embeddings\n",
    "\n",
    "Now, let's process the employee handbook PDF file located in the docs folder, generate embeddings, and prepare it for indexing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00e4bb34",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "# Function to generate embeddings using Azure OpenAI\n",
    "async def generate_embeddings(text):\n",
    "    \"\"\"Generate embeddings for a text using Azure OpenAI.\"\"\"\n",
    "    try:\n",
    "        # Make direct API call to Azure OpenAI\n",
    "        response = await embedding_client.embeddings.create(\n",
    "            input=text,\n",
    "            model=azure_embedding_deployment\n",
    "        )\n",
    "        return response.data[0].embedding\n",
    "    except Exception as e:\n",
    "        print(f\"Error generating embeddings: {e}\")\n",
    "        # Return a zero vector if there's an error\n",
    "        return [0.0] * VECTOR_DIMENSIONS\n",
    "\n",
    "def extract_text_from_pdf(pdf_path):\n",
    "    \"\"\"Extract text from a PDF file, returning the text content by page.\"\"\"\n",
    "    \n",
    "    print(f\"Extracting text from {pdf_path}...\")\n",
    "    \n",
    "    pdf_pages = []\n",
    "    \n",
    "    try:\n",
    "        with open(pdf_path, 'rb') as file:\n",
    "            pdf_reader = PyPDF2.PdfReader(file)\n",
    "            \n",
    "            for page_num, page in enumerate(pdf_reader.pages):\n",
    "                text = page.extract_text()\n",
    "                if text.strip():  # Only add non-empty pages\n",
    "                    pdf_pages.append({\n",
    "                        \"page_num\": page_num + 1,\n",
    "                        \"content\": text.strip()\n",
    "                    })\n",
    "            \n",
    "            print(f\"Successfully extracted text from {len(pdf_pages)} pages\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error extracting text from PDF: {e}\")\n",
    "    \n",
    "    return pdf_pages\n",
    "\n",
    "async def chunk_text_with_embeddings(pages, max_chunk_size=4000):\n",
    "    \"\"\"Split page content into smaller chunks for better indexing and retrieval and add embeddings.\"\"\"\n",
    "    \n",
    "    chunks = []\n",
    "    \n",
    "    for page in pages:\n",
    "        page_text = page[\"content\"]\n",
    "        page_num = page[\"page_num\"]\n",
    "        \n",
    "        # If the page text is shorter than max_chunk_size, keep it as is\n",
    "        if len(page_text) <= max_chunk_size:\n",
    "            # Generate embedding for the chunk\n",
    "            embedding = await generate_embeddings(page_text)\n",
    "            \n",
    "            chunks.append({\n",
    "                \"page_num\": page_num,\n",
    "                \"content\": page_text,\n",
    "                \"title\": f\"Employee Handbook - Page {page_num}\",\n",
    "                \"category\": \"Handbook\",\n",
    "                \"vector\": embedding\n",
    "            })\n",
    "        else:\n",
    "            # Split by paragraphs first\n",
    "            paragraphs = page_text.split('\\n\\n')\n",
    "            current_chunk = \"\"\n",
    "            \n",
    "            for para in paragraphs:\n",
    "                if len(current_chunk) + len(para) <= max_chunk_size:\n",
    "                    current_chunk += para + \"\\n\\n\"\n",
    "                else:\n",
    "                    # Add the current chunk if it's not empty\n",
    "                    if current_chunk:\n",
    "                        # Generate embedding for the chunk\n",
    "                        embedding = await generate_embeddings(current_chunk.strip())\n",
    "                        \n",
    "                        chunks.append({\n",
    "                            \"page_num\": page_num,\n",
    "                            \"content\": current_chunk.strip(),\n",
    "                            \"title\": f\"Employee Handbook - Page {page_num}\",\n",
    "                            \"category\": \"Handbook\",\n",
    "                            \"vector\": embedding\n",
    "                        })\n",
    "                    \n",
    "                    current_chunk = para + \"\\n\\n\"\n",
    "            \n",
    "            # Add the last chunk if it's not empty\n",
    "            if current_chunk:\n",
    "                # Generate embedding for the chunk\n",
    "                embedding = await generate_embeddings(current_chunk.strip())\n",
    "                \n",
    "                chunks.append({\n",
    "                    \"page_num\": page_num,\n",
    "                    \"content\": current_chunk.strip(),\n",
    "                    \"title\": f\"Employee Handbook - Page {page_num}\",\n",
    "                    \"category\": \"Handbook\",\n",
    "                    \"vector\": embedding\n",
    "                })\n",
    "    \n",
    "    print(f\"Created {len(chunks)} chunks with embeddings from {len(pages)} pages\")\n",
    "    return chunks\n",
    "\n",
    "# Index documents\n",
    "def index_documents(documents, search_client):\n",
    "    \"\"\"Index a list of documents into Azure AI Search.\"\"\"\n",
    "    \n",
    "    indexed_docs = []\n",
    "    \n",
    "    for doc in documents:\n",
    "        # Create a unique ID for each document\n",
    "        doc_id = str(uuid.uuid4())\n",
    "        \n",
    "        # Format the document for indexing\n",
    "        search_doc = {\n",
    "            \"id\": doc_id,\n",
    "            \"title\": doc[\"title\"],\n",
    "            \"content\": doc[\"content\"],\n",
    "            \"category\": doc[\"category\"],\n",
    "            \"page_num\": doc[\"page_num\"],\n",
    "            \"vector\": doc[\"vector\"]\n",
    "        }\n",
    "        \n",
    "        indexed_docs.append(search_doc)\n",
    "    \n",
    "    # Index the documents in batches\n",
    "    search_client.upload_documents(documents=indexed_docs)\n",
    "    print(f\"Indexed {len(indexed_docs)} documents with vector embeddings\")\n",
    "    \n",
    "    return indexed_docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c1cb966",
   "metadata": {
    "title": "Process the Employee Handbook PDF"
   },
   "outputs": [],
   "source": [
    "async def process_and_index_pdf():\n",
    "    pdf_path = \"docs/employee_handbook.pdf\"\n",
    "    pdf_pages = extract_text_from_pdf(pdf_path)\n",
    "    pdf_chunks = await chunk_text_with_embeddings(pdf_pages)\n",
    "    \n",
    "    # Index the processed chunks\n",
    "    indexed_documents = index_documents(pdf_chunks, search_client)\n",
    "    return indexed_documents\n",
    "\n",
    "# Setup function for initializing vector search\n",
    "async def init_vector_search():\n",
    "    # Process and index the PDF\n",
    "    await process_and_index_pdf()\n",
    "    print(\"Vector search initialized!\")\n",
    "    return True\n",
    "\n",
    "# When running in Jupyter, you can initialize with:\n",
    "# await init_vector_search()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffdc4a45",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "# Define a function to search HR documents using vector search\n",
    "async def search_hr_documents(query, top=5):\n",
    "    \"\"\"\n",
    "    Search for HR documents based on a query using vector search.\n",
    "    \n",
    "    Args:\n",
    "        query (str): The search query\n",
    "        top (int): Number of top results to return\n",
    "        \n",
    "    Returns:\n",
    "        str: Formatted search results\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Generate embedding for the query\n",
    "        query_embedding = await generate_embeddings(query)\n",
    "        \n",
    "        # Perform vector search\n",
    "        vector_results = search_client.search(\n",
    "            search_text=query,\n",
    "            vector_queries=[{\n",
    "                \"kind\": \"vector\",\n",
    "                \"vector\": query_embedding,\n",
    "                \"k\": top,\n",
    "                \"fields\": \"vector\"\n",
    "            }],\n",
    "            select=[\"title\", \"content\", \"page_num\"],\n",
    "            top=top\n",
    "        )\n",
    "        # Format the results\n",
    "        results_text = f\"Search results for: '{query}'\\n\\n\"\n",
    "        \n",
    "        for i, result in enumerate(vector_results):\n",
    "            results_text += f\"Result {i+1} (Page {result['page_num']}):\\n\"\n",
    "            results_text += f\"Title: {result['title']}\\n\"\n",
    "            results_text += f\"Content: {result['content'][:200]}...\\n\\n\"\n",
    "        \n",
    "        return results_text\n",
    "    \n",
    "    except Exception as e:\n",
    "        return f\"Error performing search: {str(e)}\"\n",
    "\n",
    "# Let's test the vector search\n",
    "# await search_hr_documents(\"What are the company values?\", top=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc3cecd6",
   "metadata": {},
   "source": [
    "## 5. Creating Plugins for the Agentic RAG System\n",
    "\n",
    "Now, let's define a simple search plugin that our agent will use for retrieving information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f19f659",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KernelPlugin(name='searchPlugin', description=None, functions={'search_hr_documents': KernelFunctionFromMethod(metadata=KernelFunctionMetadata(name='search_hr_documents', plugin_name='searchPlugin', description='Search for HR documents based on a query.', parameters=[KernelParameterMetadata(name='query', description=None, default_value=None, type_='str', is_required=True, type_object=<class 'str'>, schema_data={'type': 'string'}, include_in_function_choices=True), KernelParameterMetadata(name='top', description=None, default_value=3, type_='int', is_required=False, type_object=<class 'int'>, schema_data={'type': 'integer'}, include_in_function_choices=True)], is_prompt=False, is_asynchronous=True, return_parameter=KernelParameterMetadata(name='return', description='Returns the search results as formatted text.', default_value=None, type_='str', is_required=True, type_object=<class 'str'>, schema_data={'type': 'string', 'description': 'Returns the search results as formatted text.'}, include_in_function_choices=True), additional_properties={}), invocation_duration_histogram=<opentelemetry.metrics._internal.instrument._ProxyHistogram object at 0xffff5ea47a50>, streaming_duration_histogram=<opentelemetry.metrics._internal.instrument._ProxyHistogram object at 0xffff5e8e2bd0>, method=<bound method DocumentSearchPlugin.search_hr_documents of <__main__.DocumentSearchPlugin object at 0xffff5fbb1590>>, stream_method=None)})"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class DocumentSearchPlugin:\n",
    "    \"\"\"A Plugin that provides search capabilities for HR documents.\"\"\"\n",
    "\n",
    "    def __init__(self, search_client):\n",
    "        self.search_client = search_client\n",
    "\n",
    "    @kernel_function(description=\"Search for HR documents based on a query.\")\n",
    "    async def search_hr_documents(\n",
    "        self, \n",
    "        query: str,\n",
    "        top: Optional[int] = 3\n",
    "    ) -> Annotated[str, \"Returns the search results as formatted text.\"]:\n",
    "        \"\"\"Search for HR documents that match the query.\"\"\"\n",
    "        try:\n",
    "            # Generate embedding for the query\n",
    "            query_embedding = await generate_embeddings(query)\n",
    "            \n",
    "            # Perform vector search\n",
    "            vector_results = self.search_client.search(\n",
    "                search_text=query,\n",
    "                vector_queries=[{\n",
    "                    \"kind\": \"vector\",\n",
    "                    \"vector\": query_embedding,\n",
    "                    \"k\": top,\n",
    "                    \"fields\": \"vector\"\n",
    "                }],\n",
    "                select=[\"title\", \"content\", \"page_num\"],\n",
    "                top=top\n",
    "            )\n",
    "            \n",
    "            # Format the results\n",
    "            results_text = f\"Search results for: '{query}'\\n\\n\"\n",
    "            \n",
    "            for i, result in enumerate(vector_results):\n",
    "                results_text += f\"Result {i+1} (Page {result['page_num']}):\\n\"\n",
    "                results_text += f\"Title: {result['title']}\\n\"\n",
    "                results_text += f\"Content: {result['content'][:300]}...\\n\\n\"\n",
    "            \n",
    "            return results_text\n",
    "        \n",
    "        except Exception as e:\n",
    "            return f\"Error performing search: {str(e)}\"\n",
    "\n",
    "# Register the search plugin with the kernel\n",
    "kernel.add_plugin(DocumentSearchPlugin(search_client), plugin_name=\"searchPlugin\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69dd2bfe",
   "metadata": {},
   "source": [
    "## 6. Creating a Simple Agentic RAG Assistant\n",
    "\n",
    "Let's create a simple agent that can perform multiple searches as needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7dfe32a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up the agent with system message that encourages multiple searches\n",
    "agent = ChatCompletionAgent(\n",
    "    kernel=kernel,\n",
    "    instructions=\"\"\"You are a helpful HR assistant named HRBot that specializes in company policies and procedures.\n",
    "    Your purpose is to answer employee questions accurately using company documentation.\n",
    "    \n",
    "    IMPORTANT SEARCH INSTRUCTIONS:\n",
    "    1. When answering questions, you have access to a searchPlugin.search_hr_documents function.\n",
    "    2. You should make MULTIPLE searches with DIFFERENT search queries to gather comprehensive information.\n",
    "    3. For each question, formulate 2-3 DIFFERENT search queries that approach the question from different angles.\n",
    "    4. Refine your search queries based on initial results - if information is missing, search again with more specific terms.\n",
    "    5. When formulating search queries, use HR terminology and specific policy-related keywords.\n",
    "    \n",
    "    When responding:\n",
    "    - Combine information from all search results to provide complete answers\n",
    "    - Always cite which page of the handbook information comes from\n",
    "    - If information is unavailable after multiple searches, acknowledge this and suggest who to contact\n",
    "    - Be professional, concise, and helpful\n",
    "    \n",
    "    Example search strategy for \"What is the vacation policy?\":\n",
    "    1. First search: \"vacation policy allowance\"\n",
    "    2. Second search: \"paid time off accrual\"\n",
    "    3. Third search: \"requesting vacation procedure\"\n",
    "    \"\"\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76b5f626",
   "metadata": {},
   "source": [
    "## 7. Testing Our Simple Agentic RAG Assistant\n",
    "\n",
    "Let's test our assistant with some example queries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9826a5e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "async def test_agentic_search():\n",
    "    # Create a chat history\n",
    "    chat_history = ChatHistory()\n",
    "\n",
    "    user_inputs = [\n",
    "        \"What is the companies mission?\",\n",
    "        \"What are the data security policies?\",\n",
    "        \"What should I do on my first day at the company?\",\n",
    "    ]\n",
    "\n",
    "    for user_input in user_inputs:\n",
    "        # Add the user message to chat history\n",
    "        chat_history.add_user_message(user_input)\n",
    "        \n",
    "        # Display user query\n",
    "        html_output = f\"<p><strong>User:</strong> {user_input}</p>\"\n",
    "        \n",
    "        agent_name: str | None = None\n",
    "        full_response = \"\"\n",
    "        function_calls = []\n",
    "        function_results = {}\n",
    "        \n",
    "        # Track function calls by their ID and accumulate arguments\n",
    "        function_call_accumulator = {}\n",
    "\n",
    "        # Collect the agent's response\n",
    "        async for content in agent.invoke_stream(chat_history):\n",
    "            if not agent_name and hasattr(content, 'name'):\n",
    "                agent_name = content.name\n",
    "\n",
    "            # Track function calls and results\n",
    "            for item in content.items:\n",
    "                if isinstance(item, FunctionCallContent):\n",
    "                    # Get or create accumulator for this function call\n",
    "                    call_id = getattr(item, 'id', None) or str(uuid.uuid4())\n",
    "                    \n",
    "                    if call_id not in function_call_accumulator:\n",
    "                        function_call_accumulator[call_id] = {\n",
    "                            'function_name': item.function_name,\n",
    "                            'arguments': '',\n",
    "                            'processed': False\n",
    "                        }\n",
    "                    \n",
    "                    # Accumulate arguments\n",
    "                    function_call_accumulator[call_id]['arguments'] += item.arguments\n",
    "                    \n",
    "                    # Try to parse complete JSON\n",
    "                    try:\n",
    "                        args = json.loads(function_call_accumulator[call_id]['arguments'])\n",
    "                        if not function_call_accumulator[call_id]['processed']:\n",
    "                            query = args.get(\"query\", \"\")\n",
    "                            call_info = f\"Calling: search_hr_documents(query=\\\"{query}\\\")\"\n",
    "                            function_calls.append(call_info)\n",
    "                            function_call_accumulator[call_id]['processed'] = True\n",
    "                    except json.JSONDecodeError:\n",
    "                        # JSON not complete yet, continue accumulating\n",
    "                        pass\n",
    "                        \n",
    "                elif isinstance(item, FunctionResultContent):\n",
    "                    result_info = f\"Result: {item.result[:150]}...\" if len(item.result) > 150 else f\"Result: {item.result}\"\n",
    "                    function_calls.append(result_info)\n",
    "                    # Store function results to add to chat history\n",
    "                    function_results[item.function_name] = item.result\n",
    "\n",
    "            # Extract the text content\n",
    "            if hasattr(content, 'content') and content.content and content.content.strip():\n",
    "                # Check if this is a regular text message (not function related)\n",
    "                if not any(isinstance(item, (FunctionCallContent, FunctionResultContent))\n",
    "                         for item in content.items):\n",
    "                    full_response += content.content\n",
    "\n",
    "        # Add function calls to HTML\n",
    "        if function_calls:\n",
    "            html_output += '<details><summary style=\"cursor: pointer; font-weight: bold;\">Search Queries (click to expand)</summary><pre>'\n",
    "            html_output += \"\\n\".join(function_calls)\n",
    "            html_output += '</pre></details>'\n",
    "\n",
    "        # Add agent response to HTML\n",
    "        html_output += f\"<p><strong>{agent_name or 'HRBot'}:</strong> {full_response}</p>\"\n",
    "        html_output += \"<hr>\"\n",
    "\n",
    "        # Add agent's response to chat history\n",
    "        if full_response:\n",
    "            chat_history.add_assistant_message(full_response)\n",
    "\n",
    "        # Display formatted HTML\n",
    "        display(Markdown(html_output))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02a4be10",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<p><strong>User:</strong> What is the companies mission?</p><details><summary style=\"cursor: pointer; font-weight: bold;\">Search Queries (click to expand)</summary><pre>Calling: search_hr_documents(query=\"\")\n",
       "Calling: search_hr_documents(query=\"{\"qu\")\n",
       "Calling: search_hr_documents(query=\"ery\":\")\n",
       "Calling: search_hr_documents(query=\" \"comp\")\n",
       "Calling: search_hr_documents(query=\"any \")\n",
       "Calling: search_hr_documents(query=\"missi\")\n",
       "Calling: search_hr_documents(query=\"on sta\")\n",
       "Calling: search_hr_documents(query=\"teme\")\n",
       "Calling: search_hr_documents(query=\"nt\"}\")\n",
       "Calling: search_hr_documents(query=\"\")\n",
       "Calling: search_hr_documents(query=\"{\"qu\")\n",
       "Calling: search_hr_documents(query=\"ery\":\")\n",
       "Calling: search_hr_documents(query=\" \"corp\")\n",
       "Calling: search_hr_documents(query=\"orat\")\n",
       "Calling: search_hr_documents(query=\"e mis\")\n",
       "Calling: search_hr_documents(query=\"sion v\")\n",
       "Calling: search_hr_documents(query=\"alue\")\n",
       "Calling: search_hr_documents(query=\"s\"}\")\n",
       "Calling: search_hr_documents(query=\"\")\n",
       "Calling: search_hr_documents(query=\"{\"qu\")\n",
       "Calling: search_hr_documents(query=\"ery\":\")\n",
       "Calling: search_hr_documents(query=\" \"orga\")\n",
       "Calling: search_hr_documents(query=\"niza\")\n",
       "Calling: search_hr_documents(query=\"tion \")\n",
       "Calling: search_hr_documents(query=\"purpos\")\n",
       "Calling: search_hr_documents(query=\"e st\")\n",
       "Calling: search_hr_documents(query=\"ateme\")\n",
       "Calling: search_hr_documents(query=\"nt\"}\")\n",
       "Result: Search results for: 'company mission statement'\n",
       "\n",
       "Result 1 (Page 3):\n",
       "Title: Employee Handbook - Page 3\n",
       "Content: Contoso Electronics Employee Handbook  ...\n",
       "Result: Search results for: 'corporate mission values'\n",
       "\n",
       "Result 1 (Page 3):\n",
       "Title: Employee Handbook - Page 3\n",
       "Content: Contoso Electronics Employee Handbook  \n",
       "...\n",
       "Result: Search results for: 'organization purpose statement'\n",
       "\n",
       "Result 1 (Page 8):\n",
       "Title: Employee Handbook - Page 8\n",
       "Content: website.  \n",
       " \n",
       "Questions or Concerns...</pre></details><p><strong>agent_heVykdtPnDMDKybR:</strong> The company's mission, as outlined in the Employee Handbook, is to position Contoso Electronics as a leader in the aerospace industry by providing advanced electronic components for both commercial and military aircraft. The focus is on creating cutting-edge systems that are reliable and efficient (Page3).If you need more specific details or further context regarding the organization's values or strategic goals, please let me know!</p><hr>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "<p><strong>User:</strong> What are the data security policies?</p><details><summary style=\"cursor: pointer; font-weight: bold;\">Search Queries (click to expand)</summary><pre>Calling: search_hr_documents(query=\"\")\n",
       "Calling: search_hr_documents(query=\"{\"qu\")\n",
       "Calling: search_hr_documents(query=\"ery\":\")\n",
       "Calling: search_hr_documents(query=\" \"data\")\n",
       "Calling: search_hr_documents(query=\" sec\")\n",
       "Calling: search_hr_documents(query=\"urity\")\n",
       "Calling: search_hr_documents(query=\" polic\")\n",
       "Calling: search_hr_documents(query=\"y\"}\")\n",
       "Calling: search_hr_documents(query=\"\")\n",
       "Calling: search_hr_documents(query=\"{\"qu\")\n",
       "Calling: search_hr_documents(query=\"ery\":\")\n",
       "Calling: search_hr_documents(query=\" \"info\")\n",
       "Calling: search_hr_documents(query=\"rmat\")\n",
       "Calling: search_hr_documents(query=\"ion s\")\n",
       "Calling: search_hr_documents(query=\"ecurit\")\n",
       "Calling: search_hr_documents(query=\"y pr\")\n",
       "Calling: search_hr_documents(query=\"otoco\")\n",
       "Calling: search_hr_documents(query=\"ls\"}\")\n",
       "Calling: search_hr_documents(query=\"\")\n",
       "Calling: search_hr_documents(query=\"{\"qu\")\n",
       "Calling: search_hr_documents(query=\"ery\":\")\n",
       "Calling: search_hr_documents(query=\" \"data\")\n",
       "Calling: search_hr_documents(query=\" pro\")\n",
       "Calling: search_hr_documents(query=\"tecti\")\n",
       "Calling: search_hr_documents(query=\"on gui\")\n",
       "Calling: search_hr_documents(query=\"deli\")\n",
       "Calling: search_hr_documents(query=\"nes\"}\")\n",
       "Result: Search results for: 'information security protocols'\n",
       "\n",
       "Result 1 (Page 10):\n",
       "Title: Employee Handbook - Page 10\n",
       "Content: â€¢ All computers, servers, and ot...\n",
       "Result: Search results for: 'data security policy'\n",
       "\n",
       "Result 1 (Page 10):\n",
       "Title: Employee Handbook - Page 10\n",
       "Content: â€¢ All computers, servers, and other digita...\n",
       "Result: Search results for: 'data protection guidelines'\n",
       "\n",
       "Result 1 (Page 10):\n",
       "Title: Employee Handbook - Page 10\n",
       "Content: â€¢ All computers, servers, and other ...</pre></details><p><strong>agent_heVykdtPnDMDKybR:</strong> The data security policies at Contoso Electronics include the following key measures (Page10 of the Employee Handbook):\n",
       "\n",
       "1. **Protection of Devices**: All computers, servers, and digital devices that store customer data must be equipped with up-to-date anti-virus and security software.\n",
       "\n",
       "2. **Password Management**: Passwords used to access customer data are required to be complex and must be regularly updated to enhance security.\n",
       "\n",
       "3. **Data Backup**: Customer data needs to be backed up regularly to ensure that it is safeguarded against loss.\n",
       "\n",
       "These measures are in place to maintain the integrity and confidentiality of customer information. If you require more specific information or additional details on other aspects of data security, please let me know!</p><hr>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "<p><strong>User:</strong> What should I do on my first day at the company?</p><details><summary style=\"cursor: pointer; font-weight: bold;\">Search Queries (click to expand)</summary><pre>Calling: search_hr_documents(query=\"\")\n",
       "Calling: search_hr_documents(query=\"{\"qu\")\n",
       "Calling: search_hr_documents(query=\"ery\":\")\n",
       "Calling: search_hr_documents(query=\" \"firs\")\n",
       "Calling: search_hr_documents(query=\"t da\")\n",
       "Calling: search_hr_documents(query=\"y ins\")\n",
       "Calling: search_hr_documents(query=\"tructi\")\n",
       "Calling: search_hr_documents(query=\"ons\"\")\n",
       "Calling: search_hr_documents(query=\"}\")\n",
       "Calling: search_hr_documents(query=\"\")\n",
       "Calling: search_hr_documents(query=\"{\"qu\")\n",
       "Calling: search_hr_documents(query=\"ery\":\")\n",
       "Calling: search_hr_documents(query=\" \"new \")\n",
       "Calling: search_hr_documents(query=\"empl\")\n",
       "Calling: search_hr_documents(query=\"oyee \")\n",
       "Calling: search_hr_documents(query=\"orient\")\n",
       "Calling: search_hr_documents(query=\"atio\")\n",
       "Calling: search_hr_documents(query=\"n\"}\")\n",
       "Calling: search_hr_documents(query=\"\")\n",
       "Calling: search_hr_documents(query=\"{\"qu\")\n",
       "Calling: search_hr_documents(query=\"ery\":\")\n",
       "Calling: search_hr_documents(query=\" \"empl\")\n",
       "Calling: search_hr_documents(query=\"oyee\")\n",
       "Calling: search_hr_documents(query=\" onbo\")\n",
       "Calling: search_hr_documents(query=\"arding\")\n",
       "Calling: search_hr_documents(query=\" pro\")\n",
       "Calling: search_hr_documents(query=\"cess\"\")\n",
       "Calling: search_hr_documents(query=\"}\")\n",
       "Result: Search results for: 'new employee orientation'\n",
       "\n",
       "Result 1 (Page 1):\n",
       "Title: Employee Handbook - Page 1\n",
       "Content: Contoso Electronics \n",
       "Employee Handbook.....\n",
       "Result: Search results for: 'first day instructions'\n",
       "\n",
       "Result 1 (Page 1):\n",
       "Title: Employee Handbook - Page 1\n",
       "Content: Contoso Electronics \n",
       "Employee Handbook...\n",
       "...\n",
       "Result: Search results for: 'employee onboarding process'\n",
       "\n",
       "Result 1 (Page 1):\n",
       "Title: Employee Handbook - Page 1\n",
       "Content: Contoso Electronics \n",
       "Employee Handboo...\n",
       "Calling: search_hr_documents(query=\"\")\n",
       "Calling: search_hr_documents(query=\"{\"qu\")\n",
       "Calling: search_hr_documents(query=\"ery\":\")\n",
       "Calling: search_hr_documents(query=\" \"new \")\n",
       "Calling: search_hr_documents(query=\"hire\")\n",
       "Calling: search_hr_documents(query=\" firs\")\n",
       "Calling: search_hr_documents(query=\"t day \")\n",
       "Calling: search_hr_documents(query=\"chec\")\n",
       "Calling: search_hr_documents(query=\"klist\")\n",
       "Calling: search_hr_documents(query=\"\"}\")\n",
       "Calling: search_hr_documents(query=\"\")\n",
       "Calling: search_hr_documents(query=\"{\"qu\")\n",
       "Calling: search_hr_documents(query=\"ery\":\")\n",
       "Calling: search_hr_documents(query=\" \"empl\")\n",
       "Calling: search_hr_documents(query=\"oyee\")\n",
       "Calling: search_hr_documents(query=\" firs\")\n",
       "Calling: search_hr_documents(query=\"t day \")\n",
       "Calling: search_hr_documents(query=\"sche\")\n",
       "Calling: search_hr_documents(query=\"dule\"\")\n",
       "Calling: search_hr_documents(query=\"}\")\n",
       "Calling: search_hr_documents(query=\"\")\n",
       "Calling: search_hr_documents(query=\"{\"qu\")\n",
       "Calling: search_hr_documents(query=\"ery\":\")\n",
       "Calling: search_hr_documents(query=\" \"onbo\")\n",
       "Calling: search_hr_documents(query=\"ardi\")\n",
       "Calling: search_hr_documents(query=\"ng fi\")\n",
       "Calling: search_hr_documents(query=\"rst da\")\n",
       "Calling: search_hr_documents(query=\"y ex\")\n",
       "Calling: search_hr_documents(query=\"pecta\")\n",
       "Calling: search_hr_documents(query=\"tions\"\")\n",
       "Calling: search_hr_documents(query=\"}\")\n",
       "Result: Search results for: 'employee first day schedule'\n",
       "\n",
       "Result 1 (Page 1):\n",
       "Title: Employee Handbook - Page 1\n",
       "Content: Contoso Electronics \n",
       "Employee Handboo...\n",
       "Result: Search results for: 'onboarding first day expectations'\n",
       "\n",
       "Result 1 (Page 1):\n",
       "Title: Employee Handbook - Page 1\n",
       "Content: Contoso Electronics \n",
       "Employee H...\n",
       "Result: Search results for: 'new hire first day checklist'\n",
       "\n",
       "Result 1 (Page 1):\n",
       "Title: Employee Handbook - Page 1\n",
       "Content: Contoso Electronics \n",
       "Employee Handbo...\n",
       "Calling: search_hr_documents(query=\"\")\n",
       "Calling: search_hr_documents(query=\"{\"qu\")\n",
       "Calling: search_hr_documents(query=\"ery\":\")\n",
       "Calling: search_hr_documents(query=\" \"firs\")\n",
       "Calling: search_hr_documents(query=\"t da\")\n",
       "Calling: search_hr_documents(query=\"y emp\")\n",
       "Calling: search_hr_documents(query=\"loyee \")\n",
       "Calling: search_hr_documents(query=\"guid\")\n",
       "Calling: search_hr_documents(query=\"e\"}\")\n",
       "Calling: search_hr_documents(query=\"\")\n",
       "Calling: search_hr_documents(query=\"{\"qu\")\n",
       "Calling: search_hr_documents(query=\"ery\":\")\n",
       "Calling: search_hr_documents(query=\" \"empl\")\n",
       "Calling: search_hr_documents(query=\"oyee\")\n",
       "Calling: search_hr_documents(query=\" indu\")\n",
       "Calling: search_hr_documents(query=\"ction \")\n",
       "Calling: search_hr_documents(query=\"proc\")\n",
       "Calling: search_hr_documents(query=\"ess\"}\")\n",
       "Calling: search_hr_documents(query=\"\")\n",
       "Calling: search_hr_documents(query=\"{\"qu\")\n",
       "Calling: search_hr_documents(query=\"ery\":\")\n",
       "Calling: search_hr_documents(query=\" \"welc\")\n",
       "Calling: search_hr_documents(query=\"ome \")\n",
       "Calling: search_hr_documents(query=\"packa\")\n",
       "Calling: search_hr_documents(query=\"ge for\")\n",
       "Calling: search_hr_documents(query=\" new\")\n",
       "Calling: search_hr_documents(query=\" hire\")\n",
       "Calling: search_hr_documents(query=\"s\"}\")\n",
       "Result: Search results for: 'first day employee guide'\n",
       "\n",
       "Result 1 (Page 1):\n",
       "Title: Employee Handbook - Page 1\n",
       "Content: Contoso Electronics \n",
       "Employee Handbook.....\n",
       "Result: Search results for: 'employee induction process'\n",
       "\n",
       "Result 1 (Page 1):\n",
       "Title: Employee Handbook - Page 1\n",
       "Content: Contoso Electronics \n",
       "Employee Handbook...\n",
       "Result: Search results for: 'welcome package for new hires'\n",
       "\n",
       "Result 1 (Page 1):\n",
       "Title: Employee Handbook - Page 1\n",
       "Content: Contoso Electronics \n",
       "Employee Handb...</pre></details><p><strong>agent_heVykdtPnDMDKybR:</strong> It seems that I was unable to find specific guidelines or a checklist related to activities for your first day at Contoso Electronics within the Employee Handbook. However, typically, the first day at a company involves:\n",
       "\n",
       "1. **Employee Orientation**: You may attend an orientation session where you will receive information about the company, your role, and essential policies and procedures.\n",
       "\n",
       "2. **Meet Your Team**: Introducing yourself to your colleagues and getting to know your team members is a key step to begin building relationships.\n",
       "\n",
       "3. **IT Setup**: Expect to set up your workstation, including logging into your computer and accessing necessary software and tools for your job.\n",
       "\n",
       "4. **Reviewing Company Policies**: Familiarize yourself with the employee handbook, policies, and any compliance training that may be mandatory.\n",
       "\n",
       "5. **Mentorship or Buddy System**: If your company has a mentorship program, you might meet your assigned mentor or buddy who will help you navigate your first few weeks.\n",
       "\n",
       "I recommend reaching out to your HR representative or your manager for a detailed agenda or checklist tailored to your first day. They can provide you with specific instructions and expectations to help you settle into your new role effectively.</p><hr>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# await test_agentic_search()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d938ca5",
   "metadata": {},
   "source": [
    "## 8. Conclusion\n",
    "\n",
    "In this challenge, we've explored how to build an agentic RAG system using Azure AI Search and Semantic Kernel. We've learned:\n",
    "\n",
    "1. How to extract and process text from PDF documents\n",
    "2. How to index documents in Azure AI Search\n",
    "3. How to create plugins for document retrieval and query refinement\n",
    "4. How to integrate retrieval mechanisms with a conversational agent\n",
    "5. How to improve search results through query refinement\n",
    "\n",
    "This agentic approach transforms RAG from a simple lookup mechanism into an intelligent system that can handle nuanced information needs by:\n",
    "\n",
    "- **Dynamically refining queries** to improve search results\n",
    "- **Selectively retrieving information** based on the user's needs\n",
    "- **Integrating retrieval with other capabilities** through the plugin system\n",
    "\n",
    "These concepts can be applied to various enterprise scenarios, particularly for building knowledge bases that help employees navigate company policies and procedures. "
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "formats": "ipynb,py:percent"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
